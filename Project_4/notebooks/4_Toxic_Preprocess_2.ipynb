{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_tokenizer(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def polarity_sentence(sentences):\n",
    "    listy = []\n",
    "    for i in list(range(0,len(sentences))):\n",
    "        pol = TextBlob(sentences[i]).polarity\n",
    "        listy.append(pol)\n",
    "    return np.min(listy), np.max(listy), np.mean(listy),listy\n",
    "\n",
    "# TODO appears to not be working on comment_text_s\n",
    "def polarity_comment(text):\n",
    "    txt = \" \".join(text)\n",
    "    return TextBlob(txt).polarity\n",
    "\n",
    "def token_clean(text):\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    text = text.lower().split()\n",
    "    return text\n",
    "\n",
    "def comment_text_short(text):\n",
    "    return ''.join(text)[:1000]\n",
    "\n",
    "# def comment_char_short(text):\n",
    "#     return ''.join(text)[:1000]\n",
    "\n",
    "def filtered(text):\n",
    "    filter = ['PRP','CC','IN','DT','PRP$']\n",
    "    matches = []\n",
    "\n",
    "    words=pos_tag(word_tokenize(text))\n",
    "    for i in range(len(words)):\n",
    "        if words[i][1] not in filter:\n",
    "            matches.append(words[i][0])\n",
    "\n",
    "    filtered = ' '.join(matches)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv') # train data\n",
    "df['idx'] = df['id']\n",
    "df = df.set_index('idx')\n",
    "print(df.shape)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['category'] = ['To'*r.toxic + 'ST'*r.severe_toxic + 'Ob'*r.obscene+ 'Th'*r.threat+ 'In'*r.insult+'IH'*r.identity_hate for _,r in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['rating'] = df['toxic'] + df['severe_toxic'] + df['obscene'] + df['threat'] + df['insult'] + df['identity_hate']\n",
    "df['clean'] = [1 if r == 0 else 0 for r in df.rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0    143346\n",
       "1      6360\n",
       "2      3480\n",
       "3      4209\n",
       "4      1760\n",
       "5       385\n",
       "6        31\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(['rating'],ascending=[False])\n",
    "df.groupby('rating').nunique()['id'] # class imbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "                143346\n",
       "To                5666\n",
       "ToObIn            3800\n",
       "ToOb              1758\n",
       "ToIn              1215\n",
       "ToSTObIn           989\n",
       "ToObInIH           618\n",
       "Ob                 317\n",
       "In                 301\n",
       "ToSTObInIH         265\n",
       "ObIn               181\n",
       "ToSTOb             158\n",
       "ToIH               136\n",
       "ToInIH             134\n",
       "ToObThIn           131\n",
       "ToTh               113\n",
       "ToSTObThIn          64\n",
       "ToObThInIH          56\n",
       "IH                  54\n",
       "ToST                41\n",
       "ToObIH              35\n",
       "ToSTObThInIH        31\n",
       "InIH                28\n",
       "Th                  22\n",
       "ObInIH              18\n",
       "ToThIn              16\n",
       "ToSTIn              14\n",
       "ToObTh              11\n",
       "ToSTTh              11\n",
       "ToSTInIH             7\n",
       "ToThIH               7\n",
       "ToSTObIH             6\n",
       "ToSTObTh             4\n",
       "ToSTIH               3\n",
       "ThIn                 3\n",
       "ObIH                 3\n",
       "ToThInIH             3\n",
       "ObThIn               2\n",
       "ObTh                 2\n",
       "ToSTThIH             1\n",
       "ToSTThIn             1\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('category').nunique()['id'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['comment_text_s'] = df['comment_text'].apply(comment_text_short)\n",
    "df['comment_text_f'] = df['comment_text_s'].apply(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note that classes are not mutually exclusive, any comment to belong to any of 6 classes\n",
    "# as such, may need to test each classification separately, unless there is a way to test all together?\n",
    "df['token_clean'] = df['comment_text'].apply(token_clean)\n",
    "df['sent_token'] = df['comment_text'].apply(sentence_tokenizer)\n",
    "df['polarity_sentence'] = df['sent_token'].apply(polarity_sentence)\n",
    "df['polarity_comment'] = df['comment_text'].apply(polarity_comment)\n",
    "df['polarity_comment_s'] = df['comment_text_s'].apply(polarity_comment)\n",
    "df['word_count'] = df['token_clean'].apply(len)\n",
    "df['char_count'] = df['comment_text'].apply(len)\n",
    "# df['char_count_ts'] = df['comment_text_s'].apply(len)\n",
    "df['char_count_s'] = df['comment_text_s'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['polarity_min'] = [x[0] for x in df['polarity_sentence']]\n",
    "df['polarity_max'] = [x[1] for x in df['polarity_sentence']]\n",
    "df['polarity_mean'] = [x[2] for x in df['polarity_sentence']]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('../data/toxictrain.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
