{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def sentence_tokenizer(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def polarity_sentence(sentences):\n",
    "    listy = []\n",
    "    for i in list(range(0,len(sentences))):\n",
    "        pol = TextBlob(sentences[i]).polarity\n",
    "        listy.append(pol)\n",
    "    return np.min(listy), np.max(listy), np.mean(listy),listy\n",
    "\n",
    "# TODO appears to not be working on comment_text_s\n",
    "def polarity_comment(text):\n",
    "    txt = \" \".join(text)\n",
    "    return TextBlob(txt).polarity\n",
    "\n",
    "def token_clean(text):\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    text = text.lower().split()\n",
    "    return text\n",
    "\n",
    "def comment_text_short(text):\n",
    "    return ''.join(text)[:300]\n",
    "\n",
    "def filtered(text):\n",
    "    filter = ['PRP','CC','IN','DT','PRP$']\n",
    "    matches = []\n",
    "\n",
    "    words=pos_tag(word_tokenize(text))\n",
    "    for i in range(len(words)):\n",
    "        if words[i][1] not in filter:\n",
    "            matches.append(words[i][0])\n",
    "\n",
    "    filtered = ' '.join(matches)\n",
    "    return filtered\n",
    "\n",
    "def categorization(text):\n",
    "#     categories = [['To','toxic'],['ST','severe_toxic'],['O','obscene'],['Th','threat'],\n",
    "#                   ['I','insult'],['IH','identity_hate']]\n",
    "    categories = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "    listy = []\n",
    "#     for row in range(len(text.shape[0])):\n",
    "#     for row in text:\n",
    "    for column in categories:\n",
    "        if df[column]:\n",
    "            listy.append(column)\n",
    "    return listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "idx                                  \n",
       "0000997932d777bf  0000997932d777bf   \n",
       "000103f0d9cfb60f  000103f0d9cfb60f   \n",
       "000113f07ec002fd  000113f07ec002fd   \n",
       "0001b41b1c6bb37e  0001b41b1c6bb37e   \n",
       "0001d958c54c6e35  0001d958c54c6e35   \n",
       "\n",
       "                                                       comment_text  toxic  \\\n",
       "idx                                                                          \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "idx                                                                      \n",
       "0000997932d777bf             0        0       0       0              0   \n",
       "000103f0d9cfb60f             0        0       0       0              0   \n",
       "000113f07ec002fd             0        0       0       0              0   \n",
       "0001b41b1c6bb37e             0        0       0       0              0   \n",
       "0001d958c54c6e35             0        0       0       0              0   \n",
       "\n",
       "                 category  \n",
       "idx                        \n",
       "0000997932d777bf      NaN  \n",
       "000103f0d9cfb60f      NaN  \n",
       "000113f07ec002fd      NaN  \n",
       "0001b41b1c6bb37e      NaN  \n",
       "0001d958c54c6e35      NaN  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "idx                                  \n",
       "0000997932d777bf  0000997932d777bf   \n",
       "000103f0d9cfb60f  000103f0d9cfb60f   \n",
       "000113f07ec002fd  000113f07ec002fd   \n",
       "0001b41b1c6bb37e  0001b41b1c6bb37e   \n",
       "0001d958c54c6e35  0001d958c54c6e35   \n",
       "\n",
       "                                                       comment_text  toxic  \\\n",
       "idx                                                                          \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "idx                                                                     \n",
       "0000997932d777bf             0        0       0       0              0  \n",
       "000103f0d9cfb60f             0        0       0       0              0  \n",
       "000113f07ec002fd             0        0       0       0              0  \n",
       "0001b41b1c6bb37e             0        0       0       0              0  \n",
       "0001d958c54c6e35             0        0       0       0              0  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv') # train data\n",
    "df['idx'] = df['id']\n",
    "df = df.set_index('idx')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000997932d777bf</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000103f0d9cfb60f</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000113f07ec002fd</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001b41b1c6bb37e</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0001d958c54c6e35</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "idx                                  \n",
       "0000997932d777bf  0000997932d777bf   \n",
       "000103f0d9cfb60f  000103f0d9cfb60f   \n",
       "000113f07ec002fd  000113f07ec002fd   \n",
       "0001b41b1c6bb37e  0001b41b1c6bb37e   \n",
       "0001d958c54c6e35  0001d958c54c6e35   \n",
       "\n",
       "                                                       comment_text  toxic  \\\n",
       "idx                                                                          \n",
       "0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "idx                                                                      \n",
       "0000997932d777bf             0        0       0       0              0   \n",
       "000103f0d9cfb60f             0        0       0       0              0   \n",
       "000113f07ec002fd             0        0       0       0              0   \n",
       "0001b41b1c6bb37e             0        0       0       0              0   \n",
       "0001d958c54c6e35             0        0       0       0              0   \n",
       "\n",
       "                 category  \n",
       "idx                        \n",
       "0000997932d777bf      NaN  \n",
       "000103f0d9cfb60f      NaN  \n",
       "000113f07ec002fd      NaN  \n",
       "0001b41b1c6bb37e      NaN  \n",
       "0001d958c54c6e35      NaN  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'] = 'NaN'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-ce25a85be1a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategorization\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.4/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   2549\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2551\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-166-a3b83548a541>\u001b[0m in \u001b[0;36mcategorization\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m#     for row in text:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcategories\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mlisty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlisty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.4/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m   1120\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "df['category'] = df['category'].apply(categorization)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot compare a dtyped [int64] array with a scalar of type [bool]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.4/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.4/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    134\u001b[0m                                    names('rand_'), op('&')),\n\u001b[0;32m--> 135\u001b[0;31m                  ror_=bool_method(lambda x, y: operator.or_(y, x),\n\u001b[0m\u001b[1;32m    136\u001b[0m                                   names('ror_'), op('|')),\n",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'bitwise_or' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.4/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    918\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_binop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.scalar_binop\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Buffer dtype mismatch, expected 'Python object' but got 'long'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-160-48bb1d5e32ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'no'\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'severe_toxic'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'yes'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'no'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.4/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    952\u001b[0m                       is_integer_dtype(np.asarray(other)) else fill_bool)\n\u001b[1;32m    953\u001b[0m             return filler(self._constructor(\n\u001b[0;32m--> 954\u001b[0;31m                 \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m                 index=self.index)).__finalize__(self)\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow1.4/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    922\u001b[0m                            \u001b[0;34m\"with a scalar of type [{type}]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                            ).format(dtype=x.dtype, type=type(y).__name__)\n\u001b[0;32m--> 924\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot compare a dtyped [int64] array with a scalar of type [bool]"
     ]
    }
   ],
   "source": [
    "# df['category'] = np.where(df['toxic']==1,'yes','no' | df['severe_toxic']==1,'yes','no')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0    143346\n",
       "1      6360\n",
       "2      3480\n",
       "3      4209\n",
       "4      1760\n",
       "5       385\n",
       "6        31\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'] = df['toxic'] + df['severe_toxic'] + df['obscene'] + df['threat'] + df['insult'] + df['identity_hate']\n",
    "df = df.sort_values(['rating'],ascending=[False])\n",
    "df.groupby('rating').nunique()['id'] # class imbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(',', ','),\n",
       " ('I', 'PRP'),\n",
       " ('hope', 'VBP'),\n",
       " ('your', 'PRP$'),\n",
       " ('retarded', 'JJ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = df['comment_text'].iloc[0]\n",
    "words=pos_tag(word_tokenize(text))\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['comment_text_s'] = df['comment_text'].apply(comment_text_short)\n",
    "df['comment_text_f'] = df['comment_text_s'].apply(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note that classes are not mutually exclusive, any comment to belong to any of 6 classes\n",
    "# as such, may need to test each classification separately, unless there is a way to test all together?\n",
    "df['token_clean'] = df['comment_text'].apply(token_clean)\n",
    "df['sent_token'] = df['comment_text'].apply(sentence_tokenizer)\n",
    "# df['polarity_sentence'] = df['sent_token'].apply(polarity_sentence)\n",
    "# df['polarity_comment'] = df['comment_text'].apply(polarity_comment)\n",
    "df['polarity_comment_s'] = df['comment_text_s'].apply(polarity_comment)\n",
    "df['word_count'] = df['token_clean'].apply(len)\n",
    "df['char_count'] = df['comment_text'].apply(len)\n",
    "df['char_count_s'] = df['comment_text_s'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>rating</th>\n",
       "      <th>comment_text_s</th>\n",
       "      <th>comment_text_f</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>sent_token</th>\n",
       "      <th>polarity_comment_s</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3a4c7758fad18de3</th>\n",
       "      <td>3a4c7758fad18de3</td>\n",
       "      <td>, I hope your retarded kids get anal raped and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>, I hope your retarded kids get anal raped and...</td>\n",
       "      <td>, hope retarded kids get anal raped murdered h...</td>\n",
       "      <td>[i, hope, your, retarded, kids, get, anal, rap...</td>\n",
       "      <td>[, I hope your retarded kids get anal raped an...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24d2b50726b67167</th>\n",
       "      <td>24d2b50726b67167</td>\n",
       "      <td>I am going to murder ZimZalaBim ST47 for being...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>I am going to murder ZimZalaBim ST47 for being...</td>\n",
       "      <td>am going to murder ZimZalaBim ST47 being evil ...</td>\n",
       "      <td>[i, am, going, to, murder, zimzalabim, st47, f...</td>\n",
       "      <td>[I am going to murder ZimZalaBim ST47 for bein...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c586b7a2fd575b13</th>\n",
       "      <td>c586b7a2fd575b13</td>\n",
       "      <td>Shut up you asswipe, we don't care. I'll decap...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Shut up you asswipe, we don't care. I'll decap...</td>\n",
       "      <td>Shut up asswipe , do n't care . 'll decapitate...</td>\n",
       "      <td>[shut, up, you, asswipe, we, dont, care, ill, ...</td>\n",
       "      <td>[Shut up you asswipe, we don't care., I'll dec...</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77d84b1321c22d9a</th>\n",
       "      <td>77d84b1321c22d9a</td>\n",
       "      <td>LGBT \\n\\nyou little fuck , are you a fag , tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>LGBT \\n\\nyou little fuck , are you a fag , tha...</td>\n",
       "      <td>LGBT little fuck , are fag , piece shit page i...</td>\n",
       "      <td>[lgbt, you, little, fuck, are, you, a, fag, th...</td>\n",
       "      <td>[LGBT \\n\\nyou little fuck , are you a fag , th...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368c10281978876</th>\n",
       "      <td>1368c10281978876</td>\n",
       "      <td>You're a stupid cunt \\n\\nFuck you dumb arse, y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>You're a stupid cunt \\n\\nFuck you dumb arse, y...</td>\n",
       "      <td>'re stupid cunt Fuck dumb arse , mum has hairy...</td>\n",
       "      <td>[youre, a, stupid, cunt, fuck, you, dumb, arse...</td>\n",
       "      <td>[You're a stupid cunt \\n\\nFuck you dumb arse, ...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "idx                                  \n",
       "3a4c7758fad18de3  3a4c7758fad18de3   \n",
       "24d2b50726b67167  24d2b50726b67167   \n",
       "c586b7a2fd575b13  c586b7a2fd575b13   \n",
       "77d84b1321c22d9a  77d84b1321c22d9a   \n",
       "1368c10281978876  1368c10281978876   \n",
       "\n",
       "                                                       comment_text  toxic  \\\n",
       "idx                                                                          \n",
       "3a4c7758fad18de3  , I hope your retarded kids get anal raped and...      1   \n",
       "24d2b50726b67167  I am going to murder ZimZalaBim ST47 for being...      1   \n",
       "c586b7a2fd575b13  Shut up you asswipe, we don't care. I'll decap...      1   \n",
       "77d84b1321c22d9a  LGBT \\n\\nyou little fuck , are you a fag , tha...      1   \n",
       "1368c10281978876  You're a stupid cunt \\n\\nFuck you dumb arse, y...      1   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "idx                                                                      \n",
       "3a4c7758fad18de3             1        1       1       1              1   \n",
       "24d2b50726b67167             1        1       1       1              1   \n",
       "c586b7a2fd575b13             1        1       1       1              1   \n",
       "77d84b1321c22d9a             1        1       1       1              1   \n",
       "1368c10281978876             1        1       1       1              1   \n",
       "\n",
       "                  rating                                     comment_text_s  \\\n",
       "idx                                                                           \n",
       "3a4c7758fad18de3       6  , I hope your retarded kids get anal raped and...   \n",
       "24d2b50726b67167       6  I am going to murder ZimZalaBim ST47 for being...   \n",
       "c586b7a2fd575b13       6  Shut up you asswipe, we don't care. I'll decap...   \n",
       "77d84b1321c22d9a       6  LGBT \\n\\nyou little fuck , are you a fag , tha...   \n",
       "1368c10281978876       6  You're a stupid cunt \\n\\nFuck you dumb arse, y...   \n",
       "\n",
       "                                                     comment_text_f  \\\n",
       "idx                                                                   \n",
       "3a4c7758fad18de3  , hope retarded kids get anal raped murdered h...   \n",
       "24d2b50726b67167  am going to murder ZimZalaBim ST47 being evil ...   \n",
       "c586b7a2fd575b13  Shut up asswipe , do n't care . 'll decapitate...   \n",
       "77d84b1321c22d9a  LGBT little fuck , are fag , piece shit page i...   \n",
       "1368c10281978876  're stupid cunt Fuck dumb arse , mum has hairy...   \n",
       "\n",
       "                                                        token_clean  \\\n",
       "idx                                                                   \n",
       "3a4c7758fad18de3  [i, hope, your, retarded, kids, get, anal, rap...   \n",
       "24d2b50726b67167  [i, am, going, to, murder, zimzalabim, st47, f...   \n",
       "c586b7a2fd575b13  [shut, up, you, asswipe, we, dont, care, ill, ...   \n",
       "77d84b1321c22d9a  [lgbt, you, little, fuck, are, you, a, fag, th...   \n",
       "1368c10281978876  [youre, a, stupid, cunt, fuck, you, dumb, arse...   \n",
       "\n",
       "                                                         sent_token  \\\n",
       "idx                                                                   \n",
       "3a4c7758fad18de3  [, I hope your retarded kids get anal raped an...   \n",
       "24d2b50726b67167  [I am going to murder ZimZalaBim ST47 for bein...   \n",
       "c586b7a2fd575b13  [Shut up you asswipe, we don't care., I'll dec...   \n",
       "77d84b1321c22d9a  [LGBT \\n\\nyou little fuck , are you a fag , th...   \n",
       "1368c10281978876  [You're a stupid cunt \\n\\nFuck you dumb arse, ...   \n",
       "\n",
       "                  polarity_comment_s  word_count  \n",
       "idx                                               \n",
       "3a4c7758fad18de3                0.00          94  \n",
       "24d2b50726b67167                0.00          12  \n",
       "c586b7a2fd575b13               -0.25          24  \n",
       "77d84b1321c22d9a                0.00          56  \n",
       "1368c10281978876                0.00          59  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df['polarity_min'] = [x[0] for x in df['polarity_sentence']]\n",
    "# df['polarity_max'] = [x[1] for x in df['polarity_sentence']]\n",
    "# df['polarity_mean'] = [x[2] for x in df['polarity_sentence']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/pandas/core/indexing.py:194: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('../data/toxictrain.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see blog at https://ianlondon.github.io/blog/mongodb-auth/\n",
    "# see Challenge 14\n",
    "client = MongoClient(\"mongodb://cipher813:password@52.91.233.197/cool_db\") # defaults to port 27017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client.database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db = client.cool_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.create_collection(\"toxic_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.collection_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supplemental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DOWNSAMPLING: NLP should be upsampled so do not do this\n",
    "# df_t = df[df['rating']>0]\n",
    "# df_nt = df[df['rating']==0]\n",
    "# df_nt = shuffle(df_nt)\n",
    "# df_nt = df_nt[-16225:]\n",
    "# df = pd.concat([df_t,df_nt])\n",
    "# df_0 = df[df['rating']==0]\n",
    "# df_1 = df[df['rating']>0]\n",
    "# print(df_0.shape,df_1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# downsample comments to number of toxic text\n",
    "# from sklearn.utils import resample\n",
    "# df1 = df[['comment_text','toxic']]\n",
    "# X = df1.iloc[:,0]\n",
    "# y = df1.iloc[:,1]\n",
    "# print(X.shape, y.shape)\n",
    "# y[y==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_d, y_d = resample(X[y == 1],y[y == 1],replace=True, n_samples=X[y == 1].shape[0],random_state=42)\n",
    "# print(X_d.shape, y_d.shape)\n",
    "# y_d[y_d==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_bal = np.vstack((X[y==1],X_d))\n",
    "# y_bal = np.hstack((y[y==1],y_d))\n",
    "# print(X_bal.shape,y_bal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_bal = pd.DataFrame(X_bal)\n",
    "# X_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df2 = pd.concat([X_bal, y_bal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df2.sum(axis=0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count_vect = CountVectorizer()\n",
    "# X = count_vect.fit_transform(df1.comment_text)\n",
    "# # X = X.toarray()\n",
    "# # count_vect.vocabulary_\n",
    "# # X = df[['word_count','polarity_min','polarity_max','polarity_mean']]\n",
    "# y = df1['toxic']\n",
    "# # y = df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "# print(X.shape, y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count_vect = CountVectorizer()\n",
    "# X = count_vect.fit_transform(df.comment_text)\n",
    "# # X = X.toarray()\n",
    "# print(X.shape) \n",
    "# # count_vect.vocabulary_\n",
    "# # X = df[['word_count','polarity_min','polarity_max','polarity_mean']]\n",
    "# y = df['toxic']\n",
    "# # y = df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_d, y_d = resample(X[y == 0],y[y == 0],replace=True, n_samples=X[y == 1].shape[0],random_state=42)\n",
    "# print(X_d.shape, y_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # downsample comments to number of toxic text\n",
    "# from sklearn.utils import resample\n",
    "# df1 = df[['comment_text','toxic']]\n",
    "# X = df1.iloc[:,0]\n",
    "# y = df1.iloc[:,1]\n",
    "# print(X.shape, y.shape)\n",
    "# y[y==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(X[y==0].shape, X[y==1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_imb = np.vstack((X[y == 0], X[y == 1][:40]))\n",
    "\n",
    "# y_imb = np.hstack((y[y == 0], y[y == 1][:40]))\n",
    "\n",
    "# print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_d, y_d = resample(X[y == 0],y[y == 0],replace=True, n_samples=X[y == 1].shape[0],random_state=42)\n",
    "# print(X_d.shape, y_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count_vect = CountVectorizer()\n",
    "# X = count_vect.fit_transform(df1.comment_text)\n",
    "# print(X)\n",
    "# y = y_d\n",
    "# X = X.toarray()\n",
    "# print(X.shape) \n",
    "# count_vect.vocabulary_\n",
    "# X = df[['word_count','polarity_min','polarity_max','polarity_mean']]\n",
    "# y = df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "\n",
    "# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# X_train_up, y_train_up = resample(X_train[y_train == 1],y_train[y_train == 1],replace=True,\n",
    "#                                     n_samples=X_train[y_train == 0].shape[0],random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(X_train_up.shape, y_train_up.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['stemmer'] = df['comment_text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.groupby('rating').nunique()['id'] # class imbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df.sort_values(['rating'],ascending=[False])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "# pipe_lr = make_pipeline(StandardScaler(),\n",
    "#                          PCA(n_components=2),\n",
    "#                          LogisticRegression(random_state=1))\n",
    "# pipe_lr.fit(X_train, y_train)\n",
    "# y_pred = pipe_lr.predict(X_test)\n",
    "# print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "# scaler = StandardScaler(with_mean=False).fit(X_train)\n",
    "# X_train_s = scaler.transform(X_train)\n",
    "# X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DenseTransformer(TransformerMixin):\n",
    "\n",
    "#     def transform(self, X, y=None, **fit_params):\n",
    "#         return X.todense()\n",
    "\n",
    "#     def fit_transform(self, X, y=None, **fit_params):\n",
    "#         self.fit(X, y, **fit_params)\n",
    "#         return self.transform(X)\n",
    "\n",
    "#     def fit(self, X, y=None, **fit_params):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#      ('vectorizer', CountVectorizer()), \n",
    "#      ('to_dense', DenseTransformer()), \n",
    "#      ('classifier', RandomForestClassifier())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# # pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LinearSVC())])\n",
    "# predicted = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define models to test\n",
    "# model_list = [['GaussianNB', GaussianNB()], \n",
    "#                 ['BernoulliNB', BernoulliNB()], \n",
    "# #                 ['MultinomialNB', MultinomialNB()],\n",
    "#                 ['DecisionTree', DecisionTreeClassifier(class_weight='balanced')], \n",
    "#                 ['KNN', KNeighborsClassifier(10)], \n",
    "#                 ['RandomForest', RandomForestClassifier(class_weight='balanced')], \n",
    "#                 ['GradientBoost', GradientBoostingClassifier()],\n",
    "#                 ['AdaBoost', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=DecisionTreeClassifier(class_weight='balanced'))],\n",
    "#                 ['XGBoost', XGBClassifier()],\n",
    "#                 ['LogisticRegression', LogisticRegression(class_weight='balanced')],          \n",
    "#                 ['SVM', SVC(probability=True, class_weight='balanced')]] # scale data; F1 0.57\n",
    "\n",
    "# model_list_s = ['KNN','LogisticRegression','SVM'] # standardize/normalize data\n",
    "\n",
    "# # Calculate metrics for each model\n",
    "# roc = {}\n",
    "# results_dict = {}\n",
    "# for model in model_list:\n",
    "#     if model[0] in model_list_s:\n",
    "#         X_train = X_train_s\n",
    "#         X_test = X_test_s\n",
    "    \n",
    "#     model_name = model[0]\n",
    "#     model = model[1]\n",
    "    \n",
    "#     accuracy = []\n",
    "#     precision_1 = []\n",
    "#     precision_0 = []\n",
    "#     recall_1 = []\n",
    "#     recall_0 = []\n",
    "#     f1_1 = []\n",
    "#     f1_0 = []\n",
    "#     auc = []\n",
    "        \n",
    "#     # Perform K-Fold CV and calculate metrics for each fold\n",
    "#     kf = KFold(5, random_state=42, shuffle=True) \n",
    "#     for train_idx, test_idx in kf.split(X, y=y):\n",
    "#         model.fit(X_train, y_train)\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         accuracy.append(accuracy_score(y_test, y_pred))\n",
    "#         precision_1.append(precision_score(y_test, y_pred ,pos_label=1))\n",
    "#         precision_0.append(precision_score(y_test, y_pred ,pos_label=0))\n",
    "#         recall_1.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "#         recall_0.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "#         f1_1.append(f1_score(y_test, y_pred, pos_label=1))\n",
    "#         f1_0.append(f1_score(y_test, y_pred, pos_label=0))\n",
    "#         auc.append(roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "#     # Calculate mean metric across K-folds\n",
    "#     mean_accuracy = np.mean(accuracy)\n",
    "#     mean_precision_1 = np.mean(precision_1)\n",
    "#     mean_precision_0 = np.mean(precision_0)\n",
    "#     mean_recall_1 = np.mean(recall_1)\n",
    "#     mean_recall_0 = np.mean(recall_0)\n",
    "#     mean_f1_1 = np.mean(f1_1)\n",
    "#     mean_f1_0 = np.mean(f1_0)\n",
    "#     mean_auc = np.mean(auc)\n",
    "    \n",
    "#     # Capture TPR and FPR from last fold for plotting\n",
    "#     y_score = model.predict_proba(X_test)[:,1]\n",
    "#     roc[model_name] = roc_curve(y_test, y_score), mean_auc\n",
    "#     results_dict[model_name] = {\"accuracy\": mean_accuracy, \"precision_s\": mean_precision_1, \"precision_f\": mean_precision_0, \"recall_s\": mean_recall_1, \"recall_f\": mean_recall_0, \"f1_s\": mean_f1_1, \"f1_f\": mean_f1_0, \"auc\": mean_auc}\n",
    "    \n",
    "#     # Print formatted results\n",
    "#     print(model)\n",
    "#     print('\\t==============================')\n",
    "#     print('\\tAccuracy:', mean_accuracy)\n",
    "#     print('\\tAUC:', mean_auc)\n",
    "#     print('\\n')\n",
    "#     print(confusion_matrix(y_test,y_pred))\n",
    "#     print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curve from the last K-Fold split\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# # Plot 50-50 Line\n",
    "# ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "\n",
    "# # Plot Classifier ROC Curves\n",
    "# for key, value in roc.items():\n",
    "#     label = '{}, AUC: {}%'.format(key, round(100*value[1],1))\n",
    "#     ax.plot(roc[key][0][0], roc[key][0][1], label=label)\n",
    "    \n",
    "# ax.set_xlabel('FPR')\n",
    "# ax.set_ylabel('TPR')\n",
    "# ax.set_title('ROC Curve - All Models',fontweight='bold',fontsize=15)\n",
    "# ax.legend(loc='best')\n",
    "# plt.savefig('../charts/toxic_roc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rd = pd.DataFrame(results_dict).T\n",
    "# rd = rd.apply(lambda x: round(100*x,1).astype(str) + \"%\")\n",
    "# rd = rd.sort_values(['auc'],ascending=[False])\n",
    "# rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv = CountVectorizer()\n",
    "\n",
    "# r = pd.SparseDataFrame(cv.fit_transform(text), \n",
    "#                        df.index,\n",
    "#                        cv.get_feature_names(), \n",
    "#                        default_fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text = df['comment_text'].iloc[0]\n",
    "# x_back = count_vectorizer(text)\n",
    "# df1 = pd.DataFrame(x_back,columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stop = stopwords.words('english')\n",
    "# stop += ['.', ',', '(', ')', \"'\", '\"']\n",
    "# stop = set(stop)\n",
    "\n",
    "# counter = Counter()\n",
    "\n",
    "# n = 2\n",
    "# for doc in df['comment_text']:\n",
    "#     words = TextBlob(doc).words\n",
    "#     words = [w for w in words if w not in stop]\n",
    "#     bigrams = ngrams(words, n)\n",
    "#     counter += Counter(bigrams)\n",
    "\n",
    "# for phrase, count in counter.most_common(30):\n",
    "#     print('%20s %i' % (\" \".join(phrase), count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# text = ['That is should come to this!', 'This above all: to thine own self be true.', 'Something is rotten in the state of Denmark.']\n",
    "\n",
    "# # CountVectorizer is a class; so `vectorizer` below represents an instance of that object.\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,2)) # selects uni and bigrams\n",
    "\n",
    "# # call `fit` to build the vocabulary\n",
    "# vectorizer.fit(text)\n",
    "\n",
    "# # then, use `get_feature_names` to return the tokens\n",
    "# print(vectorizer.get_feature_names())\n",
    "\n",
    "# # finally, call `transform` to convert text to a bag of words\n",
    "# x = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('Sparse Matrix')\n",
    "# # A compressed version; the \"sparse\" matrix.\n",
    "# print(type(x))\n",
    "# print(x)\n",
    "\n",
    "# print ('Matrix')\n",
    "# x_back = x.toarray()\n",
    "# print(type(x_back))\n",
    "# print(x_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_back = df['token_clean'].apply(count_vectorizer)\n",
    "# count_vect = CountVectorizer()\n",
    "# X_train_counts = count_vect.fit_transform(df['comment_text'])\n",
    "# print(X_train_counts.shape)\n",
    "# X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(x_back, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_back = count_vectorizer(text)\n",
    "# pd.DataFrame(x_back, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TF: frequency in this document\n",
    "#### IDF: inverse frequency in the corpus\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2))\n",
    "# doc_vectors = vectorizer.fit_transform(text)\n",
    "\n",
    "# classes = np.array(['pos']*50 + ['neg']*50)\n",
    "\n",
    "\n",
    "# model = MultinomialNB().fit(doc_vectors, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentences = df['sent_token'].iloc[0]\n",
    "# whitespace_tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer = TreebankWordTokenizer()\n",
    "# tokenizer.tokenize(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer = WhitespaceTokenizer()\n",
    "# tokenizer.tokenize(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
