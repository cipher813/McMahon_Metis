{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import (sent_tokenize, TreebankWordTokenizer, WhitespaceTokenizer)\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB,MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report,confusion_matrix, precision_score, \n",
    "                             recall_score, f1_score, roc_curve, roc_auc_score, average_precision_score, \n",
    "                             precision_recall_curve, auc)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def sentence_tokenizer(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def whitespace_tokenizer(sentences):\n",
    "    listy = []\n",
    "    tokenizer = WhitespaceTokenizer()\n",
    "    for i in list(range(0,len(sentences))):\n",
    "        tokenized = tokenizer.tokenize(sentences[i])\n",
    "        listy.append(tokenized)\n",
    "    return listy\n",
    "\n",
    "def polarity(sentences):\n",
    "    listy = []\n",
    "    for i in list(range(0,len(sentences))):\n",
    "        pol = TextBlob(sentences[i]).polarity\n",
    "        listy.append(pol)\n",
    "    return np.min(listy), np.max(listy), np.mean(listy),listy\n",
    "\n",
    "def stemmer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    listy = []\n",
    "    for word in TextBlob(text).words:\n",
    "        listy.append(stemmer.stem(word))\n",
    "    return listy\n",
    "\n",
    "def token_clean(text):\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    text = text.lower().split()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32450, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>rating</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>sent_token</th>\n",
       "      <th>polarity_sent_token</th>\n",
       "      <th>word_count</th>\n",
       "      <th>polarity_min</th>\n",
       "      <th>polarity_max</th>\n",
       "      <th>polarity_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>[cocksucker, before, you, piss, around, on, my...</td>\n",
       "      <td>[COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK]</td>\n",
       "      <td>(0.0, 0.0, 0.0, [0.0])</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0005c987bdfc9d4b</td>\n",
       "      <td>Hey... what is it..\\n@ | talk .\\nWhat is it......</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[hey, what, is, it, talk, what, is, it, an, ex...</td>\n",
       "      <td>[Hey... what is it..\\n@ | talk ., What is it.....</td>\n",
       "      <td>(-0.0333333333333, 0.366666666667, 0.111111111...</td>\n",
       "      <td>50</td>\n",
       "      <td>-0.033333</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0007e25b2121310b</td>\n",
       "      <td>Bye! \\n\\nDon't look, come or think of comming ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[bye, dont, look, come, or, think, of, comming...</td>\n",
       "      <td>[Bye!, Don't look, come or think of comming ba...</td>\n",
       "      <td>(0.0, 0.0, 0.0, [0.0, 0.0, 0.0])</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>001810bf8c45bf5f</td>\n",
       "      <td>You are gay or antisemmitian? \\n\\nArchangel WH...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[you, are, gay, or, antisemmitian, archangel, ...</td>\n",
       "      <td>[You are gay or antisemmitian?, Archangel WHit...</td>\n",
       "      <td>(-1.0, 0.416666666667, -0.0359375, [0.41666666...</td>\n",
       "      <td>113</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>-0.035937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>00190820581d90ce</td>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[fuck, your, filthy, mother, in, the, ass, dry]</td>\n",
       "      <td>[FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!]</td>\n",
       "      <td>(-0.427777777778, -0.427777777778, -0.42777777...</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.427778</td>\n",
       "      <td>-0.427778</td>\n",
       "      <td>-0.427778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                                       comment_text  \\\n",
       "6   0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK   \n",
       "12  0005c987bdfc9d4b  Hey... what is it..\\n@ | talk .\\nWhat is it......   \n",
       "16  0007e25b2121310b  Bye! \\n\\nDon't look, come or think of comming ...   \n",
       "42  001810bf8c45bf5f  You are gay or antisemmitian? \\n\\nArchangel WH...   \n",
       "43  00190820581d90ce           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!   \n",
       "\n",
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate  rating  \\\n",
       "6       1             1        1       0       1              0       4   \n",
       "12      1             0        0       0       0              0       1   \n",
       "16      1             0        0       0       0              0       1   \n",
       "42      1             0        1       0       1              1       4   \n",
       "43      1             0        1       0       1              0       3   \n",
       "\n",
       "                                          token_clean  \\\n",
       "6   [cocksucker, before, you, piss, around, on, my...   \n",
       "12  [hey, what, is, it, talk, what, is, it, an, ex...   \n",
       "16  [bye, dont, look, come, or, think, of, comming...   \n",
       "42  [you, are, gay, or, antisemmitian, archangel, ...   \n",
       "43    [fuck, your, filthy, mother, in, the, ass, dry]   \n",
       "\n",
       "                                           sent_token  \\\n",
       "6      [COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK]   \n",
       "12  [Hey... what is it..\\n@ | talk ., What is it.....   \n",
       "16  [Bye!, Don't look, come or think of comming ba...   \n",
       "42  [You are gay or antisemmitian?, Archangel WHit...   \n",
       "43         [FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!]   \n",
       "\n",
       "                                  polarity_sent_token  word_count  \\\n",
       "6                              (0.0, 0.0, 0.0, [0.0])           8   \n",
       "12  (-0.0333333333333, 0.366666666667, 0.111111111...          50   \n",
       "16                   (0.0, 0.0, 0.0, [0.0, 0.0, 0.0])          10   \n",
       "42  (-1.0, 0.416666666667, -0.0359375, [0.41666666...         113   \n",
       "43  (-0.427777777778, -0.427777777778, -0.42777777...           8   \n",
       "\n",
       "    polarity_min  polarity_max  polarity_mean  \n",
       "6       0.000000      0.000000       0.000000  \n",
       "12     -0.033333      0.366667       0.111111  \n",
       "16      0.000000      0.000000       0.000000  \n",
       "42     -1.000000      0.416667      -0.035937  \n",
       "43     -0.427778     -0.427778      -0.427778  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/toxictrain.pkl')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            1.529400e+04\n",
       "severe_toxic     1.595000e+03\n",
       "obscene          8.449000e+03\n",
       "threat           4.780000e+02\n",
       "insult           7.877000e+03\n",
       "identity_hate    1.405000e+03\n",
       "rating           3.509800e+04\n",
       "word_count       1.959182e+06\n",
       "polarity_min    -5.685087e+03\n",
       "polarity_max     5.303854e+03\n",
       "polarity_mean   -3.346247e+02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0    16225\n",
       "1     6360\n",
       "2     3480\n",
       "3     4209\n",
       "4     1760\n",
       "5      385\n",
       "6       31\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('rating').nunique()['id'] # class imbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# downsampling\n",
    "# df_t = df[df['rating']>0]\n",
    "# df_nt = df[df['rating']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32450,) (32450,)\n"
     ]
    }
   ],
   "source": [
    "df1 = df[['comment_text','toxic']]\n",
    "X = df1['comment_text']\n",
    "y = df1['toxic']\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32450, 66472)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_cv = count_vect.fit_transform(df1.comment_text)\n",
    "X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22715,) (22715,)\n",
      "(9735,) (9735,)\n"
     ]
    }
   ],
   "source": [
    "# X_train_cv, X_test_cv, y_train_cv, y_test_cv = train_test_split(X_cv, y, test_size=0.3,random_state=42, stratify=y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42, stratify=y)\n",
    "\n",
    "k_range = list(range(1, 101))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to test\n",
    "model_list = [['GaussianNB', GaussianNB()], \n",
    "                ['BernoulliNB', BernoulliNB(alpha=0.5)], \n",
    "                ['MultinomialNB', MultinomialNB(alpha=0)],\n",
    "                ['DecisionTree', DecisionTreeClassifier(criterion = 'gini', max_depth=2, splitter='best')], \n",
    "                ['KNN', KNeighborsClassifier(27)], \n",
    "                ['RandomForest', RandomForestClassifier(max_features='auto',n_estimators=1000)], \n",
    "                ['GradientBoost', GradientBoostingClassifier(n_estimators=500)],\n",
    "                ['AdaBoost', AdaBoostClassifier(algorithm='SAMME.R',\n",
    "                      base_estimator=DecisionTreeClassifier(criterion = 'gini', max_depth=2, splitter='best'),\n",
    "                      n_estimators=2)],\n",
    "                ['XGBoost', XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
    "                       gamma=0, learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
    "                       min_child_weight=11, missing=-999, n_estimators=500, nthread=4,\n",
    "                       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "                       scale_pos_weight=1, seed=0, silent=1, subsample=0.8)],\n",
    "                ['LogisticRegression', LogisticRegression(C=1000, penalty='l1')],          \n",
    "                ['SVM', SVC(C=10,gamma=0.001,probability=True)]] \n",
    "\n",
    "# Calculate metrics for each model\n",
    "roc = {}\n",
    "results_dict = {}\n",
    "for model in model_list:\n",
    "    \n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    pipe = Pipeline([('vect', CountVectorizer()),('tfidf', TfidfTransformer()),\n",
    "                     ('to_dense', DenseTransformer()), ('pipe', model)])\n",
    "\n",
    "    accuracy = []\n",
    "    precision_1 = []\n",
    "    precision_0 = []\n",
    "    recall_1 = []\n",
    "    recall_0 = []\n",
    "    f1_1 = []\n",
    "    f1_0 = []\n",
    "    auc = []\n",
    "        \n",
    "    # Perform K-Fold CV and calculate metrics for each fold\n",
    "    kf = KFold(5, random_state=42, shuffle=True) \n",
    "    for train_idx, test_idx in kf.split(X, y=y):\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision_1.append(precision_score(y_test, y_pred ,pos_label=1))\n",
    "        precision_0.append(precision_score(y_test, y_pred ,pos_label=0))\n",
    "        recall_1.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "        recall_0.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "        f1_1.append(f1_score(y_test, y_pred, pos_label=1))\n",
    "        f1_0.append(f1_score(y_test, y_pred, pos_label=0))\n",
    "        auc.append(roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "    # Calculate mean metric across K-folds\n",
    "    mean_accuracy = np.mean(accuracy)\n",
    "    mean_precision_1 = np.mean(precision_1)\n",
    "    mean_precision_0 = np.mean(precision_0)\n",
    "    mean_recall_1 = np.mean(recall_1)\n",
    "    mean_recall_0 = np.mean(recall_0)\n",
    "    mean_f1_1 = np.mean(f1_1)\n",
    "    mean_f1_0 = np.mean(f1_0)\n",
    "    mean_auc = np.mean(auc)\n",
    "    \n",
    "    # Capture TPR and FPR from last fold for plotting\n",
    "    y_score = pipe.predict_proba(X_test)[:,1]\n",
    "    roc[model_name] = roc_curve(y_test, y_score), mean_auc\n",
    "    results_dict[model_name] = {\"accuracy\": mean_accuracy, \"precision_s\": mean_precision_1, \"precision_f\": mean_precision_0, \"recall_s\": mean_recall_1, \"recall_f\": mean_recall_0, \"f1_s\": mean_f1_1, \"f1_f\": mean_f1_0, \"auc\": mean_auc}\n",
    "    \n",
    "    # Print formatted results\n",
    "    print(model)\n",
    "    print('\\t==============================')\n",
    "    print('\\tAccuracy:', mean_accuracy)\n",
    "    print('\\tAUC:', mean_auc)\n",
    "    print('\\n')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curve from the last K-Fold split\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot 50-50 Line\n",
    "ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "\n",
    "# Plot Classifier ROC Curves\n",
    "for key, value in roc.items():\n",
    "    label = '{}, AUC: {}%'.format(key, round(100*value[1],1))\n",
    "    ax.plot(roc[key][0][0], roc[key][0][1], label=label)\n",
    "    \n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('ROC Curve - All Models',fontweight='bold',fontsize=15)\n",
    "ax.legend(loc='best')\n",
    "plt.savefig('../charts/toxic_roc_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rd = pd.DataFrame(results_dict).T\n",
    "rd = rd.apply(lambda x: round(100*x,1).astype(str) + \"%\")\n",
    "rd = rd.sort_values(['auc'],ascending=[False])\n",
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# count_vect.vocabulary_.get(u'chicken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "# X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "# X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tfidf_transformer = TfidfTransformer()\n",
    "# X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "# X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clf = MultinomialNB().fit(X_train_tfidf, y)\n",
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB())])\n",
    "text_clf.fit(X_train, y_train)\n",
    "y_pred = text_clf.predict(X_test)\n",
    "\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                           alpha=1e-3, random_state=42,\n",
    "                                           max_iter=5, tol=None))])\n",
    "text_clf.fit(X_train,y_train) \n",
    "y_pred = text_clf.predict(X_test)\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('pipe', KNeighborsClassifier(27))])\n",
    "pipe.fit(X_train,y_train) \n",
    "y_pred = pipe.predict(X_test)\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('pipe', RandomForestClassifier(max_features='auto', n_estimators=1000))])\n",
    "pipe.fit(X_train,y_train) \n",
    "y_pred = pipe.predict(X_test)\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('pipe', GradientBoostingClassifier(n_estimators=500))])\n",
    "pipe.fit(X_train,y_train) \n",
    "y_pred = pipe.predict(X_test)\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipe = Pipeline([('vect', CountVectorizer()),\n",
    "#                      ('tfidf', TfidfTransformer()),\n",
    "#                      ('pipe', XGBClassifier())])\n",
    "# pipe.fit(X_train,y_train) \n",
    "# y_pred = pipe.predict(X_test)\n",
    "# print(np.mean(y_pred == y_test))\n",
    "# print(confusion_matrix(y_test,y_pred))\n",
    "# print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('pipe', SVC(C=10,gamma=0.001,probability=True))])\n",
    "pipe.fit(X_train,y_train) \n",
    "y_pred = pipe.predict(X_test)\n",
    "print(np.mean(y_pred == y_test))\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(X_train.shape, X_test.shape, y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# downsample comments to number of toxic text\n",
    "from sklearn.utils import resample\n",
    "df1 = df[['comment_text','toxic']]\n",
    "X = df1.iloc[:,0]\n",
    "y = df1.iloc[:,1]\n",
    "print(X.shape, y.shape)\n",
    "y[y==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_d, y_d = resample(X[y == 1],y[y == 1],replace=True, n_samples=X[y == 1].shape[0],random_state=42)\n",
    "print(X_d.shape, y_d.shape)\n",
    "y_d[y_d==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_bal = np.vstack((X[y==1],X_d))\n",
    "y_bal = np.hstack((y[y==1],y_d))\n",
    "print(X_bal.shape,y_bal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_bal = pd.DataFrame(X_bal)\n",
    "X_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.concat([X_bal, y_bal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.sum(axis=0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(df1.comment_text)\n",
    "# X = X.toarray()\n",
    "# count_vect.vocabulary_\n",
    "# X = df[['word_count','polarity_min','polarity_max','polarity_mean']]\n",
    "y = df1['toxic']\n",
    "# y = df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "print(X.shape, y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(df.comment_text)\n",
    "# X = X.toarray()\n",
    "print(X.shape) \n",
    "# count_vect.vocabulary_\n",
    "# X = df[['word_count','polarity_min','polarity_max','polarity_mean']]\n",
    "y = df['toxic']\n",
    "# y = df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_d, y_d = resample(X[y == 0],y[y == 0],replace=True, n_samples=X[y == 1].shape[0],random_state=42)\n",
    "print(X_d.shape, y_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# downsample comments to number of toxic text\n",
    "from sklearn.utils import resample\n",
    "df1 = df[['comment_text','toxic']]\n",
    "X = df1.iloc[:,0]\n",
    "y = df1.iloc[:,1]\n",
    "print(X.shape, y.shape)\n",
    "y[y==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(X[y==0].shape, X[y==1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_imb = np.vstack((X[y == 0], X[y == 1][:40]))\n",
    "\n",
    "# y_imb = np.hstack((y[y == 0], y[y == 1][:40]))\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_d, y_d = resample(X[y == 0],y[y == 0],replace=True, n_samples=X[y == 1].shape[0],random_state=42)\n",
    "print(X_d.shape, y_d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(df1.comment_text)\n",
    "print(X)\n",
    "y = y_d\n",
    "# X = X.toarray()\n",
    "# print(X.shape) \n",
    "# count_vect.vocabulary_\n",
    "# X = df[['word_count','polarity_min','polarity_max','polarity_mean']]\n",
    "# y = df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "\n",
    "# print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# X_train_up, y_train_up = resample(X_train[y_train == 1],y_train[y_train == 1],replace=True,\n",
    "#                                     n_samples=X_train[y_train == 0].shape[0],random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(X_train_up.shape, y_train_up.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note that classes are not mutually exclusive, any comment to belong to any of 6 classes\n",
    "# as such, may need to test each classification separately, unless there is a way to test all together?\n",
    "# df['rating'] = df['toxic'] + df['severe_toxic'] + df['obscene'] + df['threat'] + df['insult'] + df['identity_hate']\n",
    "# df['token_clean'] = df['comment_text'].apply(token_clean)\n",
    "# df['sent_token'] = df['comment_text'].apply(sentence_tokenizer)\n",
    "# df['polarity_sent_token'] = df['sent_token'].apply(polarity)\n",
    "# df['word_count'] = df['token_clean'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['polarity_min'] = [x[0] for x in df['polarity_sent_token']]\n",
    "# df['polarity_max'] = [x[1] for x in df['polarity_sent_token']]\n",
    "# df['polarity_mean'] = [x[2] for x in df['polarity_sent_token']]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df['stemmer'] = df['comment_text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.groupby('rating').nunique()['id'] # class imbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df = df.sort_values(['rating'],ascending=[False])\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline\n",
    "# pipe_lr = make_pipeline(StandardScaler(),\n",
    "#                          PCA(n_components=2),\n",
    "#                          LogisticRegression(random_state=1))\n",
    "# pipe_lr.fit(X_train, y_train)\n",
    "# y_pred = pipe_lr.predict(X_test)\n",
    "# print('Test Accuracy: %.3f' % pipe_lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "# scaler = StandardScaler(with_mean=False).fit(X_train)\n",
    "# X_train_s = scaler.transform(X_train)\n",
    "# X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# class DenseTransformer(TransformerMixin):\n",
    "\n",
    "#     def transform(self, X, y=None, **fit_params):\n",
    "#         return X.todense()\n",
    "\n",
    "#     def fit_transform(self, X, y=None, **fit_params):\n",
    "#         self.fit(X, y, **fit_params)\n",
    "#         return self.transform(X)\n",
    "\n",
    "#     def fit(self, X, y=None, **fit_params):\n",
    "#         return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#      ('vectorizer', CountVectorizer()), \n",
    "#      ('to_dense', DenseTransformer()), \n",
    "#      ('classifier', RandomForestClassifier())\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# # pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LinearSVC())])\n",
    "# predicted = pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define models to test\n",
    "model_list = [['GaussianNB', GaussianNB()], \n",
    "                ['BernoulliNB', BernoulliNB()], \n",
    "#                 ['MultinomialNB', MultinomialNB()],\n",
    "                ['DecisionTree', DecisionTreeClassifier(class_weight='balanced')], \n",
    "                ['KNN', KNeighborsClassifier(10)], \n",
    "                ['RandomForest', RandomForestClassifier(class_weight='balanced')], \n",
    "                ['GradientBoost', GradientBoostingClassifier()],\n",
    "                ['AdaBoost', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=DecisionTreeClassifier(class_weight='balanced'))],\n",
    "                ['XGBoost', XGBClassifier()],\n",
    "                ['LogisticRegression', LogisticRegression(class_weight='balanced')],          \n",
    "                ['SVM', SVC(probability=True, class_weight='balanced')]] # scale data; F1 0.57\n",
    "\n",
    "model_list_s = ['KNN','LogisticRegression','SVM'] # standardize/normalize data\n",
    "\n",
    "# Calculate metrics for each model\n",
    "roc = {}\n",
    "results_dict = {}\n",
    "for model in model_list:\n",
    "    if model[0] in model_list_s:\n",
    "        X_train = X_train_s\n",
    "        X_test = X_test_s\n",
    "    \n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    \n",
    "    accuracy = []\n",
    "    precision_1 = []\n",
    "    precision_0 = []\n",
    "    recall_1 = []\n",
    "    recall_0 = []\n",
    "    f1_1 = []\n",
    "    f1_0 = []\n",
    "    auc = []\n",
    "        \n",
    "    # Perform K-Fold CV and calculate metrics for each fold\n",
    "    kf = KFold(5, random_state=42, shuffle=True) \n",
    "    for train_idx, test_idx in kf.split(X, y=y):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision_1.append(precision_score(y_test, y_pred ,pos_label=1))\n",
    "        precision_0.append(precision_score(y_test, y_pred ,pos_label=0))\n",
    "        recall_1.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "        recall_0.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "        f1_1.append(f1_score(y_test, y_pred, pos_label=1))\n",
    "        f1_0.append(f1_score(y_test, y_pred, pos_label=0))\n",
    "        auc.append(roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "    # Calculate mean metric across K-folds\n",
    "    mean_accuracy = np.mean(accuracy)\n",
    "    mean_precision_1 = np.mean(precision_1)\n",
    "    mean_precision_0 = np.mean(precision_0)\n",
    "    mean_recall_1 = np.mean(recall_1)\n",
    "    mean_recall_0 = np.mean(recall_0)\n",
    "    mean_f1_1 = np.mean(f1_1)\n",
    "    mean_f1_0 = np.mean(f1_0)\n",
    "    mean_auc = np.mean(auc)\n",
    "    \n",
    "    # Capture TPR and FPR from last fold for plotting\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    roc[model_name] = roc_curve(y_test, y_score), mean_auc\n",
    "    results_dict[model_name] = {\"accuracy\": mean_accuracy, \"precision_s\": mean_precision_1, \"precision_f\": mean_precision_0, \"recall_s\": mean_recall_1, \"recall_f\": mean_recall_0, \"f1_s\": mean_f1_1, \"f1_f\": mean_f1_0, \"auc\": mean_auc}\n",
    "    \n",
    "    # Print formatted results\n",
    "    print(model)\n",
    "    print('\\t==============================')\n",
    "    print('\\tAccuracy:', mean_accuracy)\n",
    "    print('\\tAUC:', mean_auc)\n",
    "    print('\\n')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curve from the last K-Fold split\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot 50-50 Line\n",
    "ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "\n",
    "# Plot Classifier ROC Curves\n",
    "for key, value in roc.items():\n",
    "    label = '{}, AUC: {}%'.format(key, round(100*value[1],1))\n",
    "    ax.plot(roc[key][0][0], roc[key][0][1], label=label)\n",
    "    \n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('ROC Curve - All Models',fontweight='bold',fontsize=15)\n",
    "ax.legend(loc='best')\n",
    "plt.savefig('../charts/toxic_roc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rd = pd.DataFrame(results_dict).T\n",
    "rd = rd.apply(lambda x: round(100*x,1).astype(str) + \"%\")\n",
    "rd = rd.sort_values(['auc'],ascending=[False])\n",
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv = CountVectorizer()\n",
    "\n",
    "# r = pd.SparseDataFrame(cv.fit_transform(text), \n",
    "#                        df.index,\n",
    "#                        cv.get_feature_names(), \n",
    "#                        default_fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# text = df['comment_text'].iloc[0]\n",
    "# x_back = count_vectorizer(text)\n",
    "# df1 = pd.DataFrame(x_back,columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stop = stopwords.words('english')\n",
    "# stop += ['.', ',', '(', ')', \"'\", '\"']\n",
    "# stop = set(stop)\n",
    "\n",
    "# counter = Counter()\n",
    "\n",
    "# n = 2\n",
    "# for doc in df['comment_text']:\n",
    "#     words = TextBlob(doc).words\n",
    "#     words = [w for w in words if w not in stop]\n",
    "#     bigrams = ngrams(words, n)\n",
    "#     counter += Counter(bigrams)\n",
    "\n",
    "# for phrase, count in counter.most_common(30):\n",
    "#     print('%20s %i' % (\" \".join(phrase), count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['That is should come to this!', 'This above all: to thine own self be true.', 'Something is rotten in the state of Denmark.']\n",
    "\n",
    "# # CountVectorizer is a class; so `vectorizer` below represents an instance of that object.\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,2)) # selects uni and bigrams\n",
    "\n",
    "# # call `fit` to build the vocabulary\n",
    "# vectorizer.fit(text)\n",
    "\n",
    "# # then, use `get_feature_names` to return the tokens\n",
    "# print(vectorizer.get_feature_names())\n",
    "\n",
    "# # finally, call `transform` to convert text to a bag of words\n",
    "# x = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('Sparse Matrix')\n",
    "# # A compressed version; the \"sparse\" matrix.\n",
    "# print(type(x))\n",
    "# print(x)\n",
    "\n",
    "# print ('Matrix')\n",
    "# x_back = x.toarray()\n",
    "# print(type(x_back))\n",
    "# print(x_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_back = df['token_clean'].apply(count_vectorizer)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df['comment_text'])\n",
    "print(X_train_counts.shape)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(x_back, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_back = count_vectorizer(text)\n",
    "# pd.DataFrame(x_back, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TF: frequency in this document\n",
    "#### IDF: inverse frequency in the corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2))\n",
    "doc_vectors = vectorizer.fit_transform(text)\n",
    "\n",
    "classes = np.array(['pos']*50 + ['neg']*50)\n",
    "\n",
    "\n",
    "model = MultinomialNB().fit(doc_vectors, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentences = df['sent_token'].iloc[0]\n",
    "# whitespace_tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer = TreebankWordTokenizer()\n",
    "# tokenizer.tokenize(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer = WhitespaceTokenizer()\n",
    "# tokenizer.tokenize(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_pickle('../data/toxictrain.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RESOURCES\n",
    "# http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "# https://stackoverflow.com/questions/28384680/scikit-learns-pipeline-a-sparse-matrix-was-passed-but-dense-data-is-required#28384887"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
