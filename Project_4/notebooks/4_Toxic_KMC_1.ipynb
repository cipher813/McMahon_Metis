{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/toxictrain.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cluster_centers(X, labels, k_num):\n",
    "    CC_list = []\n",
    "    for k in range(k_num):\n",
    "        # get the mean coordinates of each cluster\n",
    "        CC_list.append(np.mean(X[labels == k], axis = 0))\n",
    "    return CC_list\n",
    "\n",
    "# for each cluster substract the mean from each data point to get the error\n",
    "# then get the magnitude of each error, square it, and sum it\n",
    "def get_SSE(X, labels):\n",
    "    k_num = len(np.unique(labels))\n",
    "    CC_list = get_cluster_centers(X, labels, k_num)\n",
    "    CSEs = []\n",
    "    for k in range(k_num):\n",
    "        # for each cluster of k we get the coordinates of how far off each point is to the cluster\n",
    "        error_cords = X[labels == k] - CC_list[k]\n",
    "        # square the coordinates and sum to get the magnitude squared\n",
    "        error_cords_sq = error_cords ** 2\n",
    "        error_mag_sq = np.sum(error_cords_sq, axis = 1)\n",
    "        # since we already have the magnitude of the error squared we can just take the sum for the cluster\n",
    "        CSE = np.sum(error_mag_sq)\n",
    "        CSEs.append(CSE)\n",
    "    # sum each cluster's sum of squared errors\n",
    "    return sum(CSEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe A: all rating > 0 included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16225, 16) (32000, 16)\n",
      "(48225, 16)\n"
     ]
    }
   ],
   "source": [
    "# DOWNSAMPLING: to prevent kernel crashing\n",
    "df_t = df[df['rating']>0]\n",
    "df_nt = df[df['rating']==0]\n",
    "df_nt = shuffle(df_nt)\n",
    "df_nt = df_nt[-17000:] # 16225 with rating > 0 \n",
    "print(df_t.shape,df_nt.shape)\n",
    "df_A = pd.concat([df_t,df_nt])\n",
    "df_0 = df_A[df_A['rating']==0]\n",
    "df_1 = df_A[df_A['rating']>0]\n",
    "print(df_A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48225, 86640)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_A = count_vect.fit_transform(df_A.comment_text)\n",
    "X_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSEs = []\n",
    "Sil_coefs = []\n",
    "for k in range(2,20):\n",
    "    km = KMeans(n_clusters=k, random_state=1)\n",
    "    km.fit(X_A)\n",
    "    labels = km.labels_\n",
    "    Sil_coefs.append(silhouette_score(X_A, labels, metric='euclidean'))\n",
    "    SSEs.append(km.inertia_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5), sharex=True)\n",
    "k_clusters = range(2,20)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "\n",
    "# plot here on ax2\n",
    "ax2.plot(k_clusters, SSEs)\n",
    "ax2.set_xlabel('number of clusters')\n",
    "ax2.set_ylabel('SSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=13)\n",
    "km.fit(X_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_digits = km.cluster_centers_\n",
    "mu_digits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Dataframe B: All samples downsized and randomized equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_B = shuffle(df)\n",
    "df_B = df[-40000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_B = count_vect.fit_transform(df_B.comment_text)\n",
    "X_B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SSEs = []\n",
    "Sil_coefs = []\n",
    "for k in range(2,20):\n",
    "    km = KMeans(n_clusters=k, random_state=1)\n",
    "    km.fit(X_B)\n",
    "    labels = km.labels_\n",
    "    Sil_coefs.append(silhouette_score(X_B, labels, metric='euclidean'))\n",
    "    SSEs.append(km.inertia_) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(15,5), sharex=True)\n",
    "k_clusters = range(2,20)\n",
    "ax1.plot(k_clusters, Sil_coefs)\n",
    "ax1.set_xlabel('number of clusters')\n",
    "ax1.set_ylabel('silhouette coefficient')\n",
    "\n",
    "# plot here on ax2\n",
    "ax2.plot(k_clusters, SSEs)\n",
    "ax2.set_xlabel('number of clusters')\n",
    "ax2.set_ylabel('SSE');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=13)\n",
    "km.fit(X_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mu_digits = km.cluster_centers_\n",
    "mu_digits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
