{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import (sent_tokenize, TreebankWordTokenizer, WhitespaceTokenizer)\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB,MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report,confusion_matrix, precision_score, \n",
    "                             recall_score, f1_score, roc_curve, roc_auc_score, average_precision_score, \n",
    "                             precision_recall_curve, auc)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def sentence_tokenizer(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def whitespace_tokenizer(sentences):\n",
    "    listy = []\n",
    "    tokenizer = WhitespaceTokenizer()\n",
    "    for i in list(range(0,len(sentences))):\n",
    "        tokenized = tokenizer.tokenize(sentences[i])\n",
    "        listy.append(tokenized)\n",
    "    return listy\n",
    "\n",
    "def polarity(sentences):\n",
    "    listy = []\n",
    "    for i in list(range(0,len(sentences))):\n",
    "        pol = TextBlob(sentences[i]).polarity\n",
    "        listy.append(pol)\n",
    "    return np.min(listy), np.max(listy), np.mean(listy),listy\n",
    "\n",
    "def stemmer(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    listy = []\n",
    "    for word in TextBlob(text).words:\n",
    "        listy.append(stemmer.stem(word))\n",
    "    return listy\n",
    "\n",
    "# def count_vectorizer(text):\n",
    "#     vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "#     _ = vectorizer.fit(text)\n",
    "#     x = vectorizer.transform(text)\n",
    "#     x_back = x.toarray()\n",
    "#     return x_back\n",
    "\n",
    "def token_clean(text):\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    text = text.lower().split()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train.csv') # train data\n",
    "# df_test = pd.read_csv('../data/test.csv') # test data\n",
    "df = df_train\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note that classes are not mutually exclusive, any comment to belong to any of 6 classes\n",
    "# as such, may need to test each classification separately, unless there is a way to test all together?\n",
    "df['rating'] = df['toxic'] + df['severe_toxic'] + df['obscene'] + df['threat'] + df['insult'] + df['identity_hate']\n",
    "df['token_clean'] = df['comment_text'].apply(token_clean)\n",
    "df['sent_token'] = df['comment_text'].apply(sentence_tokenizer)\n",
    "df['polarity_sent_token'] = df['sent_token'].apply(polarity)\n",
    "df['word_count'] = df['token_clean'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>rating</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>sent_token</th>\n",
       "      <th>polarity_sent_token</th>\n",
       "      <th>word_count</th>\n",
       "      <th>polarity_min</th>\n",
       "      <th>polarity_max</th>\n",
       "      <th>polarity_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[Explanation\\nWhy the edits made under my user...</td>\n",
       "      <td>(0.0, 0.136363636364, 0.0454545454545, [0.0, 0...</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[D'aww!, He matches this background colour I'm...</td>\n",
       "      <td>(0.0, 0.375, 0.14375, [0.375, 0.0, 0.2, 0.0])</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
       "      <td>[Hey man, I'm really not trying to edit war., ...</td>\n",
       "      <td>(-0.1, 0.25, 0.116666666667, [-0.1, 0.2, 0.25])</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[more, i, cant, make, any, real, suggestions, ...</td>\n",
       "      <td>[\"\\nMore\\nI can't make any real suggestions on...</td>\n",
       "      <td>(0.0, 0.4, 0.17875, [0.19, 0.125, 0.0, 0.4])</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.178750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[You, sir, are my hero., Any chance you rememb...</td>\n",
       "      <td>(0.0, 0.0, 0.0, [0.0, 0.0])</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  rating  \\\n",
       "0             0        0       0       0              0       0   \n",
       "1             0        0       0       0              0       0   \n",
       "2             0        0       0       0              0       0   \n",
       "3             0        0       0       0              0       0   \n",
       "4             0        0       0       0              0       0   \n",
       "\n",
       "                                         token_clean  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [daww, he, matches, this, background, colour, ...   \n",
       "2  [hey, man, im, really, not, trying, to, edit, ...   \n",
       "3  [more, i, cant, make, any, real, suggestions, ...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                          sent_token  \\\n",
       "0  [Explanation\\nWhy the edits made under my user...   \n",
       "1  [D'aww!, He matches this background colour I'm...   \n",
       "2  [Hey man, I'm really not trying to edit war., ...   \n",
       "3  [\"\\nMore\\nI can't make any real suggestions on...   \n",
       "4  [You, sir, are my hero., Any chance you rememb...   \n",
       "\n",
       "                                 polarity_sent_token  word_count  \\\n",
       "0  (0.0, 0.136363636364, 0.0454545454545, [0.0, 0...          43   \n",
       "1      (0.0, 0.375, 0.14375, [0.375, 0.0, 0.2, 0.0])          17   \n",
       "2    (-0.1, 0.25, 0.116666666667, [-0.1, 0.2, 0.25])          42   \n",
       "3       (0.0, 0.4, 0.17875, [0.19, 0.125, 0.0, 0.4])         109   \n",
       "4                        (0.0, 0.0, 0.0, [0.0, 0.0])          13   \n",
       "\n",
       "   polarity_min  polarity_max  polarity_mean  \n",
       "0           0.0      0.136364       0.045455  \n",
       "1           0.0      0.375000       0.143750  \n",
       "2          -0.1      0.250000       0.116667  \n",
       "3           0.0      0.400000       0.178750  \n",
       "4           0.0      0.000000       0.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['polarity_min'] = [x[0] for x in df['polarity_sent_token']]\n",
    "df['polarity_max'] = [x[1] for x in df['polarity_sent_token']]\n",
    "df['polarity_mean'] = [x[2] for x in df['polarity_sent_token']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['stemmer'] = df['comment_text'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>rating</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>sent_token</th>\n",
       "      <th>polarity_sent_token</th>\n",
       "      <th>word_count</th>\n",
       "      <th>polarity_min</th>\n",
       "      <th>polarity_max</th>\n",
       "      <th>polarity_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
       "      <td>[Explanation\\nWhy the edits made under my user...</td>\n",
       "      <td>(0.0, 0.136363636364, 0.0454545454545, [0.0, 0...</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
       "      <td>[D'aww!, He matches this background colour I'm...</td>\n",
       "      <td>(0.0, 0.375, 0.14375, [0.375, 0.0, 0.2, 0.0])</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.143750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
       "      <td>[Hey man, I'm really not trying to edit war., ...</td>\n",
       "      <td>(-0.1, 0.25, 0.116666666667, [-0.1, 0.2, 0.25])</td>\n",
       "      <td>42</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.116667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[more, i, cant, make, any, real, suggestions, ...</td>\n",
       "      <td>[\"\\nMore\\nI can't make any real suggestions on...</td>\n",
       "      <td>(0.0, 0.4, 0.17875, [0.19, 0.125, 0.0, 0.4])</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.178750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
       "      <td>[You, sir, are my hero., Any chance you rememb...</td>\n",
       "      <td>(0.0, 0.0, 0.0, [0.0, 0.0])</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  rating  \\\n",
       "0             0        0       0       0              0       0   \n",
       "1             0        0       0       0              0       0   \n",
       "2             0        0       0       0              0       0   \n",
       "3             0        0       0       0              0       0   \n",
       "4             0        0       0       0              0       0   \n",
       "\n",
       "                                         token_clean  \\\n",
       "0  [explanation, why, the, edits, made, under, my...   \n",
       "1  [daww, he, matches, this, background, colour, ...   \n",
       "2  [hey, man, im, really, not, trying, to, edit, ...   \n",
       "3  [more, i, cant, make, any, real, suggestions, ...   \n",
       "4  [you, sir, are, my, hero, any, chance, you, re...   \n",
       "\n",
       "                                          sent_token  \\\n",
       "0  [Explanation\\nWhy the edits made under my user...   \n",
       "1  [D'aww!, He matches this background colour I'm...   \n",
       "2  [Hey man, I'm really not trying to edit war., ...   \n",
       "3  [\"\\nMore\\nI can't make any real suggestions on...   \n",
       "4  [You, sir, are my hero., Any chance you rememb...   \n",
       "\n",
       "                                 polarity_sent_token  word_count  \\\n",
       "0  (0.0, 0.136363636364, 0.0454545454545, [0.0, 0...          43   \n",
       "1      (0.0, 0.375, 0.14375, [0.375, 0.0, 0.2, 0.0])          17   \n",
       "2    (-0.1, 0.25, 0.116666666667, [-0.1, 0.2, 0.25])          42   \n",
       "3       (0.0, 0.4, 0.17875, [0.19, 0.125, 0.0, 0.4])         109   \n",
       "4                        (0.0, 0.0, 0.0, [0.0, 0.0])          13   \n",
       "\n",
       "   polarity_min  polarity_max  polarity_mean  \n",
       "0           0.0      0.136364       0.045455  \n",
       "1           0.0      0.375000       0.143750  \n",
       "2          -0.1      0.250000       0.116667  \n",
       "3           0.0      0.400000       0.178750  \n",
       "4           0.0      0.000000       0.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('rating').nunique()['id'] # class imbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>rating</th>\n",
       "      <th>token_clean</th>\n",
       "      <th>sent_token</th>\n",
       "      <th>polarity_sent_token</th>\n",
       "      <th>word_count</th>\n",
       "      <th>polarity_min</th>\n",
       "      <th>polarity_max</th>\n",
       "      <th>polarity_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106617</th>\n",
       "      <td>3a4c7758fad18de3</td>\n",
       "      <td>, I hope your retarded kids get anal raped and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[i, hope, your, retarded, kids, get, anal, rap...</td>\n",
       "      <td>[, I hope your retarded kids get anal raped an...</td>\n",
       "      <td>(-0.6, 1.0, -0.01875, [-0.4, -0.4, 0.55, 0.15,...</td>\n",
       "      <td>94</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.018750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13964</th>\n",
       "      <td>24d2b50726b67167</td>\n",
       "      <td>I am going to murder ZimZalaBim ST47 for being...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[i, am, going, to, murder, zimzalabim, st47, f...</td>\n",
       "      <td>[I am going to murder ZimZalaBim ST47 for bein...</td>\n",
       "      <td>(-1.0, -1.0, -1.0, [-1.0])</td>\n",
       "      <td>12</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73821</th>\n",
       "      <td>c586b7a2fd575b13</td>\n",
       "      <td>Shut up you asswipe, we don't care. I'll decap...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[shut, up, you, asswipe, we, dont, care, ill, ...</td>\n",
       "      <td>[Shut up you asswipe, we don't care., I'll dec...</td>\n",
       "      <td>(-0.2, 0.0, -0.0755555555556, [0.0, -0.1777777...</td>\n",
       "      <td>24</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.075556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151131</th>\n",
       "      <td>77d84b1321c22d9a</td>\n",
       "      <td>LGBT \\n\\nyou little fuck , are you a fag , tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[lgbt, you, little, fuck, are, you, a, fag, th...</td>\n",
       "      <td>[LGBT \\n\\nyou little fuck , are you a fag , th...</td>\n",
       "      <td>(-0.1775, 0.0, -0.08875, [-0.17750000000000005...</td>\n",
       "      <td>56</td>\n",
       "      <td>-0.1775</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.088750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>1368c10281978876</td>\n",
       "      <td>You're a stupid cunt \\n\\nFuck you dumb arse, y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[youre, a, stupid, cunt, fuck, you, dumb, arse...</td>\n",
       "      <td>[You're a stupid cunt \\n\\nFuck you dumb arse, ...</td>\n",
       "      <td>(-0.4125, -0.4125, -0.4125, [-0.41250000000000...</td>\n",
       "      <td>59</td>\n",
       "      <td>-0.4125</td>\n",
       "      <td>-0.4125</td>\n",
       "      <td>-0.412500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "106617  3a4c7758fad18de3  , I hope your retarded kids get anal raped and...   \n",
       "13964   24d2b50726b67167  I am going to murder ZimZalaBim ST47 for being...   \n",
       "73821   c586b7a2fd575b13  Shut up you asswipe, we don't care. I'll decap...   \n",
       "151131  77d84b1321c22d9a  LGBT \\n\\nyou little fuck , are you a fag , tha...   \n",
       "7299    1368c10281978876  You're a stupid cunt \\n\\nFuck you dumb arse, y...   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  rating  \\\n",
       "106617      1             1        1       1       1              1       6   \n",
       "13964       1             1        1       1       1              1       6   \n",
       "73821       1             1        1       1       1              1       6   \n",
       "151131      1             1        1       1       1              1       6   \n",
       "7299        1             1        1       1       1              1       6   \n",
       "\n",
       "                                              token_clean  \\\n",
       "106617  [i, hope, your, retarded, kids, get, anal, rap...   \n",
       "13964   [i, am, going, to, murder, zimzalabim, st47, f...   \n",
       "73821   [shut, up, you, asswipe, we, dont, care, ill, ...   \n",
       "151131  [lgbt, you, little, fuck, are, you, a, fag, th...   \n",
       "7299    [youre, a, stupid, cunt, fuck, you, dumb, arse...   \n",
       "\n",
       "                                               sent_token  \\\n",
       "106617  [, I hope your retarded kids get anal raped an...   \n",
       "13964   [I am going to murder ZimZalaBim ST47 for bein...   \n",
       "73821   [Shut up you asswipe, we don't care., I'll dec...   \n",
       "151131  [LGBT \\n\\nyou little fuck , are you a fag , th...   \n",
       "7299    [You're a stupid cunt \\n\\nFuck you dumb arse, ...   \n",
       "\n",
       "                                      polarity_sent_token  word_count  \\\n",
       "106617  (-0.6, 1.0, -0.01875, [-0.4, -0.4, 0.55, 0.15,...          94   \n",
       "13964                          (-1.0, -1.0, -1.0, [-1.0])          12   \n",
       "73821   (-0.2, 0.0, -0.0755555555556, [0.0, -0.1777777...          24   \n",
       "151131  (-0.1775, 0.0, -0.08875, [-0.17750000000000005...          56   \n",
       "7299    (-0.4125, -0.4125, -0.4125, [-0.41250000000000...          59   \n",
       "\n",
       "        polarity_min  polarity_max  polarity_mean  \n",
       "106617       -0.6000        1.0000      -0.018750  \n",
       "13964        -1.0000       -1.0000      -1.000000  \n",
       "73821        -0.2000        0.0000      -0.075556  \n",
       "151131       -0.1775        0.0000      -0.088750  \n",
       "7299         -0.4125       -0.4125      -0.412500  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(['rating'],ascending=[False])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 189775)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X = count_vect.fit_transform(df.comment_text)\n",
    "# X = X.toarray()\n",
    "print(X.shape) \n",
    "# count_vect.vocabulary_\n",
    "# X = df[['word_count','polarity_min','polarity_max','polarity_mean']]\n",
    "y = df['toxic']\n",
    "# y = df[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42, stratify=y)\n",
    "\n",
    "k_range = list(range(1, 101))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "scaler = StandardScaler(with_mean=False).fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenseTransformer(TransformerMixin):\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    def fit_transform(self, X, y=None, **fit_params):\n",
    "        self.fit(X, y, **fit_params)\n",
    "        return self.transform(X)\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "     ('vectorizer', CountVectorizer()), \n",
    "     ('to_dense', DenseTransformer()), \n",
    "     ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer()), ('classifier', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to test\n",
    "model_list = [['GaussianNB', GaussianNB()], \n",
    "                ['BernoulliNB', BernoulliNB()], \n",
    "#                 ['MultinomialNB', MultinomialNB()],\n",
    "                ['DecisionTree', DecisionTreeClassifier()], \n",
    "                ['KNN', KNeighborsClassifier(10)], \n",
    "                ['RandomForest', RandomForestClassifier()], \n",
    "                ['GradientBoost', GradientBoostingClassifier()],\n",
    "                ['AdaBoost', AdaBoostClassifier(algorithm='SAMME.R', base_estimator=DecisionTreeClassifier())],\n",
    "                ['XGBoost', XGBClassifier()],\n",
    "                ['LogisticRegression', LogisticRegression()],          \n",
    "                ['SVM', SVC(probability=True)]] # scale data; F1 0.57\n",
    "\n",
    "model_list_s = ['KNN','LogisticRegression','SVM'] # standardize/normalize data\n",
    "\n",
    "# Calculate metrics for each model\n",
    "roc = {}\n",
    "results_dict = {}\n",
    "for model in model_list:\n",
    "    if model[0] in model_list_s:\n",
    "        X_train = X_train_s\n",
    "        X_test = X_test_s\n",
    "    \n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    \n",
    "    accuracy = []\n",
    "    precision_1 = []\n",
    "    precision_0 = []\n",
    "    recall_1 = []\n",
    "    recall_0 = []\n",
    "    f1_1 = []\n",
    "    f1_0 = []\n",
    "    auc = []\n",
    "        \n",
    "    # Perform K-Fold CV and calculate metrics for each fold\n",
    "    kf = KFold(5, random_state=42, shuffle=True) \n",
    "    for train_idx, test_idx in kf.split(X, y=y):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision_1.append(precision_score(y_test, y_pred ,pos_label=1))\n",
    "        precision_0.append(precision_score(y_test, y_pred ,pos_label=0))\n",
    "        recall_1.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "        recall_0.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "        f1_1.append(f1_score(y_test, y_pred, pos_label=1))\n",
    "        f1_0.append(f1_score(y_test, y_pred, pos_label=0))\n",
    "        auc.append(roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "    # Calculate mean metric across K-folds\n",
    "    mean_accuracy = np.mean(accuracy)\n",
    "    mean_precision_1 = np.mean(precision_1)\n",
    "    mean_precision_0 = np.mean(precision_0)\n",
    "    mean_recall_1 = np.mean(recall_1)\n",
    "    mean_recall_0 = np.mean(recall_0)\n",
    "    mean_f1_1 = np.mean(f1_1)\n",
    "    mean_f1_0 = np.mean(f1_0)\n",
    "    mean_auc = np.mean(auc)\n",
    "    \n",
    "    # Capture TPR and FPR from last fold for plotting\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    roc[model_name] = roc_curve(y_test, y_score), mean_auc\n",
    "    results_dict[model_name] = {\"accuracy\": mean_accuracy, \"precision_s\": mean_precision_1, \"precision_f\": mean_precision_0, \"recall_s\": mean_recall_1, \"recall_f\": mean_recall_0, \"f1_s\": mean_f1_1, \"f1_f\": mean_f1_0, \"auc\": mean_auc}\n",
    "    \n",
    "    # Print formatted results\n",
    "    print(model)\n",
    "    print('\\t==============================')\n",
    "    print('\\tAccuracy:', mean_accuracy)\n",
    "    print('\\tAUC:', mean_auc)\n",
    "    print('\\n')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve from the last K-Fold split\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot 50-50 Line\n",
    "ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "\n",
    "# Plot Classifier ROC Curves\n",
    "for key, value in roc.items():\n",
    "    label = '{}, AUC: {}%'.format(key, round(100*value[1],1))\n",
    "    ax.plot(roc[key][0][0], roc[key][0][1], label=label)\n",
    "    \n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('ROC Curve - All Models',fontweight='bold',fontsize=15)\n",
    "ax.legend(loc='best')\n",
    "plt.savefig('../charts/toxic_roc.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = pd.DataFrame(results_dict).T\n",
    "rd = rd.apply(lambda x: round(100*x,1).astype(str) + \"%\")\n",
    "rd = rd.sort_values(['auc'],ascending=[False])\n",
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cv = CountVectorizer()\n",
    "\n",
    "# r = pd.SparseDataFrame(cv.fit_transform(text), \n",
    "#                        df.index,\n",
    "#                        cv.get_feature_names(), \n",
    "#                        default_fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = df['comment_text'].iloc[0]\n",
    "# x_back = count_vectorizer(text)\n",
    "# df1 = pd.DataFrame(x_back,columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop = stopwords.words('english')\n",
    "# stop += ['.', ',', '(', ')', \"'\", '\"']\n",
    "# stop = set(stop)\n",
    "\n",
    "# counter = Counter()\n",
    "\n",
    "# n = 2\n",
    "# for doc in df['comment_text']:\n",
    "#     words = TextBlob(doc).words\n",
    "#     words = [w for w in words if w not in stop]\n",
    "#     bigrams = ngrams(words, n)\n",
    "#     counter += Counter(bigrams)\n",
    "\n",
    "# for phrase, count in counter.most_common(30):\n",
    "#     print('%20s %i' % (\" \".join(phrase), count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = ['That is should come to this!', 'This above all: to thine own self be true.', 'Something is rotten in the state of Denmark.']\n",
    "\n",
    "# # CountVectorizer is a class; so `vectorizer` below represents an instance of that object.\n",
    "# vectorizer = CountVectorizer(ngram_range=(1,2)) # selects uni and bigrams\n",
    "\n",
    "# # call `fit` to build the vocabulary\n",
    "# vectorizer.fit(text)\n",
    "\n",
    "# # then, use `get_feature_names` to return the tokens\n",
    "# print(vectorizer.get_feature_names())\n",
    "\n",
    "# # finally, call `transform` to convert text to a bag of words\n",
    "# x = vectorizer.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('Sparse Matrix')\n",
    "# # A compressed version; the \"sparse\" matrix.\n",
    "# print(type(x))\n",
    "# print(x)\n",
    "\n",
    "# print ('Matrix')\n",
    "# x_back = x.toarray()\n",
    "# print(type(x_back))\n",
    "# print(x_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_back = df['token_clean'].apply(count_vectorizer)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(df['comment_text'])\n",
    "print(X_train_counts.shape)\n",
    "X_train_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(x_back, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_back = count_vectorizer(text)\n",
    "# pd.DataFrame(x_back, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### TF: frequency in this document\n",
    "#### IDF: inverse frequency in the corpus\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", ngram_range=(1,2))\n",
    "doc_vectors = vectorizer.fit_transform(text)\n",
    "\n",
    "classes = np.array(['pos']*50 + ['neg']*50)\n",
    "\n",
    "\n",
    "model = MultinomialNB().fit(doc_vectors, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentences = df['sent_token'].iloc[0]\n",
    "# whitespace_tokenizer(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer = TreebankWordTokenizer()\n",
    "# tokenizer.tokenize(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenizer = WhitespaceTokenizer()\n",
    "# tokenizer.tokenize(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('../data/toxictrain.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
