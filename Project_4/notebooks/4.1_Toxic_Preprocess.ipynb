{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from time import time\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_tokenizer(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    return sentences\n",
    "\n",
    "def polarity_sentence(sentences):\n",
    "    listy = []\n",
    "    for i in list(range(0,len(sentences))):\n",
    "        pol = TextBlob(sentences[i]).polarity\n",
    "        listy.append(pol)\n",
    "    return np.min(listy), np.max(listy), np.mean(listy),listy\n",
    "\n",
    "# TODO appears to not be working on comment_text_s\n",
    "def polarity_comment(text):\n",
    "    txt = \" \".join(text)\n",
    "    return TextBlob(txt).polarity\n",
    "\n",
    "def token_clean(text):\n",
    "    text = text.replace('\\n',' ')\n",
    "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    text = text.lower().split()\n",
    "    return text\n",
    "\n",
    "def comment_text_short(text):\n",
    "    return ''.join(text)[:1000]\n",
    "\n",
    "def filtered(text):\n",
    "    filter = ['PRP','CC','IN','DT','PRP$']\n",
    "    matches = []\n",
    "\n",
    "    words=pos_tag(word_tokenize(text))\n",
    "    for i in range(len(words)):\n",
    "        if words[i][1] not in filter:\n",
    "            matches.append(words[i][0])\n",
    "\n",
    "    filtered = ' '.join(matches)\n",
    "    return filtered\n",
    "\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/train.csv') # train data\n",
    "df['idx'] = df['id']\n",
    "df = df.set_index('idx')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['category'] = ['To'*r.toxic + 'ST'*r.severe_toxic + 'Ob'*r.obscene+ 'Th'*r.threat+ 'In'*r.insult+'IH'*r.identity_hate for _,r in df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=0,numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['rating'] = df['toxic'] + df['severe_toxic'] + df['obscene'] + df['threat'] + df['insult'] + df['identity_hate']\n",
    "df['clean'] = [1 if r == 0 else 0 for r in df.rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "0    143346\n",
       "1      6360\n",
       "2      3480\n",
       "3      4209\n",
       "4      1760\n",
       "5       385\n",
       "6        31\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sort_values(['rating'],ascending=[False])\n",
    "df.groupby('rating').nunique()['id'] # class imbalance issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "                143346\n",
       "To                5666\n",
       "ToObIn            3800\n",
       "ToOb              1758\n",
       "ToIn              1215\n",
       "ToSTObIn           989\n",
       "ToObInIH           618\n",
       "Ob                 317\n",
       "In                 301\n",
       "ToSTObInIH         265\n",
       "ObIn               181\n",
       "ToSTOb             158\n",
       "ToIH               136\n",
       "ToInIH             134\n",
       "ToObThIn           131\n",
       "ToTh               113\n",
       "ToSTObThIn          64\n",
       "ToObThInIH          56\n",
       "IH                  54\n",
       "ToST                41\n",
       "ToObIH              35\n",
       "ToSTObThInIH        31\n",
       "InIH                28\n",
       "Th                  22\n",
       "ObInIH              18\n",
       "ToThIn              16\n",
       "ToSTIn              14\n",
       "ToObTh              11\n",
       "ToSTTh              11\n",
       "ToSTInIH             7\n",
       "ToThIH               7\n",
       "ToSTObIH             6\n",
       "ToSTObTh             4\n",
       "ToSTIH               3\n",
       "ThIn                 3\n",
       "ObIH                 3\n",
       "ToThInIH             3\n",
       "ObThIn               2\n",
       "ObTh                 2\n",
       "ToSTThIH             1\n",
       "ToSTThIn             1\n",
       "Name: id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('category').nunique()['id'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['comment_text_s'] = df['comment_text'].apply(comment_text_short)\n",
    "df['comment_text_f'] = df['comment_text_s'].apply(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# note that classes are not mutually exclusive, any comment to belong to any of 6 classes\n",
    "# as such, may need to test each classification separately, unless there is a way to test all together?\n",
    "df['token_clean'] = df['comment_text'].apply(token_clean)\n",
    "df['sent_token'] = df['comment_text'].apply(sentence_tokenizer)\n",
    "df['polarity_sentence'] = df['sent_token'].apply(polarity_sentence)\n",
    "df['polarity_comment'] = df['comment_text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "df['polarity_comment_s'] = df['comment_text_s'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "df['word_count'] = df['token_clean'].apply(len)\n",
    "df['char_count'] = df['comment_text'].apply(len)\n",
    "# df['char_count_ts'] = df['comment_text_s'].apply(len)\n",
    "df['char_count_s'] = df['comment_text_s'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 24)\n"
     ]
    }
   ],
   "source": [
    "df['polarity_min'] = [x[0] for x in df['polarity_sentence']]\n",
    "df['polarity_max'] = [x[1] for x in df['polarity_sentence']]\n",
    "df['polarity_mean'] = [x[2] for x in df['polarity_sentence']]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['avg_word_length'] = df['comment_text'].apply(lambda x: avg_word(x))\n",
    "df['stop_word_count'] = df['comment_text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "df['hashtag_count'] = df['comment_text'].apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "df['numeric_count'] = df['comment_text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "df['upper_count'] = df['comment_text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['comment_text_clean'] = df['comment_text'].apply(lambda x: \" \".join(x.lower() for x in x.split())).str.replace('[^\\w\\s]','').apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "article      55403\n",
      "page         45611\n",
      "wikipedia    35557\n",
      "talk         31288\n",
      "please       29607\n",
      "would        29212\n",
      "one          28057\n",
      "like         27705\n",
      "dont         26102\n",
      "see          21486\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(df['comment_text_clean']).split()).value_counts()[:10]\n",
    "print(freq)\n",
    "freq = list(freq.index)\n",
    "df['comment_text_clean'] = df['comment_text_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rasjid            1\n",
      "inexhaustible     1\n",
      "33113             1\n",
      "judaïca           1\n",
      "raucous           1\n",
      "vochen            1\n",
      "httpwwwncaacom    1\n",
      "cyn               1\n",
      "sali              1\n",
      "acceptranges      1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "freq = pd.Series(' '.join(df['comment_text_clean']).split()).value_counts()[-10:]\n",
    "print(freq)\n",
    "freq = list(freq.index)\n",
    "df['comment_text_clean'] = df['comment_text_clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import Word\n",
    "df['comment_text_clean'] = df['comment_text_clean'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['hope', 'retarded']),\n",
       " WordList(['retarded', 'kid']),\n",
       " WordList(['kid', 'get']),\n",
       " WordList(['get', 'anal']),\n",
       " WordList(['anal', 'raped']),\n",
       " WordList(['raped', 'murdered']),\n",
       " WordList(['murdered', 'fag']),\n",
       " WordList(['fag', 'father']),\n",
       " WordList(['father', 'im']),\n",
       " WordList(['im', 'gon']),\n",
       " WordList(['gon', 'na']),\n",
       " WordList(['na', 'fuck']),\n",
       " WordList(['fuck', 'fat']),\n",
       " WordList(['fat', 'wife']),\n",
       " WordList(['wife', 'trow']),\n",
       " WordList(['trow', 'bridge']),\n",
       " WordList(['bridge', 'consider']),\n",
       " WordList(['consider', 'happy']),\n",
       " WordList(['happy', 'another']),\n",
       " WordList(['another', 'useful']),\n",
       " WordList(['useful', 'editor']),\n",
       " WordList(['editor', 'wikiepia']),\n",
       " WordList(['wikiepia', 'retired']),\n",
       " WordList(['retired', 'user']),\n",
       " WordList(['user', 'retired']),\n",
       " WordList(['retired', 'everyday']),\n",
       " WordList(['everyday', 'even']),\n",
       " WordList(['even', 'dare']),\n",
       " WordList(['dare', 'removing']),\n",
       " WordList(['removing', 'peace']),\n",
       " WordList(['peace', 'shit']),\n",
       " WordList(['shit', 'ever']),\n",
       " WordList(['ever', 'fuck']),\n",
       " WordList(['fuck', 'want']),\n",
       " WordList(['want', 'report']),\n",
       " WordList(['report', 'want']),\n",
       " WordList(['want', 'old']),\n",
       " WordList(['old', 'cunt']),\n",
       " WordList(['cunt', 'longer']),\n",
       " WordList(['longer', 'give']),\n",
       " WordList(['give', 'fuck']),\n",
       " WordList(['fuck', 'fucking']),\n",
       " WordList(['fucking', 'leave']),\n",
       " WordList(['leave', 'npa']),\n",
       " WordList(['npa', 'warning']),\n",
       " WordList(['warning', 'template']),\n",
       " WordList(['template', 'block']),\n",
       " WordList(['block', 'thats']),\n",
       " WordList(['thats', 'best'])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TextBlob(df['comment_text_clean'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jew</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zimzalabim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>murder</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>st47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>going</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  tf\n",
       "0         jew   1\n",
       "1        evil   1\n",
       "2  zimzalabim   1\n",
       "3      murder   1\n",
       "4  homosexual   1\n",
       "5        st47   1\n",
       "6       going   1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = (df['comment_text_clean'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jew</td>\n",
       "      <td>1</td>\n",
       "      <td>4.657734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evil</td>\n",
       "      <td>1</td>\n",
       "      <td>5.459623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zimzalabim</td>\n",
       "      <td>1</td>\n",
       "      <td>10.593950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>murder</td>\n",
       "      <td>1</td>\n",
       "      <td>5.545698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>1</td>\n",
       "      <td>6.074882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>st47</td>\n",
       "      <td>1</td>\n",
       "      <td>9.783020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>going</td>\n",
       "      <td>1</td>\n",
       "      <td>3.171427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  tf        idf\n",
       "0         jew   1   4.657734\n",
       "1        evil   1   5.459623\n",
       "2  zimzalabim   1  10.593950\n",
       "3      murder   1   5.545698\n",
       "4  homosexual   1   6.074882\n",
       "5        st47   1   9.783020\n",
       "6       going   1   3.171427"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i,word in enumerate(tf1['words']):\n",
    "    tf1.loc[i, 'idf'] = np.log(df.shape[0]/(len(df[df['comment_text_clean'].str.contains(word)])))\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jew</td>\n",
       "      <td>1</td>\n",
       "      <td>4.657734</td>\n",
       "      <td>4.657734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>evil</td>\n",
       "      <td>1</td>\n",
       "      <td>5.459623</td>\n",
       "      <td>5.459623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zimzalabim</td>\n",
       "      <td>1</td>\n",
       "      <td>10.593950</td>\n",
       "      <td>10.593950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>murder</td>\n",
       "      <td>1</td>\n",
       "      <td>5.545698</td>\n",
       "      <td>5.545698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>homosexual</td>\n",
       "      <td>1</td>\n",
       "      <td>6.074882</td>\n",
       "      <td>6.074882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>st47</td>\n",
       "      <td>1</td>\n",
       "      <td>9.783020</td>\n",
       "      <td>9.783020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>going</td>\n",
       "      <td>1</td>\n",
       "      <td>3.171427</td>\n",
       "      <td>3.171427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  tf        idf      tfidf\n",
       "0         jew   1   4.657734   4.657734\n",
       "1        evil   1   5.459623   5.459623\n",
       "2  zimzalabim   1  10.593950  10.593950\n",
       "3      murder   1   5.545698   5.545698\n",
       "4  homosexual   1   6.074882   6.074882\n",
       "5        st47   1   9.783020   9.783020\n",
       "6       going   1   3.171427   3.171427"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2025373 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(df['comment_text_clean'])\n",
    "train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2382577 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(df['comment_text_clean'])\n",
    "train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>category</th>\n",
       "      <th>rating</th>\n",
       "      <th>...</th>\n",
       "      <th>char_count_s</th>\n",
       "      <th>polarity_min</th>\n",
       "      <th>polarity_max</th>\n",
       "      <th>polarity_mean</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>numeric_count</th>\n",
       "      <th>upper_count</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3a4c7758fad18de3</th>\n",
       "      <td>3a4c7758fad18de3</td>\n",
       "      <td>, I hope your retarded kids get anal raped and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ToSTObThInIH</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>494</td>\n",
       "      <td>-0.6000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-0.018750</td>\n",
       "      <td>4.210526</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>hope retarded kid get anal raped murdered fag ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24d2b50726b67167</th>\n",
       "      <td>24d2b50726b67167</td>\n",
       "      <td>I am going to murder ZimZalaBim ST47 for being...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ToSTObThInIH</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>going murder zimzalabim st47 evil homosexual jew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c586b7a2fd575b13</th>\n",
       "      <td>c586b7a2fd575b13</td>\n",
       "      <td>Shut up you asswipe, we don't care. I'll decap...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ToSTObThInIH</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>-0.2000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.075556</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>shut asswipe care ill decapitate mother shit h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77d84b1321c22d9a</th>\n",
       "      <td>77d84b1321c22d9a</td>\n",
       "      <td>LGBT \\n\\nyou little fuck , are you a fag , tha...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ToSTObThInIH</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>280</td>\n",
       "      <td>-0.1775</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.088750</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>lgbt little fuck fag piece shit making fucked ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368c10281978876</th>\n",
       "      <td>1368c10281978876</td>\n",
       "      <td>You're a stupid cunt \\n\\nFuck you dumb arse, y...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ToSTObThInIH</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>278</td>\n",
       "      <td>-0.4125</td>\n",
       "      <td>-0.4125</td>\n",
       "      <td>-0.412500</td>\n",
       "      <td>3.694915</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>youre stupid cunt fuck dumb arse mum hairy cun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                id  \\\n",
       "idx                                  \n",
       "3a4c7758fad18de3  3a4c7758fad18de3   \n",
       "24d2b50726b67167  24d2b50726b67167   \n",
       "c586b7a2fd575b13  c586b7a2fd575b13   \n",
       "77d84b1321c22d9a  77d84b1321c22d9a   \n",
       "1368c10281978876  1368c10281978876   \n",
       "\n",
       "                                                       comment_text  toxic  \\\n",
       "idx                                                                          \n",
       "3a4c7758fad18de3  , I hope your retarded kids get anal raped and...      1   \n",
       "24d2b50726b67167  I am going to murder ZimZalaBim ST47 for being...      1   \n",
       "c586b7a2fd575b13  Shut up you asswipe, we don't care. I'll decap...      1   \n",
       "77d84b1321c22d9a  LGBT \\n\\nyou little fuck , are you a fag , tha...      1   \n",
       "1368c10281978876  You're a stupid cunt \\n\\nFuck you dumb arse, y...      1   \n",
       "\n",
       "                  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "idx                                                                      \n",
       "3a4c7758fad18de3             1        1       1       1              1   \n",
       "24d2b50726b67167             1        1       1       1              1   \n",
       "c586b7a2fd575b13             1        1       1       1              1   \n",
       "77d84b1321c22d9a             1        1       1       1              1   \n",
       "1368c10281978876             1        1       1       1              1   \n",
       "\n",
       "                      category  rating  \\\n",
       "idx                                      \n",
       "3a4c7758fad18de3  ToSTObThInIH       6   \n",
       "24d2b50726b67167  ToSTObThInIH       6   \n",
       "c586b7a2fd575b13  ToSTObThInIH       6   \n",
       "77d84b1321c22d9a  ToSTObThInIH       6   \n",
       "1368c10281978876  ToSTObThInIH       6   \n",
       "\n",
       "                                        ...                          \\\n",
       "idx                                     ...                           \n",
       "3a4c7758fad18de3                        ...                           \n",
       "24d2b50726b67167                        ...                           \n",
       "c586b7a2fd575b13                        ...                           \n",
       "77d84b1321c22d9a                        ...                           \n",
       "1368c10281978876                        ...                           \n",
       "\n",
       "                  char_count_s polarity_min polarity_max polarity_mean  \\\n",
       "idx                                                                      \n",
       "3a4c7758fad18de3           494      -0.6000       1.0000     -0.018750   \n",
       "24d2b50726b67167            68      -1.0000      -1.0000     -1.000000   \n",
       "c586b7a2fd575b13          1000      -0.2000       0.0000     -0.075556   \n",
       "77d84b1321c22d9a           280      -0.1775       0.0000     -0.088750   \n",
       "1368c10281978876           278      -0.4125      -0.4125     -0.412500   \n",
       "\n",
       "                 avg_word_length stop_word_count  hashtag_count  \\\n",
       "idx                                                               \n",
       "3a4c7758fad18de3        4.210526              34              0   \n",
       "24d2b50726b67167        4.750000               4              0   \n",
       "c586b7a2fd575b13      161.000000               9              0   \n",
       "77d84b1321c22d9a        3.500000              32              0   \n",
       "1368c10281978876        3.694915              25              0   \n",
       "\n",
       "                  numeric_count  upper_count  \\\n",
       "idx                                            \n",
       "3a4c7758fad18de3              0            6   \n",
       "24d2b50726b67167              0            2   \n",
       "c586b7a2fd575b13              0            0   \n",
       "77d84b1321c22d9a              0            1   \n",
       "1368c10281978876              0            3   \n",
       "\n",
       "                                                 comment_text_clean  \n",
       "idx                                                                  \n",
       "3a4c7758fad18de3  hope retarded kid get anal raped murdered fag ...  \n",
       "24d2b50726b67167   going murder zimzalabim st47 evil homosexual jew  \n",
       "c586b7a2fd575b13  shut asswipe care ill decapitate mother shit h...  \n",
       "77d84b1321c22d9a  lgbt little fuck fag piece shit making fucked ...  \n",
       "1368c10281978876  youre stupid cunt fuck dumb arse mum hairy cun...  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_pickle('../data/toxictrain.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
