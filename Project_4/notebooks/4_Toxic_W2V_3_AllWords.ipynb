{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toxic: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "\n",
    "checkpoint = \"checkpoints/w2v_3allwords.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/toxictrain.pkl')\n",
    "# df = df[df['rating']>0]\n",
    "documents = [''.join(r) for r in df.comment_text]\n",
    "text = ''.join(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "text = re.sub('[^A-Za-z0-9 ]+', '',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'hope', 'your', 'retarded', 'kids', 'get', 'anal', 'raped', 'and', 'murdered', 'for', 'having', 'such', 'a', 'fag', 'as', 'a', 'father', 'im', 'gonna', 'fuck', 'your', 'fat', 'wife', 'and', 'her', 'over', 'the', 'bridge', 'consider']\n"
     ]
    }
   ],
   "source": [
    "words = utils.preprocess(text)\n",
    "print(words[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 9910700\n",
      "Unique words: 39064\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words: {}\".format(len(words)))\n",
    "print(\"Unique words: {}\".format(len(set(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_to_int, int_to_vocab = utils.create_lookup_tables(words)\n",
    "int_words = [vocab_to_int[word] for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "threshold = 1e-5\n",
    "word_counts = Counter(int_words)\n",
    "total_count = len(int_words)\n",
    "freqs = {word: count/total_count for word, count in word_counts.items()}\n",
    "p_drop = {word: 1 - np.sqrt(threshold/freqs[word]) for word in word_counts}\n",
    "train_words = [word for word in int_words if random.random() < (1 - p_drop[word])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_target(words, idx, window_size=5):\n",
    "    ''' Get a list of words in a window around an index. '''\n",
    "    \n",
    "    R = np.random.randint(1, window_size+1)\n",
    "    start = idx - R if (idx - R) > 0 else 0\n",
    "    stop = idx + R\n",
    "    target_words = set(words[start:idx] + words[idx+1:stop+1])\n",
    "    \n",
    "    return list(target_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(words, batch_size, window_size=5):\n",
    "    ''' Create a generator of word batches as a tuple (inputs, targets) '''\n",
    "    \n",
    "    n_batches = len(words)//batch_size\n",
    "    \n",
    "    # only full batches\n",
    "    words = words[:n_batches*batch_size]\n",
    "    \n",
    "    for idx in range(0, len(words), batch_size):\n",
    "        x, y = [], []\n",
    "        batch = words[idx:idx+batch_size]\n",
    "        for ii in range(len(batch)):\n",
    "            batch_x = batch[ii]\n",
    "            batch_y = get_target(batch, ii, window_size)\n",
    "            y.extend(batch_y)\n",
    "            x.extend([batch_x]*len(batch_y))\n",
    "        yield x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    inputs = tf.placeholder(tf.int32, [None], name='inputs')\n",
    "    labels = tf.placeholder(tf.int32, [None, None], name='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_vocab = len(int_to_vocab)\n",
    "n_embedding = 200 # Number of embedding features \n",
    "with train_graph.as_default():\n",
    "    embedding = tf.Variable(tf.random_uniform((n_vocab, n_embedding), -1, 1))\n",
    "    embed = tf.nn.embedding_lookup(embedding, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of negative labels to sample\n",
    "n_sampled = 100\n",
    "with train_graph.as_default():\n",
    "    softmax_w = tf.Variable(tf.truncated_normal((n_vocab, n_embedding), stddev=0.1))\n",
    "    softmax_b = tf.Variable(tf.zeros(n_vocab))\n",
    "    \n",
    "    # Calculate the loss using negative sampling\n",
    "    loss = tf.nn.sampled_softmax_loss(softmax_w, softmax_b, \n",
    "                                      labels, embed,\n",
    "                                      n_sampled, n_vocab)\n",
    "    \n",
    "    cost = tf.reduce_mean(loss)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    ## From Thushan Ganegedara's implementation\n",
    "    valid_size = 16 # Random set of words to evaluate similarity on.\n",
    "    valid_window = 100\n",
    "    # pick 8 samples from (0,100) and (1000,1100) each ranges. lower id implies more frequent \n",
    "    valid_examples = np.array(random.sample(range(valid_window), valid_size//2))\n",
    "    valid_examples = np.append(valid_examples, \n",
    "                               random.sample(range(1000,1000+valid_window), valid_size//2))\n",
    "\n",
    "    valid_dataset = tf.constant(valid_examples, dtype=tf.int32)\n",
    "    \n",
    "    # We use the cosine distance:\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embedding), 1, keep_dims=True))\n",
    "    normalized_embedding = embedding / norm\n",
    "    valid_embedding = tf.nn.embedding_lookup(normalized_embedding, valid_dataset)\n",
    "    similarity = tf.matmul(valid_embedding, tf.transpose(normalized_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If the checkpoints directory doesn't exist:\n",
    "# !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Iteration: 100 Avg. Training loss: 5.7170 0.4361 sec/batch\n",
      "Epoch 1/50 Iteration: 200 Avg. Training loss: 5.6756 0.4354 sec/batch\n",
      "Epoch 1/50 Iteration: 300 Avg. Training loss: 5.6824 0.4011 sec/batch\n",
      "Epoch 1/50 Iteration: 400 Avg. Training loss: 5.6789 0.4592 sec/batch\n",
      "Epoch 1/50 Iteration: 500 Avg. Training loss: 5.6125 0.3727 sec/batch\n",
      "Epoch 1/50 Iteration: 600 Avg. Training loss: 5.6280 0.3723 sec/batch\n",
      "Epoch 1/50 Iteration: 700 Avg. Training loss: 5.5377 0.3715 sec/batch\n",
      "Epoch 1/50 Iteration: 800 Avg. Training loss: 5.4435 0.3735 sec/batch\n",
      "Epoch 1/50 Iteration: 900 Avg. Training loss: 5.3468 0.3930 sec/batch\n",
      "Epoch 1/50 Iteration: 1000 Avg. Training loss: 5.2790 0.3690 sec/batch\n",
      "Nearest to was: separatist, interwiki, any, previous, angelina, authoritarian, threat, redirects,\n",
      "Nearest to them: with, crab, thanks, needs, chek, nixon, replaces, kwanzaa,\n",
      "Nearest to on: interest, asking, biographies, there, hits, cellpadding0styleborder1px, image, plussize,\n",
      "Nearest to not: statistic, while, library, input, frank, andor, sake, worship,\n",
      "Nearest to use: choudary, do, links, misinform, commend, randolph, revision, timein,\n",
      "Nearest to does: tip, southgate, survive, some, reinstating, rochester, exactly, metaphysical,\n",
      "Nearest to the: heroes, questions, content, please, au93, 350, problem, code,\n",
      "Nearest to but: object, reliable, vertigo, rfcu, accommodate, shutting, simply, explain,\n",
      "Nearest to poor: jr, 0642, tower, intuitive, meal, wales, withyou, boxes,\n",
      "Nearest to wonder: deceitful, motorized, hurled, silvestris, nobodies, unbearable, hominen, alongside,\n",
      "Nearest to barnstar: phone, masculinism, floquenbeam, sidney, pull, valenciano, sheikh, hose,\n",
      "Nearest to controversial: ladyummmmmmm, jayjgs, professionalism, wikipediabusiness, utterly, philip, foam, evans,\n",
      "Nearest to religion: jza, broadcast, unnacceptable, points, blair, moulton, utchey, armistice,\n",
      "Nearest to difficult: incumbent, mackintosh, regrets, restructuring, humanly, 1821, joule, refuting,\n",
      "Nearest to french: legitimate, regardsthis, revoking, news, motivated, associated, caricature, tends,\n",
      "Nearest to event: irreversible, oil, category, can, admins, guys, bugle, man,\n",
      "Epoch 1/50 Iteration: 1100 Avg. Training loss: 5.2026 0.4744 sec/batch\n",
      "Epoch 1/50 Iteration: 1200 Avg. Training loss: 5.0970 0.4955 sec/batch\n",
      "Epoch 1/50 Iteration: 1300 Avg. Training loss: 4.9971 0.4547 sec/batch\n",
      "Epoch 1/50 Iteration: 1400 Avg. Training loss: 4.9512 0.4327 sec/batch\n",
      "Epoch 1/50 Iteration: 1500 Avg. Training loss: 4.9092 0.4264 sec/batch\n",
      "Epoch 1/50 Iteration: 1600 Avg. Training loss: 4.8971 0.5202 sec/batch\n",
      "Epoch 1/50 Iteration: 1700 Avg. Training loss: 4.8567 0.4330 sec/batch\n",
      "Epoch 1/50 Iteration: 1800 Avg. Training loss: 4.8404 0.4248 sec/batch\n",
      "Epoch 1/50 Iteration: 1900 Avg. Training loss: 4.8045 0.4082 sec/batch\n",
      "Epoch 1/50 Iteration: 2000 Avg. Training loss: 4.7933 0.4291 sec/batch\n",
      "Nearest to was: separatist, interwiki, angelina, permission, 0341, finale, authoritarian, previous,\n",
      "Nearest to them: refusing, manually, infinite, replaces, with, nixon, crab, topics,\n",
      "Nearest to on: asking, interest, hits, biographies, futhermore, graciously, school, straws,\n",
      "Nearest to not: statistic, library, mildly, while, regulations, attractive, input, frank,\n",
      "Nearest to use: choudary, revision, freelicensed, links, fill, misinform, do, boilerplate,\n",
      "Nearest to does: survive, tip, southgate, reinstating, witnessed, prominence, factory, metaphysical,\n",
      "Nearest to the: heroes, au93, code, content, verifable, 350, please, basically,\n",
      "Nearest to but: shutting, complaints, object, explain, vertigo, sayingi, scandals, hadnt,\n",
      "Nearest to poor: jr, 0642, tower, wales, soft, intuitive, meal, supporting,\n",
      "Nearest to wonder: if, handling, deceitful, talkedits, alongside, hurled, failure, hominen,\n",
      "Nearest to barnstar: phone, pull, topics, floquenbeam, masculinism, valenciano, sidney, sheikh,\n",
      "Nearest to controversial: professionalism, wikipediabusiness, jayjgs, ladyummmmmmm, philip, copyright, utterly, evans,\n",
      "Nearest to religion: broadcast, unnacceptable, jza, opponents, utchey, points, blair, armistice,\n",
      "Nearest to difficult: restructuring, regrets, incumbent, humanly, 1821, tool, mackintosh, refuting,\n",
      "Nearest to french: legitimate, tends, news, regardsthis, revoking, caricature, publications, kinda,\n",
      "Nearest to event: oil, irreversible, man, category, mafia, guys, sensationalist, sax,\n",
      "Epoch 1/50 Iteration: 2100 Avg. Training loss: 4.7806 0.4715 sec/batch\n",
      "Epoch 2/50 Iteration: 2200 Avg. Training loss: 4.9829 0.2620 sec/batch\n",
      "Epoch 2/50 Iteration: 2300 Avg. Training loss: 4.7182 0.3382 sec/batch\n",
      "Epoch 2/50 Iteration: 2400 Avg. Training loss: 4.7162 0.4006 sec/batch\n",
      "Epoch 2/50 Iteration: 2500 Avg. Training loss: 4.6627 0.3835 sec/batch\n",
      "Epoch 2/50 Iteration: 2600 Avg. Training loss: 4.6542 0.4020 sec/batch\n",
      "Epoch 2/50 Iteration: 2700 Avg. Training loss: 4.6335 0.4287 sec/batch\n",
      "Epoch 2/50 Iteration: 2800 Avg. Training loss: 4.6545 0.4971 sec/batch\n",
      "Epoch 2/50 Iteration: 2900 Avg. Training loss: 4.6328 0.3810 sec/batch\n",
      "Epoch 2/50 Iteration: 3000 Avg. Training loss: 4.6153 0.4159 sec/batch\n",
      "Nearest to was: separatist, interwiki, angelina, 0341, reacting, youplease, 000, finale,\n",
      "Nearest to them: crab, kwanzaa, replaces, infinite, refusing, manually, chek, flew,\n",
      "Nearest to on: futhermore, interest, graciously, asking, biographies, cellpadding0styleborder1px, straws, perceptions,\n",
      "Nearest to not: statistic, frank, library, mildly, attractive, irresponsibly, regulations, tune,\n",
      "Nearest to use: freelicensed, choudary, boilerplate, links, revision, dropdown, fill, misinform,\n",
      "Nearest to does: survive, southgate, reinstating, tip, supposing, metaphysical, witnessed, candidacy,\n",
      "Nearest to the: verifable, au93, content, code, heroes, cdrtools, 350, og,\n",
      "Nearest to but: shutting, onscreen, complaints, vertigo, sayingi, jubilee, hadnt, rfcu,\n",
      "Nearest to poor: 0642, jr, meal, tower, wales, chemistry, intuitive, sarek,\n",
      "Nearest to wonder: hurled, deceitful, hominen, nobodies, handling, talkedits, alongside, if,\n",
      "Nearest to barnstar: phone, floquenbeam, pull, topics, masculinism, valenciano, commit, sidney,\n",
      "Nearest to controversial: jayjgs, professionalism, philip, wikipediabusiness, ladyummmmmmm, nutcase, sociopathic, firmly,\n",
      "Nearest to religion: broadcast, unnacceptable, opponents, jza, points, blair, utchey, armistice,\n",
      "Nearest to difficult: regrets, 1821, restructuring, incumbent, humanly, refuting, mackintosh, plagiarize,\n",
      "Nearest to french: legitimate, tends, revoking, regardsthis, news, caricature, wikipediawide, kite,\n",
      "Nearest to event: irreversible, sax, oil, banu, sensationalist, mafia, bugle, man,\n",
      "Epoch 2/50 Iteration: 3100 Avg. Training loss: 4.6032 0.3817 sec/batch\n",
      "Epoch 2/50 Iteration: 3200 Avg. Training loss: 4.6187 0.3248 sec/batch\n",
      "Epoch 2/50 Iteration: 3300 Avg. Training loss: 4.5985 0.4702 sec/batch\n",
      "Epoch 2/50 Iteration: 3400 Avg. Training loss: 4.5898 0.4236 sec/batch\n",
      "Epoch 2/50 Iteration: 3500 Avg. Training loss: 4.5909 0.4867 sec/batch\n",
      "Epoch 2/50 Iteration: 3600 Avg. Training loss: 4.6062 0.4025 sec/batch\n",
      "Epoch 2/50 Iteration: 3700 Avg. Training loss: 4.5896 0.4194 sec/batch\n",
      "Epoch 2/50 Iteration: 3800 Avg. Training loss: 4.5889 0.4304 sec/batch\n",
      "Epoch 2/50 Iteration: 3900 Avg. Training loss: 4.5903 0.4026 sec/batch\n",
      "Epoch 2/50 Iteration: 4000 Avg. Training loss: 4.5910 0.4421 sec/batch\n",
      "Nearest to was: separatist, interwiki, angelina, reacting, 0341, youplease, cyde, 123222396,\n",
      "Nearest to them: kwanzaa, infinite, flew, chek, crab, concerning, replaces, manually,\n",
      "Nearest to on: futhermore, graciously, biographies, interest, asking, straws, clicking, cellpadding0styleborder1px,\n",
      "Nearest to not: statistic, library, attractive, mildly, irresponsibly, tune, workthe, frank,\n",
      "Nearest to use: freelicensed, boilerplate, uploading, choudary, links, nonfree, dropdown, misinform,\n",
      "Nearest to does: southgate, survive, reinstating, tip, supposing, candidacy, rochester, factory,\n",
      "Nearest to the: verifable, au93, content, heroes, code, empathize, 0351, cdrtools,\n",
      "Nearest to but: shutting, jubilee, vertigo, onscreen, complaints, explain, hadnt, appalled,\n",
      "Nearest to poor: 0642, jr, meal, soft, saltlake, fourteen, skit, sarek,\n",
      "Nearest to wonder: hurled, hominen, deceitful, nobodies, handling, motorized, still, unbearable,\n",
      "Nearest to barnstar: floquenbeam, pull, phone, topics, masculinism, semantic, valenciano, cause,\n",
      "Nearest to controversial: jayjgs, philip, ladyummmmmmm, professionalism, foam, wikipediabusiness, sociopathic, indiscriminately,\n",
      "Nearest to religion: broadcast, unnacceptable, jza, immortality, armistice, points, opponents, durin,\n",
      "Nearest to difficult: regrets, 1821, restructuring, incumbent, humanly, smoked, 29th, refuting,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest to french: regardsthis, revoking, tends, legitimate, wikipediawide, news, italic, bumper,\n",
      "Nearest to event: irreversible, sax, banu, oil, sensationalist, mafia, russian, bugle,\n",
      "Epoch 2/50 Iteration: 4100 Avg. Training loss: 4.5987 0.4149 sec/batch\n",
      "Epoch 2/50 Iteration: 4200 Avg. Training loss: 4.5783 0.3415 sec/batch\n",
      "Epoch 3/50 Iteration: 4300 Avg. Training loss: 4.5726 0.1038 sec/batch\n",
      "Epoch 3/50 Iteration: 4400 Avg. Training loss: 4.5126 0.3497 sec/batch\n",
      "Epoch 3/50 Iteration: 4500 Avg. Training loss: 4.4956 0.3290 sec/batch\n",
      "Epoch 3/50 Iteration: 4600 Avg. Training loss: 4.5323 0.3260 sec/batch\n",
      "Epoch 3/50 Iteration: 4700 Avg. Training loss: 4.5024 0.3452 sec/batch\n",
      "Epoch 3/50 Iteration: 4800 Avg. Training loss: 4.4706 0.3084 sec/batch\n",
      "Epoch 3/50 Iteration: 4900 Avg. Training loss: 4.5011 0.3064 sec/batch\n",
      "Epoch 3/50 Iteration: 5000 Avg. Training loss: 4.4848 0.3576 sec/batch\n",
      "Nearest to was: interwiki, separatist, angelina, 0341, reacting, authoritarian, 123222396, anyone,\n",
      "Nearest to them: kwanzaa, flew, chek, infinite, crab, concerning, 1513, 700,\n",
      "Nearest to on: interest, futhermore, graciously, biographies, cellpadding0styleborder1px, asking, clicking, straws,\n",
      "Nearest to not: statistic, subjects, workthe, mildly, frank, irresponsibly, tune, guidelinesfor,\n",
      "Nearest to use: freelicensed, boilerplate, uploading, choudary, nonfree, links, dropdown, delist,\n",
      "Nearest to does: southgate, survive, candidacy, reinstating, dispatched, rochester, tip, supposing,\n",
      "Nearest to the: verifable, content, au93, empathize, code, cdrtools, heroes, samantha,\n",
      "Nearest to but: shutting, jubilee, labyrinth, vertigo, appalled, welcomeand, onscreen, explain,\n",
      "Nearest to poor: 0642, jr, soft, druids, saltlake, skit, espinola, pitfalls,\n",
      "Nearest to wonder: hominen, hurled, deceitful, nobodies, unbearable, handling, still, vigilant,\n",
      "Nearest to barnstar: floquenbeam, pull, topics, phone, masculinism, valenciano, cause, semantic,\n",
      "Nearest to controversial: jayjgs, foam, ladyummmmmmm, philip, vivekananda, indiscriminately, ashton, angevin,\n",
      "Nearest to religion: unnacceptable, immortality, broadcast, jza, armistice, durin, opponents, points,\n",
      "Nearest to difficult: regrets, restructuring, 1821, wpstub, smoked, humanly, incumbent, refuting,\n",
      "Nearest to french: regardsthis, revoking, wikipediawide, tends, italic, legitimate, news, bumper,\n",
      "Nearest to event: irreversible, banu, sax, oil, mafia, sensationalist, russian, bugle,\n",
      "Epoch 3/50 Iteration: 5100 Avg. Training loss: 4.4675 0.3540 sec/batch\n",
      "Epoch 3/50 Iteration: 5200 Avg. Training loss: 4.4961 0.3301 sec/batch\n",
      "Epoch 3/50 Iteration: 5300 Avg. Training loss: 4.4889 0.3120 sec/batch\n",
      "Epoch 3/50 Iteration: 5400 Avg. Training loss: 4.4862 0.3478 sec/batch\n",
      "Epoch 3/50 Iteration: 5500 Avg. Training loss: 4.4752 0.4052 sec/batch\n",
      "Epoch 3/50 Iteration: 5600 Avg. Training loss: 4.4746 0.3587 sec/batch\n",
      "Epoch 3/50 Iteration: 5700 Avg. Training loss: 4.4798 0.3561 sec/batch\n",
      "Epoch 3/50 Iteration: 5800 Avg. Training loss: 4.4589 0.3222 sec/batch\n",
      "Epoch 3/50 Iteration: 5900 Avg. Training loss: 4.4556 0.4062 sec/batch\n",
      "Epoch 3/50 Iteration: 6000 Avg. Training loss: 4.4659 0.4555 sec/batch\n",
      "Nearest to was: interwiki, angelina, separatist, reacting, 0341, 123222396, youplease, cyde,\n",
      "Nearest to them: kwanzaa, concerning, flew, templatenameplease, chek, 1513, topalov, replaces,\n",
      "Nearest to on: futhermore, biographies, graciously, clicking, interest, there, cellpadding0styleborder1px, asking,\n",
      "Nearest to not: statistic, subjects, mildly, guidelinesfor, inspect, workthe, frank, irresponsibly,\n",
      "Nearest to use: freelicensed, uploading, boilerplate, fairuse, nonfree, dropdown, checking, tagsfairuse,\n",
      "Nearest to does: southgate, deleted, candidacy, factory, dispatched, survive, reinstating, supposing,\n",
      "Nearest to the: verifable, content, 0351, substantial, empathize, db, code, please,\n",
      "Nearest to but: jubilee, welcomeand, shutting, enhances, appalled, complaints, vertigo, onscreen,\n",
      "Nearest to poor: 0642, skit, soft, espinola, druids, jr, saltlake, meal,\n",
      "Nearest to wonder: hominen, hurled, deceitful, unbearable, nobodies, handling, still, manga,\n",
      "Nearest to barnstar: floquenbeam, pull, topics, phone, masculinism, cause, valenciano, hose,\n",
      "Nearest to controversial: jayjgs, foam, indiscriminately, ladyummmmmmm, vivekananda, nutcase, philip, trp,\n",
      "Nearest to religion: immortality, unnacceptable, broadcast, opponents, durin, industrialized, armistice, points,\n",
      "Nearest to difficult: regrets, restructuring, smoked, wpstub, incumbent, 1821, refuting, humanly,\n",
      "Nearest to french: regardsthis, revoking, tends, wikipediawide, autobio, italic, chiefs, italians,\n",
      "Nearest to event: irreversible, banu, sax, oil, mafia, sensationalist, russian, professed,\n",
      "Epoch 3/50 Iteration: 6100 Avg. Training loss: 4.4606 0.5150 sec/batch\n",
      "Epoch 3/50 Iteration: 6200 Avg. Training loss: 4.4325 0.5655 sec/batch\n",
      "Epoch 3/50 Iteration: 6300 Avg. Training loss: 4.4782 0.5399 sec/batch\n",
      "Epoch 3/50 Iteration: 6400 Avg. Training loss: 4.4692 0.5366 sec/batch\n",
      "Epoch 4/50 Iteration: 6500 Avg. Training loss: 4.2557 0.3763 sec/batch\n",
      "Epoch 4/50 Iteration: 6600 Avg. Training loss: 4.3581 0.4623 sec/batch\n",
      "Epoch 4/50 Iteration: 6700 Avg. Training loss: 4.4145 0.5047 sec/batch\n",
      "Epoch 4/50 Iteration: 6800 Avg. Training loss: 4.4205 0.5742 sec/batch\n",
      "Epoch 4/50 Iteration: 6900 Avg. Training loss: 4.3992 0.5175 sec/batch\n",
      "Epoch 4/50 Iteration: 7000 Avg. Training loss: 4.4025 0.4728 sec/batch\n",
      "Nearest to was: interwiki, angelina, separatist, 0341, reacting, youplease, authoritarian, 123222396,\n",
      "Nearest to them: kwanzaa, concerning, templatenameplease, flew, chek, topalov, abrams, infinite,\n",
      "Nearest to on: cellpadding0styleborder1px, clicking, biographies, futhermore, interest, graciously, there, four,\n",
      "Nearest to not: statistic, subjects, frank, mildly, workthe, stp, inspect, irresponsibly,\n",
      "Nearest to use: uploading, freelicensed, boilerplate, fairuse, nonfree, links, fair, misinform,\n",
      "Nearest to does: southgate, dispatched, deleted, candidacy, reinstating, rochester, survive, supposing,\n",
      "Nearest to the: verifable, content, db, 0351, substantial, please, pejorative, code,\n",
      "Nearest to but: welcomeand, shutting, jubilee, vertigo, crossmr, enhances, appalled, hadnt,\n",
      "Nearest to poor: soft, 0642, skit, espinola, fourteen, druids, jr, saltlake,\n",
      "Nearest to wonder: hominen, deceitful, hurled, unbearable, still, nobodies, talkedits, handling,\n",
      "Nearest to barnstar: floquenbeam, pull, phone, masculinism, topics, cause, valenciano, semantic,\n",
      "Nearest to controversial: jayjgs, vivekananda, ladyummmmmmm, foam, indiscriminately, ashton, philip, jyllandsposten,\n",
      "Nearest to religion: immortality, unnacceptable, opponents, durin, industrialized, broadcast, armistice, points,\n",
      "Nearest to difficult: regrets, restructuring, smoked, 1821, wpstub, platforms, refuting, humanly,\n",
      "Nearest to french: regardsthis, revoking, tends, italians, wikipediawide, carta, italic, chiefs,\n",
      "Nearest to event: irreversible, sax, banu, oil, mafia, sensationalist, professed, russian,\n",
      "Epoch 4/50 Iteration: 7100 Avg. Training loss: 4.4074 0.5114 sec/batch\n",
      "Epoch 4/50 Iteration: 7200 Avg. Training loss: 4.4136 0.3806 sec/batch\n",
      "Epoch 4/50 Iteration: 7300 Avg. Training loss: 4.3776 0.3704 sec/batch\n",
      "Epoch 4/50 Iteration: 7400 Avg. Training loss: 4.4033 0.3565 sec/batch\n",
      "Epoch 4/50 Iteration: 7500 Avg. Training loss: 4.4043 0.3621 sec/batch\n",
      "Epoch 4/50 Iteration: 7600 Avg. Training loss: 4.3873 0.4351 sec/batch\n",
      "Epoch 4/50 Iteration: 7700 Avg. Training loss: 4.3628 0.4635 sec/batch\n",
      "Epoch 4/50 Iteration: 7800 Avg. Training loss: 4.4227 0.4084 sec/batch\n",
      "Epoch 4/50 Iteration: 7900 Avg. Training loss: 4.3845 0.3570 sec/batch\n",
      "Epoch 4/50 Iteration: 8000 Avg. Training loss: 4.3866 0.3813 sec/batch\n",
      "Nearest to was: interwiki, reacting, angelina, separatist, 0341, authoritarian, 123222396, youplease,\n",
      "Nearest to them: concerning, kwanzaa, templatenameplease, flew, topalov, abrams, chek, manually,\n",
      "Nearest to on: biographies, cellpadding0styleborder1px, futhermore, clicking, graciously, interest, there, four,\n",
      "Nearest to not: statistic, subjects, workthe, stp, frank, mildly, inspect, repeated,\n",
      "Nearest to use: uploading, freelicensed, boilerplate, fairuse, nonfree, fair, tagsfairuse, replacement,\n",
      "Nearest to does: deleted, southgate, dispatched, candidacy, basic, reinstating, included, supposing,\n",
      "Nearest to the: verifable, content, please, db, substantial, 0351, inuniverse, questions,\n",
      "Nearest to but: jubilee, welcomeand, vertigo, crossmr, shutting, enhances, colective, hadnt,\n",
      "Nearest to poor: soft, 0642, skit, espinola, meal, druids, fourteen, contrast,\n",
      "Nearest to wonder: deceitful, hominen, hurled, unbearable, nobodies, still, talkedits, handling,\n",
      "Nearest to barnstar: floquenbeam, tireless, phone, pull, topics, masculinism, cause, hereby,\n",
      "Nearest to controversial: jayjgs, indiscriminately, vivekananda, foam, ladyummmmmmm, utterly, solus, infamous,\n",
      "Nearest to religion: unnacceptable, immortality, opponents, industrialized, behe, corpses, durin, adherents,\n",
      "Nearest to difficult: regrets, restructuring, smoked, 1821, wpstub, platforms, refuting, futility,\n",
      "Nearest to french: regardsthis, italians, revoking, carta, tends, wikipediawide, crowns, italic,\n",
      "Nearest to event: irreversible, banu, sax, oil, russian, sensationalist, mafia, professed,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 Iteration: 8100 Avg. Training loss: 4.3629 0.4409 sec/batch\n",
      "Epoch 4/50 Iteration: 8200 Avg. Training loss: 4.4166 0.4720 sec/batch\n",
      "Epoch 4/50 Iteration: 8300 Avg. Training loss: 4.3697 0.4894 sec/batch\n",
      "Epoch 4/50 Iteration: 8400 Avg. Training loss: 4.3987 0.5439 sec/batch\n",
      "Epoch 4/50 Iteration: 8500 Avg. Training loss: 4.3627 0.4194 sec/batch\n",
      "Epoch 5/50 Iteration: 8600 Avg. Training loss: 4.1120 0.1973 sec/batch\n",
      "Epoch 5/50 Iteration: 8700 Avg. Training loss: 4.2411 0.4346 sec/batch\n",
      "Epoch 5/50 Iteration: 8800 Avg. Training loss: 4.3159 0.4226 sec/batch\n",
      "Epoch 5/50 Iteration: 8900 Avg. Training loss: 4.3436 0.4117 sec/batch\n",
      "Epoch 5/50 Iteration: 9000 Avg. Training loss: 4.3210 0.5499 sec/batch\n",
      "Nearest to was: interwiki, angelina, reacting, 0341, separatist, 123222396, times, finale,\n",
      "Nearest to them: concerning, kwanzaa, flew, templatenameplease, abrams, 700, 1513, untagged,\n",
      "Nearest to on: cellpadding0styleborder1px, biographies, futhermore, graciously, four, interest, there, clicking,\n",
      "Nearest to not: statistic, mildly, subjects, frank, stp, workthe, irresponsibly, placethis,\n",
      "Nearest to use: uploading, freelicensed, boilerplate, fairuse, nonfree, fair, wikipediause, replacement,\n",
      "Nearest to does: southgate, deleted, dispatched, supposing, reinstating, amature, candidacy, wpredflag,\n",
      "Nearest to the: verifable, please, db, content, substantial, unwittingly, inuniverse, detect,\n",
      "Nearest to but: vertigo, welcomeand, jubilee, crossmr, shutting, labyrinth, enhances, colective,\n",
      "Nearest to poor: 0642, soft, druids, espinola, rumble, meal, skit, gimme,\n",
      "Nearest to wonder: deceitful, unbearable, hominen, still, hurled, talkedits, 1800z, manic,\n",
      "Nearest to barnstar: tireless, floquenbeam, hereby, pull, phone, cause, semantic, topics,\n",
      "Nearest to controversial: jayjgs, indiscriminately, vivekananda, ladyummmmmmm, solus, ashton, utterly, infamous,\n",
      "Nearest to religion: opponents, unnacceptable, industrialized, behe, immortality, adherents, abandoning, clerics,\n",
      "Nearest to difficult: restructuring, regrets, 1821, refuting, smoked, futility, platforms, wpstub,\n",
      "Nearest to french: italians, carta, regardsthis, wikipediawide, revoking, tends, crowns, italic,\n",
      "Nearest to event: irreversible, sax, oil, banu, russian, messianic, mafia, sensationalist,\n",
      "Epoch 5/50 Iteration: 9100 Avg. Training loss: 4.3304 0.4821 sec/batch\n",
      "Epoch 5/50 Iteration: 9900 Avg. Training loss: 4.3251 0.3302 sec/batch\n",
      "Epoch 5/50 Iteration: 10000 Avg. Training loss: 4.3301 0.3386 sec/batch\n",
      "Nearest to was: interwiki, angelina, reacting, collectible, 0341, times, separatist, 123222396,\n",
      "Nearest to them: concerning, kwanzaa, templatenameplease, untagged, flew, abrams, 1513, 700,\n",
      "Nearest to on: biographies, futhermore, cellpadding0styleborder1px, there, graciously, interest, four, clicking,\n",
      "Nearest to not: subjects, statistic, stp, workthe, irresponsibly, mildly, frank, that,\n",
      "Nearest to use: uploading, boilerplate, fairuse, freelicensed, nonfree, wikipediause, fair, tagsfairuse,\n",
      "Nearest to does: deleted, southgate, included, basic, reinstating, amature, candidacy, dispatched,\n",
      "Nearest to the: verifable, content, please, db, substantial, detect, be, code,\n",
      "Nearest to but: jubilee, vertigo, crossmr, welcomeand, colective, shutting, simply, labyrinth,\n",
      "Nearest to poor: soft, meal, 0642, rumble, pitfalls, druids, espinola, withyou,\n",
      "Nearest to wonder: deceitful, hominen, unbearable, hurled, talkedits, manic, still, handling,\n",
      "Nearest to barnstar: tireless, hereby, floquenbeam, topics, phone, wanna, hose, pull,\n",
      "Nearest to controversial: jayjgs, indiscriminately, vivekananda, solus, ladyummmmmmm, utterly, jyllandsposten, infamous,\n",
      "Nearest to religion: unnacceptable, behe, opponents, industrialized, adherents, immortality, clerics, religious,\n",
      "Nearest to difficult: restructuring, regrets, smoked, wpstub, refuting, futility, akhilleus, platforms,\n",
      "Nearest to french: italians, carta, regardsthis, tends, revoking, quoted, wikipediawide, italic,\n",
      "Nearest to event: irreversible, sax, banu, oil, russian, 98, professed, messianic,\n",
      "Epoch 5/50 Iteration: 10100 Avg. Training loss: 4.3487 0.3444 sec/batch\n",
      "Epoch 5/50 Iteration: 10200 Avg. Training loss: 4.3188 0.3239 sec/batch\n",
      "Epoch 5/50 Iteration: 10300 Avg. Training loss: 4.3170 0.3395 sec/batch\n",
      "Epoch 5/50 Iteration: 10400 Avg. Training loss: 4.3467 0.3163 sec/batch\n",
      "Epoch 5/50 Iteration: 10500 Avg. Training loss: 4.3249 0.2984 sec/batch\n",
      "Epoch 5/50 Iteration: 10600 Avg. Training loss: 4.3270 0.2818 sec/batch\n",
      "Epoch 6/50 Iteration: 10700 Avg. Training loss: 4.1110 0.0647 sec/batch\n",
      "Epoch 6/50 Iteration: 10800 Avg. Training loss: 4.0579 0.3030 sec/batch\n",
      "Epoch 6/50 Iteration: 10900 Avg. Training loss: 4.2323 0.3144 sec/batch\n",
      "Epoch 6/50 Iteration: 11000 Avg. Training loss: 4.2973 0.3217 sec/batch\n",
      "Nearest to was: interwiki, angelina, 0341, reacting, times, 123222396, separatist, collectible,\n",
      "Nearest to them: concerning, kwanzaa, templatenameplease, untagged, flew, abrams, convinces, lacking,\n",
      "Nearest to on: biographies, futhermore, cellpadding0styleborder1px, four, tutoriali, graciously, there, interest,\n",
      "Nearest to not: statistic, irresponsibly, frank, stp, that, mildly, subjects, placethis,\n",
      "Nearest to use: uploading, boilerplate, fairuse, freelicensed, nonfree, wikipediause, fair, replacement,\n",
      "Nearest to does: deleted, southgate, amature, reinstating, supposing, ribbon, basic, included,\n",
      "Nearest to the: please, verifable, content, db, one, detect, unwittingly, questions,\n",
      "Nearest to but: jubilee, crossmr, welcomeand, vertigo, 5i, pretty, enhances, labyrinth,\n",
      "Nearest to poor: 0642, soft, meal, rumble, gimme, druids, skit, espinola,\n",
      "Nearest to wonder: deceitful, hominen, unbearable, hurled, talkedits, still, manic, 1800z,\n",
      "Nearest to barnstar: tireless, hereby, floquenbeam, wanna, pull, phone, talkpages, semantic,\n",
      "Nearest to controversial: jayjgs, vivekananda, indiscriminately, solus, utterly, ladyummmmmmm, infamous, cheerio,\n",
      "Nearest to religion: unnacceptable, industrialized, opponents, behe, adherents, religious, immortality, corpses,\n",
      "Nearest to difficult: restructuring, regrets, futility, refuting, smoked, 1821, wpstub, akhilleus,\n",
      "Nearest to french: italians, carta, regardsthis, crowns, revoking, wikipediawide, italic, uniting,\n",
      "Nearest to event: irreversible, sax, oil, banu, 98, russian, messianic, professed,\n",
      "Epoch 6/50 Iteration: 11100 Avg. Training loss: 4.2936 0.3107 sec/batch\n",
      "Epoch 6/50 Iteration: 11200 Avg. Training loss: 4.2467 0.2755 sec/batch\n",
      "Epoch 6/50 Iteration: 11300 Avg. Training loss: 4.3070 0.2767 sec/batch\n",
      "Epoch 6/50 Iteration: 11400 Avg. Training loss: 4.2937 0.2789 sec/batch\n",
      "Epoch 6/50 Iteration: 11500 Avg. Training loss: 4.2766 0.2779 sec/batch\n",
      "Epoch 6/50 Iteration: 11600 Avg. Training loss: 4.2760 0.2737 sec/batch\n",
      "Epoch 6/50 Iteration: 11700 Avg. Training loss: 4.2996 0.2775 sec/batch\n",
      "Epoch 6/50 Iteration: 11800 Avg. Training loss: 4.2729 0.2851 sec/batch\n",
      "Epoch 6/50 Iteration: 11900 Avg. Training loss: 4.2760 0.2940 sec/batch\n",
      "Epoch 6/50 Iteration: 12000 Avg. Training loss: 4.3001 0.3305 sec/batch\n",
      "Nearest to was: interwiki, angelina, reacting, 0341, times, collectible, separatist, capitalize,\n",
      "Nearest to them: untagged, concerning, templatenameplease, kwanzaa, flew, 1513, abrams, lacking,\n",
      "Nearest to on: biographies, four, futhermore, interest, cellpadding0styleborder1px, tutoriali, produce, there,\n",
      "Nearest to not: subjects, statistic, mildly, workthe, frank, stp, well, irresponsibly,\n",
      "Nearest to use: uploading, fairuse, boilerplate, freelicensed, fair, wikipediause, nonfree, include,\n",
      "Nearest to does: deleted, included, southgate, basic, wpredflag, amature, reinstating, candidacy,\n",
      "Nearest to the: please, content, db, one, verifable, substantial, questions, detect,\n",
      "Nearest to but: welcomeand, jubilee, vertigo, 5i, crossmr, labyrinth, colective, enhances,\n",
      "Nearest to poor: soft, meal, 0642, rumble, pitfalls, gimme, druids, contrast,\n",
      "Nearest to wonder: deceitful, unbearable, hominen, talkedits, handling, hurled, still, manic,\n",
      "Nearest to barnstar: tireless, hereby, floquenbeam, talkpages, churn, wanna, hose, phone,\n",
      "Nearest to controversial: jayjgs, vivekananda, indiscriminately, solus, utterly, hovind, ladyummmmmmm, cheerio,\n",
      "Nearest to religion: behe, industrialized, unnacceptable, opponents, adherents, religious, clerics, litmus,\n",
      "Nearest to difficult: restructuring, regrets, futility, refuting, smoked, akhilleus, 1821, referral,\n",
      "Nearest to french: italians, regardsthis, carta, crowns, troop, italic, quoted, wikipediawide,\n",
      "Nearest to event: irreversible, sax, oil, banu, 98, mafia, laurier, arafat,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 Iteration: 12100 Avg. Training loss: 4.2972 0.2972 sec/batch\n",
      "Epoch 6/50 Iteration: 12200 Avg. Training loss: 4.2788 0.2914 sec/batch\n",
      "Epoch 6/50 Iteration: 12300 Avg. Training loss: 4.3111 0.2808 sec/batch\n",
      "Epoch 6/50 Iteration: 12400 Avg. Training loss: 4.2884 0.2656 sec/batch\n",
      "Epoch 6/50 Iteration: 12500 Avg. Training loss: 4.2770 0.2662 sec/batch\n",
      "Epoch 6/50 Iteration: 12600 Avg. Training loss: 4.2668 0.2686 sec/batch\n",
      "Epoch 6/50 Iteration: 12700 Avg. Training loss: 4.2567 0.2693 sec/batch\n",
      "Epoch 6/50 Iteration: 12800 Avg. Training loss: 4.2458 0.2716 sec/batch\n",
      "Epoch 7/50 Iteration: 12900 Avg. Training loss: 3.8080 0.2179 sec/batch\n",
      "Epoch 7/50 Iteration: 13000 Avg. Training loss: 4.1126 5.6237 sec/batch\n",
      "Nearest to was: angelina, 0341, reacting, times, interwiki, because, 123222396, collectible,\n",
      "Nearest to them: concerning, untagged, templatenameplease, kwanzaa, it, sina, flew, orgy,\n",
      "Nearest to on: biographies, arcade, futhermore, tutoriali, cellpadding0styleborder1px, there, interest, graciously,\n",
      "Nearest to not: statistic, well, subjects, stp, mildly, try, skunk, protective,\n",
      "Nearest to use: uploading, fairuse, boilerplate, freelicensed, nonfree, wikipediause, fair, wpnfcc,\n",
      "Nearest to does: deleted, amature, supposing, southgate, wpredflag, ribbon, hom, included,\n",
      "Nearest to the: one, please, unwittingly, be, db, detect, if, pejorative,\n",
      "Nearest to but: crossmr, jubilee, welcomeand, 5i, vertigo, labyrinth, friendsi, person,\n",
      "Nearest to poor: soft, 0642, meal, rumble, gimme, druids, pitfalls, espinola,\n",
      "Nearest to wonder: deceitful, hominen, unbearable, talkedits, still, hurled, manic, intrusion,\n",
      "Nearest to barnstar: tireless, hereby, wanna, floquenbeam, talkpages, churn, scared, booey,\n",
      "Nearest to controversial: jayjgs, hovind, indiscriminately, vivekananda, solus, jyllandsposten, utterly, archeology,\n",
      "Nearest to religion: behe, industrialized, unnacceptable, litmus, religious, opponents, adherents, subjective,\n",
      "Nearest to difficult: restructuring, futility, refuting, 1821, smoked, regrets, akhilleus, fowlers,\n",
      "Nearest to french: italians, carta, crowns, regardsthis, italic, uniting, facial, troop,\n",
      "Nearest to event: irreversible, sax, oil, banu, furries, aesthetically, 98, arafat,\n",
      "Epoch 7/50 Iteration: 13100 Avg. Training loss: 4.2597 0.3899 sec/batch\n",
      "Epoch 7/50 Iteration: 13200 Avg. Training loss: 4.2548 0.3936 sec/batch\n",
      "Epoch 7/50 Iteration: 13300 Avg. Training loss: 4.2490 0.3491 sec/batch\n",
      "Epoch 7/50 Iteration: 13400 Avg. Training loss: 4.2253 0.2977 sec/batch\n",
      "Epoch 7/50 Iteration: 13500 Avg. Training loss: 4.2412 0.3478 sec/batch\n",
      "Epoch 7/50 Iteration: 13600 Avg. Training loss: 4.2342 0.3278 sec/batch\n",
      "Epoch 7/50 Iteration: 13700 Avg. Training loss: 4.2623 0.3090 sec/batch\n",
      "Epoch 7/50 Iteration: 13800 Avg. Training loss: 4.2416 0.3134 sec/batch\n",
      "Epoch 7/50 Iteration: 13900 Avg. Training loss: 4.2663 0.2984 sec/batch\n",
      "Epoch 7/50 Iteration: 14000 Avg. Training loss: 4.2064 0.2992 sec/batch\n",
      "Nearest to was: angelina, interwiki, times, reacting, collectible, 0341, capitalize, visiting,\n",
      "Nearest to them: untagged, templatenameplease, concerning, kwanzaa, flew, gazetteer, abrams, they,\n",
      "Nearest to on: four, biographies, interest, futhermore, cellpadding0styleborder1px, tutoriali, check, fontsize85,\n",
      "Nearest to not: subjects, statistic, well, mildly, donaire, frank, stp, workthe,\n",
      "Nearest to use: uploading, fairuse, boilerplate, nonfree, wikipediause, freelicensed, wpnfcc, fair,\n",
      "Nearest to does: deleted, included, basic, southgate, wpredflag, dictionaries, ribbon, unavailable,\n",
      "Nearest to the: please, one, substantial, db, questions, content, be, would,\n",
      "Nearest to but: 5i, crossmr, welcomeand, labyrinth, vertigo, enhances, person, jubilee,\n",
      "Nearest to poor: soft, meal, rumble, 0642, gimme, pitfalls, druids, aholes,\n",
      "Nearest to wonder: deceitful, hominen, unbearable, talkedits, intrusion, irony, 1800z, godwin,\n",
      "Nearest to barnstar: tireless, hereby, wanna, talkpages, floquenbeam, antivandalism, award, booey,\n",
      "Nearest to controversial: jayjgs, hovind, vivekananda, indiscriminately, solus, jyllandsposten, infamous, cheerio,\n",
      "Nearest to religion: behe, industrialized, litmus, religious, unnacceptable, opponents, adherents, clerics,\n",
      "Nearest to difficult: restructuring, futility, refuting, smoked, 1821, fowlers, regrets, hazrat,\n",
      "Nearest to french: italians, crowns, regardsthis, carta, troop, uniting, clearance, italic,\n",
      "Nearest to event: irreversible, sax, oil, banu, furries, aesthetically, 98, mafia,\n",
      "Epoch 7/50 Iteration: 14100 Avg. Training loss: 4.2184 0.3041 sec/batch\n",
      "Epoch 7/50 Iteration: 14200 Avg. Training loss: 4.2254 0.2975 sec/batch\n",
      "Epoch 7/50 Iteration: 14300 Avg. Training loss: 4.2650 0.3085 sec/batch\n",
      "Epoch 7/50 Iteration: 14400 Avg. Training loss: 4.2656 0.2997 sec/batch\n",
      "Epoch 7/50 Iteration: 14500 Avg. Training loss: 4.2041 0.2993 sec/batch\n",
      "Epoch 7/50 Iteration: 14600 Avg. Training loss: 4.2832 0.3049 sec/batch\n",
      "Epoch 7/50 Iteration: 14700 Avg. Training loss: 4.2401 0.2997 sec/batch\n",
      "Epoch 7/50 Iteration: 14800 Avg. Training loss: 4.2582 0.2991 sec/batch\n",
      "Epoch 7/50 Iteration: 14900 Avg. Training loss: 4.2435 0.2815 sec/batch\n",
      "Epoch 8/50 Iteration: 15000 Avg. Training loss: 3.8167 0.1356 sec/batch\n",
      "Nearest to was: angelina, times, interwiki, 0341, collectible, 123222396, capitalize, reacting,\n",
      "Nearest to them: untagged, templatenameplease, concerning, kwanzaa, they, orgy, commonsthe, it,\n",
      "Nearest to on: biographies, four, interest, tutoriali, futhermore, cellpadding0styleborder1px, clicking, check,\n",
      "Nearest to not: subjects, stp, well, statistic, donaire, talkspeedy, itspeedy, placethis,\n",
      "Nearest to use: uploading, fairuse, boilerplate, nonfree, freelicensed, fair, or, wikipediause,\n",
      "Nearest to does: deleted, included, wpredflag, ribbon, southgate, hom, amature, supposing,\n",
      "Nearest to the: please, one, db, substantial, be, unwittingly, if, questions,\n",
      "Nearest to but: crossmr, 5i, welcomeand, enhances, vertigo, remit, merchandise, labyrinth,\n",
      "Nearest to poor: soft, 0642, rumble, meal, gimme, druids, pitfalls, aholes,\n",
      "Nearest to wonder: deceitful, hominen, unbearable, talkedits, intrusion, irony, looki, 1800z,\n",
      "Nearest to barnstar: tireless, hereby, wanna, antivandalism, award, talkpages, kindness, booey,\n",
      "Nearest to controversial: jayjgs, hovind, vivekananda, indiscriminately, jyllandsposten, solus, archeology, ladyummmmmmm,\n",
      "Nearest to religion: behe, litmus, industrialized, religious, unnacceptable, adherents, subjective, sects,\n",
      "Nearest to difficult: restructuring, futility, refuting, smoked, 1821, fowlers, regrets, hazrat,\n",
      "Nearest to french: italians, crowns, carta, troop, uniting, facial, regardsthis, bore,\n",
      "Nearest to event: sax, irreversible, oil, furries, banu, 98, povi, mafia,\n",
      "Epoch 8/50 Iteration: 15100 Avg. Training loss: 4.0251 0.2774 sec/batch\n",
      "Epoch 8/50 Iteration: 15200 Avg. Training loss: 4.1882 0.2800 sec/batch\n",
      "Epoch 8/50 Iteration: 15300 Avg. Training loss: 4.2070 0.2858 sec/batch\n",
      "Epoch 8/50 Iteration: 15400 Avg. Training loss: 4.2222 0.2843 sec/batch\n",
      "Epoch 8/50 Iteration: 15500 Avg. Training loss: 4.1818 0.2907 sec/batch\n",
      "Epoch 8/50 Iteration: 15600 Avg. Training loss: 4.2150 0.2840 sec/batch\n",
      "Epoch 8/50 Iteration: 15700 Avg. Training loss: 4.1971 0.2851 sec/batch\n",
      "Epoch 8/50 Iteration: 15800 Avg. Training loss: 4.2111 0.2850 sec/batch\n",
      "Epoch 8/50 Iteration: 15900 Avg. Training loss: 4.2215 0.2902 sec/batch\n",
      "Epoch 8/50 Iteration: 16000 Avg. Training loss: 4.2250 0.2867 sec/batch\n",
      "Nearest to was: interwiki, angelina, times, 0341, collectible, reacting, previous, 123222396,\n",
      "Nearest to them: untagged, templatenameplease, concerning, they, lacking, kwanzaa, proximity, flew,\n",
      "Nearest to on: four, interest, tutoriali, check, cellpadding0styleborder1px, biographies, page, clicking,\n",
      "Nearest to not: subjects, statistic, stp, well, irresponsibly, itspeedy, mildly, donaire,\n",
      "Nearest to use: uploading, boilerplate, fairuse, fair, or, include, page, wikipediause,\n",
      "Nearest to does: deleted, included, hom, wpredflag, unavailable, dictionaries, ribbon, southgate,\n",
      "Nearest to the: one, please, substantial, be, if, db, content, would,\n",
      "Nearest to but: 5i, welcomeand, crossmr, enhances, person, existing, merchandise, vertigo,\n",
      "Nearest to poor: soft, rumble, meal, gimme, 0642, espinola, plaque, pitfalls,\n",
      "Nearest to wonder: deceitful, hominen, unbearable, talkedits, intrusion, looki, irony, still,\n",
      "Nearest to barnstar: tireless, hereby, award, antivandalism, wanna, booey, kindness, talkpages,\n",
      "Nearest to controversial: hovind, jayjgs, vivekananda, indiscriminately, jyllandsposten, archeology, cheerio, solus,\n",
      "Nearest to religion: behe, litmus, industrialized, religious, adherents, unnacceptable, beliefs, subjective,\n",
      "Nearest to difficult: restructuring, futility, refuting, regrets, 1821, smoked, fowlers, hazrat,\n",
      "Nearest to french: italians, crowns, troop, carta, facial, uniting, bore, france,\n",
      "Nearest to event: irreversible, sax, furries, oil, banu, povi, edna, arafat,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 Iteration: 16100 Avg. Training loss: 4.1983 0.2985 sec/batch\n",
      "Epoch 8/50 Iteration: 16200 Avg. Training loss: 4.2085 0.3030 sec/batch\n",
      "Epoch 8/50 Iteration: 16300 Avg. Training loss: 4.1968 0.3197 sec/batch\n",
      "Epoch 8/50 Iteration: 16400 Avg. Training loss: 4.2077 0.3277 sec/batch\n",
      "Epoch 8/50 Iteration: 16500 Avg. Training loss: 4.2187 0.3025 sec/batch\n",
      "Epoch 8/50 Iteration: 16600 Avg. Training loss: 4.1870 0.2919 sec/batch\n",
      "Epoch 8/50 Iteration: 16700 Avg. Training loss: 4.1878 0.2763 sec/batch\n",
      "Epoch 8/50 Iteration: 16800 Avg. Training loss: 4.2190 9.2410 sec/batch\n",
      "Epoch 8/50 Iteration: 16900 Avg. Training loss: 4.2105 0.3268 sec/batch\n",
      "Epoch 8/50 Iteration: 17000 Avg. Training loss: 4.2122 8.6561 sec/batch\n",
      "Nearest to was: angelina, interwiki, times, collectible, 0341, capitalize, reacting, wikipediamultilicensingmultilicense,\n",
      "Nearest to them: untagged, concerning, templatenameplease, they, thatthere, commonsthe, sina, kwanzaa,\n",
      "Nearest to on: four, check, interest, biographies, page, cellpadding0styleborder1px, tutoriali, there,\n",
      "Nearest to not: statistic, subjects, well, donaire, try, talkspeedy, itspeedy, people,\n",
      "Nearest to use: uploading, boilerplate, fair, fairuse, or, page, wikipediause, nonfree,\n",
      "Nearest to does: included, dictionaries, basic, shabazztalk, unavailable, hom, southgate, deleted,\n",
      "Nearest to the: one, be, please, if, substantial, db, that, content,\n",
      "Nearest to but: welcomeand, enhances, 5i, existing, person, crossmr, remove, vertigo,\n",
      "Nearest to poor: soft, rumble, meal, gimme, 0642, plaque, pitfalls, skeptics,\n",
      "Nearest to wonder: deceitful, hominen, unbearable, intrusion, talkedits, looki, irony, hogan,\n",
      "Nearest to barnstar: tireless, hereby, award, antivandalism, kindness, wanna, booey, churn,\n",
      "Nearest to controversial: hovind, jayjgs, indiscriminately, vivekananda, jyllandsposten, sherrod, solus, ladyummmmmmm,\n",
      "Nearest to religion: behe, litmus, industrialized, religious, adherents, rabbinic, beliefs, unnacceptable,\n",
      "Nearest to difficult: restructuring, futility, refuting, smoked, 1821, hazrat, regrets, wpstub,\n",
      "Nearest to french: italians, crowns, troop, carta, uniting, facial, france, clearance,\n",
      "Nearest to event: irreversible, sax, furries, oil, banu, povi, 98, arafat,\n",
      "Epoch 9/50 Iteration: 17100 Avg. Training loss: 3.9884 0.0602 sec/batch\n",
      "Epoch 9/50 Iteration: 17200 Avg. Training loss: 3.8407 0.4070 sec/batch\n",
      "Epoch 9/50 Iteration: 17300 Avg. Training loss: 4.1001 0.3623 sec/batch\n",
      "Epoch 9/50 Iteration: 17400 Avg. Training loss: 4.1822 0.4756 sec/batch\n",
      "Epoch 9/50 Iteration: 17500 Avg. Training loss: 4.2060 0.4061 sec/batch\n",
      "Epoch 9/50 Iteration: 17600 Avg. Training loss: 4.1475 0.3718 sec/batch\n",
      "Epoch 9/50 Iteration: 17700 Avg. Training loss: 4.1887 0.3421 sec/batch\n",
      "Epoch 9/50 Iteration: 17800 Avg. Training loss: 4.1950 0.3527 sec/batch\n",
      "Epoch 9/50 Iteration: 17900 Avg. Training loss: 4.1515 0.3573 sec/batch\n",
      "Epoch 9/50 Iteration: 18000 Avg. Training loss: 4.1629 0.3643 sec/batch\n",
      "Nearest to was: interwiki, angelina, times, collectible, 0341, capitalize, previous, wikipediamultilicensingmultilicense,\n",
      "Nearest to them: untagged, templatenameplease, concerning, they, hours, orgy, lacking, proximity,\n",
      "Nearest to on: check, four, interest, for, biographies, page, case, tutoriali,\n",
      "Nearest to not: subjects, statistic, that, well, workthe, stp, donaire, try,\n",
      "Nearest to use: uploading, boilerplate, fair, wikipediause, or, fairuse, page, include,\n",
      "Nearest to does: included, dictionaries, southgate, basic, hom, shabazztalk, unavailable, deleted,\n",
      "Nearest to the: one, please, be, substantial, db, questions, content, criteria,\n",
      "Nearest to but: welcomeand, enhances, 5i, crossmr, vertigo, person, beans, existing,\n",
      "Nearest to poor: soft, rumble, meal, gimme, plaque, 0642, deity, pitfalls,\n",
      "Nearest to wonder: deceitful, hominen, unbearable, intrusion, talkedits, hogan, looki, irony,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, award, kindness, booey, churn, talkpages,\n",
      "Nearest to controversial: hovind, jayjgs, sherrod, vivekananda, indiscriminately, bernard, archeology, solus,\n",
      "Nearest to religion: behe, litmus, industrialized, adherents, beliefs, religious, veda, rabbinic,\n",
      "Nearest to difficult: restructuring, futility, refuting, 1821, regrets, hazrat, smoked, fowlers,\n",
      "Nearest to french: italians, crowns, troop, facial, carta, uniting, regardsthis, clearance,\n",
      "Nearest to event: irreversible, furries, sax, povi, oil, banu, edna, 98,\n",
      "Epoch 9/50 Iteration: 18100 Avg. Training loss: 4.1997 0.3729 sec/batch\n",
      "Epoch 9/50 Iteration: 18200 Avg. Training loss: 4.1950 0.3739 sec/batch\n",
      "Epoch 9/50 Iteration: 18300 Avg. Training loss: 4.1675 0.3655 sec/batch\n",
      "Epoch 9/50 Iteration: 18400 Avg. Training loss: 4.1822 0.3410 sec/batch\n",
      "Epoch 9/50 Iteration: 18500 Avg. Training loss: 4.1775 0.3431 sec/batch\n",
      "Epoch 9/50 Iteration: 18600 Avg. Training loss: 4.2200 0.3428 sec/batch\n",
      "Epoch 9/50 Iteration: 18700 Avg. Training loss: 4.1879 0.3763 sec/batch\n",
      "Epoch 9/50 Iteration: 18800 Avg. Training loss: 4.1629 0.3588 sec/batch\n",
      "Epoch 9/50 Iteration: 18900 Avg. Training loss: 4.2051 0.3612 sec/batch\n",
      "Epoch 9/50 Iteration: 19000 Avg. Training loss: 4.1777 0.3790 sec/batch\n",
      "Nearest to was: angelina, interwiki, times, collectible, capitalize, previous, because, reacting,\n",
      "Nearest to them: untagged, templatenameplease, concerning, they, hours, thatthere, gazetteer, proximity,\n",
      "Nearest to on: four, check, interest, biographies, for, page, there, bhg,\n",
      "Nearest to not: try, well, statistic, workthe, tumble, bs, subjects, people,\n",
      "Nearest to use: uploading, boilerplate, fairuse, wikipediause, fair, or, page, nonfree,\n",
      "Nearest to does: included, dictionaries, supposing, basic, real, southgate, hom, ribbon,\n",
      "Nearest to the: be, one, please, db, that, substantial, would, if,\n",
      "Nearest to but: welcomeand, 5i, vertigo, existing, enhances, crossmr, aware, labyrinth,\n",
      "Nearest to poor: soft, rumble, plaque, gimme, meal, 0642, aholes, paradigm,\n",
      "Nearest to wonder: deceitful, intrusion, talkedits, hominen, unbearable, hogan, looki, irony,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, award, kindness, booey, talkpages, 11em,\n",
      "Nearest to controversial: hovind, jayjgs, sherrod, vivekananda, indiscriminately, bernard, jyllandsposten, solus,\n",
      "Nearest to religion: behe, litmus, industrialized, adherents, religious, veda, rabbinic, chola,\n",
      "Nearest to difficult: restructuring, futility, hazrat, refuting, smoked, fowlers, 1821, 1215,\n",
      "Nearest to french: italians, crowns, troop, carta, untrustworthy, facial, clearance, france,\n",
      "Nearest to event: furries, irreversible, sax, povi, oil, banu, arafat, edna,\n",
      "Epoch 9/50 Iteration: 19100 Avg. Training loss: 4.1809 0.3594 sec/batch\n",
      "Epoch 9/50 Iteration: 19200 Avg. Training loss: 4.1472 0.3333 sec/batch\n",
      "Epoch 10/50 Iteration: 19300 Avg. Training loss: 3.6497 0.2423 sec/batch\n",
      "Epoch 10/50 Iteration: 19400 Avg. Training loss: 3.9876 0.3264 sec/batch\n",
      "Epoch 10/50 Iteration: 19500 Avg. Training loss: 4.1662 0.3642 sec/batch\n",
      "Epoch 10/50 Iteration: 19600 Avg. Training loss: 4.1720 0.3372 sec/batch\n",
      "Epoch 10/50 Iteration: 19700 Avg. Training loss: 4.1560 0.3177 sec/batch\n",
      "Epoch 10/50 Iteration: 19800 Avg. Training loss: 4.1666 0.3164 sec/batch\n",
      "Epoch 10/50 Iteration: 19900 Avg. Training loss: 4.1607 0.2942 sec/batch\n",
      "Epoch 10/50 Iteration: 20000 Avg. Training loss: 4.1515 0.2906 sec/batch\n",
      "Nearest to was: angelina, interwiki, times, previous, capitalize, 0341, because, collectible,\n",
      "Nearest to them: untagged, templatenameplease, they, concerning, hours, read, proximity, thatthere,\n",
      "Nearest to on: four, interest, check, for, this, bhg, biographies, cellpadding0styleborder1px,\n",
      "Nearest to not: subjects, try, well, statistic, workthe, that, people, donaire,\n",
      "Nearest to use: uploading, fair, boilerplate, or, wikipediause, fairuse, page, specifies,\n",
      "Nearest to does: basic, dictionaries, real, included, unavailable, hom, southgate, supposing,\n",
      "Nearest to the: one, please, be, db, content, would, of, that,\n",
      "Nearest to but: 5i, welcomeand, crossmr, vertigo, person, enhances, existing, aware,\n",
      "Nearest to poor: soft, plaque, rumble, aholes, meal, gimme, paradigm, pitfalls,\n",
      "Nearest to wonder: deceitful, hominen, intrusion, talkedits, hogan, unbearable, looki, irony,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, award, kindness, 11em, booey, churn,\n",
      "Nearest to controversial: hovind, sherrod, jayjgs, vivekananda, bernard, indiscriminately, archeology, remarks,\n",
      "Nearest to religion: behe, litmus, industrialized, religious, adherents, veda, rabbinic, subjective,\n",
      "Nearest to difficult: restructuring, futility, refuting, hazrat, pervasive, regrets, smoked, 1821,\n",
      "Nearest to french: italians, crowns, troop, france, clearance, untrustworthy, recognition, wikipediawide,\n",
      "Nearest to event: furries, irreversible, povi, sax, banu, arafat, edna, oil,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 Iteration: 20100 Avg. Training loss: 4.1443 0.3602 sec/batch\n",
      "Epoch 10/50 Iteration: 20200 Avg. Training loss: 4.1614 0.3561 sec/batch\n",
      "Epoch 10/50 Iteration: 20300 Avg. Training loss: 4.1720 0.3724 sec/batch\n",
      "Epoch 10/50 Iteration: 20400 Avg. Training loss: 4.1459 0.2931 sec/batch\n",
      "Epoch 10/50 Iteration: 20500 Avg. Training loss: 4.1701 0.3109 sec/batch\n",
      "Epoch 10/50 Iteration: 20600 Avg. Training loss: 4.1644 0.3021 sec/batch\n",
      "Epoch 10/50 Iteration: 20700 Avg. Training loss: 4.1660 0.3392 sec/batch\n",
      "Epoch 10/50 Iteration: 20800 Avg. Training loss: 4.1787 0.3115 sec/batch\n",
      "Epoch 10/50 Iteration: 20900 Avg. Training loss: 4.1150 0.3081 sec/batch\n",
      "Epoch 10/50 Iteration: 21000 Avg. Training loss: 4.1667 0.2995 sec/batch\n",
      "Nearest to was: angelina, interwiki, times, because, previous, collectible, 0341, capitalize,\n",
      "Nearest to them: untagged, they, concerning, templatenameplease, hours, gazetteer, read, proximity,\n",
      "Nearest to on: four, interest, check, this, biographies, bhg, for, talk,\n",
      "Nearest to not: well, subjects, that, donaire, workthe, people, try, statistic,\n",
      "Nearest to use: uploading, or, page, fairuse, boilerplate, fair, wikipediause, nonfree,\n",
      "Nearest to does: included, real, basic, hom, wpredflag, dictionaries, supposing, unavailable,\n",
      "Nearest to the: one, db, be, please, that, content, would, if,\n",
      "Nearest to but: existing, welcomeand, person, vertigo, 5i, crossmr, aware, labyrinth,\n",
      "Nearest to poor: soft, plaque, rumble, aholes, meal, 0642, pitfalls, gimme,\n",
      "Nearest to wonder: deceitful, talkedits, intrusion, hominen, unbearable, irony, hogan, assure,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, award, kindness, churn, 11em, xlarge,\n",
      "Nearest to controversial: hovind, sherrod, jayjgs, vivekananda, archeology, bernard, solus, indiscriminately,\n",
      "Nearest to religion: behe, litmus, industrialized, adherents, veda, beliefs, rabbinic, atheism,\n",
      "Nearest to difficult: restructuring, futility, hazrat, pervasive, regrets, refuting, fowlers, smoked,\n",
      "Nearest to french: italians, crowns, troop, untrustworthy, france, recognition, carta, clearance,\n",
      "Nearest to event: furries, irreversible, sax, povi, banu, arafat, oil, man,\n",
      "Epoch 10/50 Iteration: 21100 Avg. Training loss: 4.1704 0.3155 sec/batch\n",
      "Epoch 10/50 Iteration: 21200 Avg. Training loss: 4.1628 0.2892 sec/batch\n",
      "Epoch 10/50 Iteration: 21300 Avg. Training loss: 4.1615 0.2901 sec/batch\n",
      "Epoch 11/50 Iteration: 21400 Avg. Training loss: 3.6957 0.1293 sec/batch\n",
      "Epoch 11/50 Iteration: 21500 Avg. Training loss: 3.9309 0.2834 sec/batch\n",
      "Epoch 11/50 Iteration: 21600 Avg. Training loss: 4.1244 0.2859 sec/batch\n",
      "Epoch 11/50 Iteration: 21700 Avg. Training loss: 4.1615 0.2793 sec/batch\n",
      "Epoch 11/50 Iteration: 21800 Avg. Training loss: 4.1412 0.2844 sec/batch\n",
      "Epoch 11/50 Iteration: 21900 Avg. Training loss: 4.1350 0.2728 sec/batch\n",
      "Epoch 11/50 Iteration: 22000 Avg. Training loss: 4.1522 0.2703 sec/batch\n",
      "Nearest to was: angelina, interwiki, times, because, previous, 0341, collectible, capitalize,\n",
      "Nearest to them: untagged, they, concerning, templatenameplease, hours, read, following, politburo,\n",
      "Nearest to on: four, check, for, talk, this, interest, page, bhg,\n",
      "Nearest to not: donaire, well, that, workthe, subjects, try, from, irresponsibly,\n",
      "Nearest to use: uploading, page, or, fair, wikipediause, fairuse, boilerplate, bongwarriorcongratualtions,\n",
      "Nearest to does: real, basic, hom, dictionaries, unavailable, included, wpredflag, southgate,\n",
      "Nearest to the: one, please, of, that, content, db, be, if,\n",
      "Nearest to but: vertigo, existing, welcomeand, 5i, aware, person, labyrinth, crossmr,\n",
      "Nearest to poor: plaque, soft, aholes, rumble, gimme, meal, 0642, thre,\n",
      "Nearest to wonder: deceitful, hominen, 1800z, talkedits, hogan, intrusion, looki, associating,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, award, kindness, 11em, xlarge, churn,\n",
      "Nearest to controversial: hovind, sherrod, jayjgs, remarks, bernard, vivekananda, greg, centrist,\n",
      "Nearest to religion: litmus, behe, industrialized, subjective, veda, adherents, beliefs, atheism,\n",
      "Nearest to difficult: restructuring, pervasive, hazrat, futility, descriptions, regrets, smoked, refuting,\n",
      "Nearest to french: italians, crowns, troop, france, untrustworthy, franoisbernard, uniting, tenor,\n",
      "Nearest to event: furries, povi, irreversible, sax, banu, arafat, lined, oil,\n",
      "Epoch 11/50 Iteration: 22100 Avg. Training loss: 4.1345 0.2751 sec/batch\n",
      "Epoch 11/50 Iteration: 22200 Avg. Training loss: 4.1235 0.2717 sec/batch\n",
      "Epoch 11/50 Iteration: 22300 Avg. Training loss: 4.1309 0.2732 sec/batch\n",
      "Epoch 11/50 Iteration: 22400 Avg. Training loss: 4.1415 0.2737 sec/batch\n",
      "Epoch 11/50 Iteration: 22500 Avg. Training loss: 4.1591 0.2731 sec/batch\n",
      "Epoch 11/50 Iteration: 22600 Avg. Training loss: 4.1559 0.3048 sec/batch\n",
      "Epoch 11/50 Iteration: 22700 Avg. Training loss: 4.1380 0.3427 sec/batch\n",
      "Epoch 11/50 Iteration: 22800 Avg. Training loss: 4.1495 0.2884 sec/batch\n",
      "Epoch 11/50 Iteration: 22900 Avg. Training loss: 4.1492 0.2802 sec/batch\n",
      "Epoch 11/50 Iteration: 23000 Avg. Training loss: 4.1144 0.3339 sec/batch\n",
      "Nearest to was: angelina, times, interwiki, because, collectible, previous, monasteries, reacting,\n",
      "Nearest to them: untagged, they, templatenameplease, hours, concerning, read, following, paddybriggs,\n",
      "Nearest to on: talk, four, check, for, this, page, interest, bhg,\n",
      "Nearest to not: well, subjects, donaire, that, from, stp, statistic, workthe,\n",
      "Nearest to use: uploading, fair, page, or, fairuse, boilerplate, wikipediause, specifies,\n",
      "Nearest to does: real, included, hom, basic, southgate, wpredflag, unavailable, theocracy,\n",
      "Nearest to the: one, be, that, of, if, please, content, would,\n",
      "Nearest to but: vertigo, existing, 5i, welcomeand, aware, enhances, that, g5,\n",
      "Nearest to poor: plaque, soft, aholes, meal, pitfalls, paradigm, rumble, 0642,\n",
      "Nearest to wonder: deceitful, talkedits, intrusion, hominen, 1800z, hogan, associating, looki,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, 11em, xlarge,\n",
      "Nearest to controversial: hovind, sherrod, jayjgs, bernard, centrist, vivekananda, archeology, solus,\n",
      "Nearest to religion: litmus, behe, industrialized, adherents, veda, atheism, subjective, redeem,\n",
      "Nearest to difficult: restructuring, hazrat, pervasive, 1215, treatises, taiwanese, regrets, opine,\n",
      "Nearest to french: italians, crowns, troop, france, untrustworthy, tenor, franoisbernard, recognition,\n",
      "Nearest to event: furries, povi, irreversible, sax, oil, banu, arafat, lined,\n",
      "Epoch 11/50 Iteration: 23100 Avg. Training loss: 4.0966 0.3212 sec/batch\n",
      "Epoch 11/50 Iteration: 23200 Avg. Training loss: 4.1506 0.3368 sec/batch\n",
      "Epoch 11/50 Iteration: 23300 Avg. Training loss: 4.1356 0.3784 sec/batch\n",
      "Epoch 11/50 Iteration: 23400 Avg. Training loss: 4.1356 0.4296 sec/batch\n",
      "Epoch 12/50 Iteration: 23500 Avg. Training loss: 3.9654 0.0524 sec/batch\n",
      "Epoch 12/50 Iteration: 23600 Avg. Training loss: 3.7169 0.3907 sec/batch\n",
      "Epoch 12/50 Iteration: 23700 Avg. Training loss: 3.9945 0.4280 sec/batch\n",
      "Epoch 12/50 Iteration: 23800 Avg. Training loss: 4.1582 0.4633 sec/batch\n",
      "Epoch 12/50 Iteration: 23900 Avg. Training loss: 4.1120 0.4498 sec/batch\n",
      "Epoch 12/50 Iteration: 24000 Avg. Training loss: 4.0884 0.4321 sec/batch\n",
      "Nearest to was: times, angelina, interwiki, because, previous, 0341, 123222396, collectible,\n",
      "Nearest to them: untagged, they, hours, templatenameplease, read, concerning, following, gazetteer,\n",
      "Nearest to on: talk, for, four, this, check, interest, page, bhg,\n",
      "Nearest to not: well, stp, donaire, from, subjects, second, bs, try,\n",
      "Nearest to use: uploading, fair, boilerplate, fairuse, or, page, wikipediause, bongwarriorcongratualtions,\n",
      "Nearest to does: hom, real, basic, included, southgate, unavailable, wpredflag, theocracy,\n",
      "Nearest to the: one, of, be, content, please, if, that, would,\n",
      "Nearest to but: vertigo, 5i, welcomeand, enhances, crossmr, existing, labyrinth, beans,\n",
      "Nearest to poor: plaque, aholes, soft, meal, tower, deity, gimme, rumble,\n",
      "Nearest to wonder: deceitful, hominen, 1800z, intrusion, hogan, assure, elseyou, looki,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, 11em, xlarge,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, jayjgs, vivekananda, archeology, solus,\n",
      "Nearest to religion: litmus, behe, industrialized, veda, adherents, subjective, redeem, beliefs,\n",
      "Nearest to difficult: restructuring, 1215, pervasive, descriptions, hazrat, opine, taiwanese, treatises,\n",
      "Nearest to french: italians, crowns, troop, untrustworthy, france, wll, franoisbernard, tenor,\n",
      "Nearest to event: furries, povi, irreversible, sax, banu, arafat, man, lined,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 Iteration: 24100 Avg. Training loss: 4.1344 0.4276 sec/batch\n",
      "Epoch 12/50 Iteration: 24200 Avg. Training loss: 4.1323 0.4536 sec/batch\n",
      "Epoch 12/50 Iteration: 24300 Avg. Training loss: 4.0790 0.4304 sec/batch\n",
      "Epoch 12/50 Iteration: 24400 Avg. Training loss: 4.1536 0.4120 sec/batch\n",
      "Epoch 12/50 Iteration: 24500 Avg. Training loss: 4.1330 0.4814 sec/batch\n",
      "Epoch 12/50 Iteration: 24600 Avg. Training loss: 4.1137 0.4464 sec/batch\n",
      "Epoch 12/50 Iteration: 24700 Avg. Training loss: 4.1061 0.4242 sec/batch\n",
      "Epoch 12/50 Iteration: 24800 Avg. Training loss: 4.1050 0.4342 sec/batch\n",
      "Epoch 12/50 Iteration: 24900 Avg. Training loss: 4.1015 0.4686 sec/batch\n",
      "Epoch 12/50 Iteration: 25000 Avg. Training loss: 4.1388 0.5141 sec/batch\n",
      "Nearest to was: interwiki, times, because, angelina, collectible, capitalize, previous, 0341,\n",
      "Nearest to them: untagged, they, read, hours, templatenameplease, concerning, following, gazetteer,\n",
      "Nearest to on: talk, for, four, this, check, interest, page, bhg,\n",
      "Nearest to not: well, stp, second, subjects, try, donaire, from, workthe,\n",
      "Nearest to use: fair, uploading, or, page, fairuse, wikipediause, boilerplate, specifies,\n",
      "Nearest to does: real, included, basic, hom, theocracy, wpredflag, deleted, unavailable,\n",
      "Nearest to the: one, of, be, please, that, content, if, would,\n",
      "Nearest to but: vertigo, 5i, enhances, welcomeand, existing, g5, beans, aware,\n",
      "Nearest to poor: plaque, soft, aholes, meal, tower, paradigm, rumble, deity,\n",
      "Nearest to wonder: deceitful, assure, irony, talkedits, associating, hominen, rn, 1800z,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, award, kindness, churn, 11em, xlarge,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, solus, jayjgs, archeology, vivekananda,\n",
      "Nearest to religion: litmus, behe, industrialized, veda, vaishnavism, traditional, redeem, rabbinic,\n",
      "Nearest to difficult: restructuring, descriptions, pervasive, 1215, hazrat, treatises, taiwanese, calvinism,\n",
      "Nearest to french: italians, crowns, france, untrustworthy, troop, wll, tenor, franoisbernard,\n",
      "Nearest to event: furries, povi, irreversible, banu, sax, candice, man, oil,\n",
      "Epoch 12/50 Iteration: 25100 Avg. Training loss: 4.1349 0.4846 sec/batch\n",
      "Epoch 12/50 Iteration: 25200 Avg. Training loss: 4.1132 0.4369 sec/batch\n",
      "Epoch 12/50 Iteration: 25300 Avg. Training loss: 4.1409 0.4188 sec/batch\n",
      "Epoch 12/50 Iteration: 25400 Avg. Training loss: 4.1151 0.4617 sec/batch\n",
      "Epoch 12/50 Iteration: 25500 Avg. Training loss: 4.1217 0.4344 sec/batch\n",
      "Epoch 12/50 Iteration: 25600 Avg. Training loss: 4.1128 0.4246 sec/batch\n",
      "Epoch 13/50 Iteration: 25700 Avg. Training loss: 3.5824 0.3082 sec/batch\n",
      "Epoch 13/50 Iteration: 25800 Avg. Training loss: 3.9202 0.3950 sec/batch\n",
      "Epoch 13/50 Iteration: 25900 Avg. Training loss: 4.1280 0.4280 sec/batch\n",
      "Epoch 13/50 Iteration: 26000 Avg. Training loss: 4.1226 0.4347 sec/batch\n",
      "Nearest to was: because, times, angelina, interwiki, cyde, 123222396, previous, reacting,\n",
      "Nearest to them: untagged, they, read, concerning, hours, gazetteer, templatenameplease, commonsthe,\n",
      "Nearest to on: four, this, talk, for, interest, check, of, page,\n",
      "Nearest to not: try, well, from, bs, stp, donaire, it, that,\n",
      "Nearest to use: fair, uploading, or, fairuse, boilerplate, wikipediause, specifies, page,\n",
      "Nearest to does: real, hom, basic, angular, southgate, unavailable, included, theocracy,\n",
      "Nearest to the: one, please, of, if, be, that, db, would,\n",
      "Nearest to but: vertigo, 5i, enhances, welcomeand, crossmr, labyrinth, existing, aware,\n",
      "Nearest to poor: plaque, aholes, soft, tower, meal, tryin, deity, 0642,\n",
      "Nearest to wonder: deceitful, assure, elseyou, irony, 1800z, looki, hogan, hominen,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, award, kindness, churn, 11em, xlarge,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, archeology, solus, vivekananda, jayjgs,\n",
      "Nearest to religion: litmus, behe, industrialized, vaishnavism, veda, subjective, atheism, traditional,\n",
      "Nearest to difficult: restructuring, treatises, descriptions, pervasive, 1215, opine, hazrat, coding,\n",
      "Nearest to french: italians, crowns, france, untrustworthy, troop, wll, themthis, franoisbernard,\n",
      "Nearest to event: furries, povi, irreversible, sax, banu, candice, arafat, man,\n",
      "Epoch 13/50 Iteration: 26100 Avg. Training loss: 4.0908 0.4499 sec/batch\n",
      "Epoch 13/50 Iteration: 26200 Avg. Training loss: 4.0905 0.5074 sec/batch\n",
      "Epoch 13/50 Iteration: 26300 Avg. Training loss: 4.1190 0.4713 sec/batch\n",
      "Epoch 13/50 Iteration: 26400 Avg. Training loss: 4.1090 0.4556 sec/batch\n",
      "Epoch 13/50 Iteration: 26500 Avg. Training loss: 4.0838 0.4134 sec/batch\n",
      "Epoch 13/50 Iteration: 26600 Avg. Training loss: 4.1057 0.4158 sec/batch\n",
      "Epoch 13/50 Iteration: 26700 Avg. Training loss: 4.1263 0.4105 sec/batch\n",
      "Epoch 13/50 Iteration: 26800 Avg. Training loss: 4.0828 0.4079 sec/batch\n",
      "Epoch 13/50 Iteration: 26900 Avg. Training loss: 4.0925 0.4119 sec/batch\n",
      "Epoch 13/50 Iteration: 27000 Avg. Training loss: 4.0989 0.4289 sec/batch\n",
      "Nearest to was: interwiki, angelina, because, times, collectible, enjoying, 6912122197, 123222396,\n",
      "Nearest to them: untagged, they, read, concerning, hours, proximity, gazetteer, contr,\n",
      "Nearest to on: talk, four, this, for, interest, check, and, page,\n",
      "Nearest to not: well, bs, try, stp, second, workthe, that, from,\n",
      "Nearest to use: fair, or, uploading, boilerplate, fairuse, specifies, wikipediause, page,\n",
      "Nearest to does: real, hom, basic, included, theocracy, angular, unavailable, wpredflag,\n",
      "Nearest to the: one, of, be, that, please, would, if, criteria,\n",
      "Nearest to but: existing, vertigo, 5i, aware, welcomeand, enhances, g5, not,\n",
      "Nearest to poor: plaque, aholes, meal, soft, tower, deity, criticized, pitfalls,\n",
      "Nearest to wonder: assure, deceitful, hogan, looki, irony, unbearable, talkedits, associating,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, 11em,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, archeology, solus, vivekananda, centrist,\n",
      "Nearest to religion: litmus, behe, industrialized, vaishnavism, atheism, veda, traditional, religions,\n",
      "Nearest to difficult: restructuring, descriptions, pervasive, treatises, 1215, coding, calvinism, opine,\n",
      "Nearest to french: italians, crowns, france, untrustworthy, troop, tenor, wll, themthis,\n",
      "Nearest to event: povi, furries, banu, irreversible, candice, sax, competitors, man,\n",
      "Epoch 13/50 Iteration: 27100 Avg. Training loss: 4.0945 0.4122 sec/batch\n",
      "Epoch 13/50 Iteration: 27200 Avg. Training loss: 4.1209 0.4087 sec/batch\n",
      "Epoch 13/50 Iteration: 27300 Avg. Training loss: 4.0797 0.4045 sec/batch\n",
      "Epoch 13/50 Iteration: 27400 Avg. Training loss: 4.1284 0.4066 sec/batch\n",
      "Epoch 13/50 Iteration: 27500 Avg. Training loss: 4.1043 0.4114 sec/batch\n",
      "Epoch 13/50 Iteration: 27600 Avg. Training loss: 4.1076 0.4074 sec/batch\n",
      "Epoch 13/50 Iteration: 27700 Avg. Training loss: 4.0903 0.4078 sec/batch\n",
      "Epoch 14/50 Iteration: 27800 Avg. Training loss: 3.6635 0.1542 sec/batch\n",
      "Epoch 14/50 Iteration: 27900 Avg. Training loss: 3.8603 0.3851 sec/batch\n",
      "Epoch 14/50 Iteration: 28000 Avg. Training loss: 4.0462 0.4017 sec/batch\n",
      "Nearest to was: because, angelina, interwiki, 123222396, times, cyde, hoe, vera,\n",
      "Nearest to them: untagged, they, read, have, hours, concerning, it, commonsthe,\n",
      "Nearest to on: this, for, talk, four, and, my, of, check,\n",
      "Nearest to not: from, bs, try, well, that, stp, it, motha,\n",
      "Nearest to use: fair, boilerplate, uploading, fairuse, or, specifies, page, bongwarriorcongratualtions,\n",
      "Nearest to does: real, hom, basic, angular, unavailable, southgate, theocracy, included,\n",
      "Nearest to the: one, be, of, that, if, please, would, wikipedia,\n",
      "Nearest to but: vertigo, welcomeand, colective, existing, not, pierodic, get, shatner,\n",
      "Nearest to poor: plaque, aholes, gimme, of, meal, soft, tryin, tower,\n",
      "Nearest to wonder: deceitful, assure, unbearable, elseyou, 1800z, irony, looki, hogan,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, 11em, xlarge,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, archeology, greg, solus, remark,\n",
      "Nearest to religion: litmus, industrialized, behe, vaishnavism, criticise, veda, atheism, principle,\n",
      "Nearest to difficult: restructuring, 1215, pervasive, descriptions, treatises, coding, hazrat, calvinism,\n",
      "Nearest to french: italians, crowns, france, untrustworthy, themthis, wll, troop, franoisbernard,\n",
      "Nearest to event: furries, povi, banu, candice, irreversible, sax, man, surpasses,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 Iteration: 28100 Avg. Training loss: 4.0914 0.4145 sec/batch\n",
      "Epoch 14/50 Iteration: 28200 Avg. Training loss: 4.1031 0.4054 sec/batch\n",
      "Epoch 14/50 Iteration: 28300 Avg. Training loss: 4.0506 0.4049 sec/batch\n",
      "Epoch 14/50 Iteration: 28400 Avg. Training loss: 4.1107 0.4083 sec/batch\n",
      "Epoch 14/50 Iteration: 28500 Avg. Training loss: 4.0774 0.4100 sec/batch\n",
      "Epoch 14/50 Iteration: 28600 Avg. Training loss: 4.0715 0.3879 sec/batch\n",
      "Epoch 14/50 Iteration: 28700 Avg. Training loss: 4.0947 0.3894 sec/batch\n",
      "Epoch 14/50 Iteration: 28800 Avg. Training loss: 4.0909 0.4193 sec/batch\n",
      "Epoch 14/50 Iteration: 28900 Avg. Training loss: 4.0881 0.3884 sec/batch\n",
      "Epoch 14/50 Iteration: 29000 Avg. Training loss: 4.0655 0.3867 sec/batch\n",
      "Nearest to was: because, interwiki, collectible, angelina, capitalize, cyde, wikipediamultilicensingmultilicense, enjoying,\n",
      "Nearest to them: untagged, they, read, hours, concerning, gazetteer, proximity, after,\n",
      "Nearest to on: talk, for, this, four, check, interest, and, of,\n",
      "Nearest to not: that, stp, from, well, try, inputs, bs, workthe,\n",
      "Nearest to use: fair, or, page, uploading, fairuse, boilerplate, specifies, include,\n",
      "Nearest to does: real, basic, hom, included, angular, theocracy, 613, southgate,\n",
      "Nearest to the: one, of, be, that, please, if, would, may,\n",
      "Nearest to but: vertigo, existing, wpbefore, aware, shatner, 5i, wikipediabusiness, enhances,\n",
      "Nearest to poor: plaque, aholes, meal, soft, tower, paradigm, gimme, criticized,\n",
      "Nearest to wonder: assure, deceitful, hogan, irony, rn, talkedits, looki, unbearable,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, 11em, defender,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, archeology, greg, flynn, solus,\n",
      "Nearest to religion: litmus, industrialized, behe, vaishnavism, veda, criticise, atheism, traditional,\n",
      "Nearest to difficult: descriptions, restructuring, 1215, pervasive, treatises, coding, calvinism, hazrat,\n",
      "Nearest to french: italians, crowns, france, tenor, untrustworthy, wll, themthis, lindzen,\n",
      "Nearest to event: povi, furries, candice, banu, irreversible, arafat, occurrences, surpasses,\n",
      "Epoch 14/50 Iteration: 29100 Avg. Training loss: 4.0811 0.4058 sec/batch\n",
      "Epoch 14/50 Iteration: 29200 Avg. Training loss: 4.0806 0.4025 sec/batch\n",
      "Epoch 14/50 Iteration: 29300 Avg. Training loss: 4.1280 0.3973 sec/batch\n",
      "Epoch 14/50 Iteration: 29400 Avg. Training loss: 4.0621 0.4461 sec/batch\n",
      "Epoch 14/50 Iteration: 29500 Avg. Training loss: 4.0741 0.4550 sec/batch\n",
      "Epoch 14/50 Iteration: 29600 Avg. Training loss: 4.0942 0.4131 sec/batch\n",
      "Epoch 14/50 Iteration: 29700 Avg. Training loss: 4.0950 0.3967 sec/batch\n",
      "Epoch 14/50 Iteration: 29800 Avg. Training loss: 4.0982 0.3947 sec/batch\n",
      "Epoch 15/50 Iteration: 29900 Avg. Training loss: 3.9578 0.0361 sec/batch\n",
      "Epoch 15/50 Iteration: 30000 Avg. Training loss: 3.5940 0.4888 sec/batch\n",
      "Nearest to was: because, interwiki, cyde, hoe, collectible, vera, enjoying, 123222396,\n",
      "Nearest to them: untagged, they, read, hours, contr, have, commonsthe, it,\n",
      "Nearest to on: this, for, and, talk, my, four, of, check,\n",
      "Nearest to not: well, from, that, stp, it, bs, people, try,\n",
      "Nearest to use: uploading, fair, fairuse, boilerplate, specifies, or, page, bongwarriorcongratualtions,\n",
      "Nearest to does: hom, real, basic, angular, theocracy, southgate, included, 613,\n",
      "Nearest to the: of, one, be, that, if, you, please, would,\n",
      "Nearest to but: vertigo, get, colective, would, wikipediabusiness, 5i, aware, existing,\n",
      "Nearest to poor: plaque, aholes, meal, soft, of, paradigm, gimme, tower,\n",
      "Nearest to wonder: assure, deceitful, elseyou, hogan, irony, looki, 1800z, unbearable,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, 11em,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, archeology, flynn, greg, vivekananda,\n",
      "Nearest to religion: litmus, industrialized, behe, vaishnavism, veda, criticise, religions, principle,\n",
      "Nearest to difficult: descriptions, restructuring, pervasive, 1215, calvinism, treatises, opine, coding,\n",
      "Nearest to french: italians, france, crowns, tenor, wll, themthis, franoisbernard, untrustworthy,\n",
      "Nearest to event: furries, povi, banu, candice, irreversible, occurrences, change, sax,\n",
      "Epoch 15/50 Iteration: 30100 Avg. Training loss: 3.9517 0.5338 sec/batch\n",
      "Epoch 15/50 Iteration: 30200 Avg. Training loss: 4.1076 0.5319 sec/batch\n",
      "Epoch 15/50 Iteration: 30300 Avg. Training loss: 4.0815 0.3851 sec/batch\n",
      "Epoch 15/50 Iteration: 30400 Avg. Training loss: 4.0455 0.3368 sec/batch\n",
      "Epoch 15/50 Iteration: 30500 Avg. Training loss: 4.0615 0.2988 sec/batch\n",
      "Epoch 15/50 Iteration: 30600 Avg. Training loss: 4.0721 0.2940 sec/batch\n",
      "Epoch 15/50 Iteration: 30700 Avg. Training loss: 4.0510 0.3044 sec/batch\n",
      "Epoch 15/50 Iteration: 30800 Avg. Training loss: 4.0835 0.2985 sec/batch\n",
      "Epoch 15/50 Iteration: 30900 Avg. Training loss: 4.0823 0.2953 sec/batch\n",
      "Epoch 15/50 Iteration: 31000 Avg. Training loss: 4.0716 0.2859 sec/batch\n",
      "Nearest to was: because, interwiki, cyde, once, collectible, enjoying, times, previous,\n",
      "Nearest to them: untagged, they, read, hours, contr, after, paddybriggs, wherever,\n",
      "Nearest to on: talk, for, this, four, check, and, interest, of,\n",
      "Nearest to not: that, from, bs, try, well, but, stp, second,\n",
      "Nearest to use: fair, uploading, page, boilerplate, specifies, or, fairuse, bongwarriorcongratualtions,\n",
      "Nearest to does: hom, real, basic, included, theocracy, angular, southgate, 613,\n",
      "Nearest to the: be, of, one, that, if, page, would, please,\n",
      "Nearest to but: vertigo, existing, that, aware, wikipediabusiness, would, not, guideline,\n",
      "Nearest to poor: plaque, aholes, meal, tower, offtopic, soft, paradigm, gimme,\n",
      "Nearest to wonder: assure, deceitful, sf, rn, hogan, thanksim, boxoffice, elseyou,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, churn, defender, counterexamples,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, archeology, flynn, greg, remark,\n",
      "Nearest to religion: litmus, industrialized, behe, vaishnavism, veda, traditional, atheism, criticise,\n",
      "Nearest to difficult: descriptions, restructuring, treatises, pervasive, 1215, calvinism, coding, opine,\n",
      "Nearest to french: italians, france, crowns, tenor, wll, lindzen, themthis, franoisbernard,\n",
      "Nearest to event: povi, furries, banu, candice, occurrences, irreversible, lined, mafia,\n",
      "Epoch 15/50 Iteration: 31100 Avg. Training loss: 4.0884 0.2782 sec/batch\n",
      "Epoch 15/50 Iteration: 31200 Avg. Training loss: 4.0702 0.2765 sec/batch\n",
      "Epoch 15/50 Iteration: 31300 Avg. Training loss: 4.0517 0.2652 sec/batch\n",
      "Epoch 15/50 Iteration: 31400 Avg. Training loss: 4.1023 0.2953 sec/batch\n",
      "Epoch 15/50 Iteration: 31500 Avg. Training loss: 4.1030 0.2882 sec/batch\n",
      "Epoch 15/50 Iteration: 31600 Avg. Training loss: 4.0408 0.2579 sec/batch\n",
      "Epoch 15/50 Iteration: 31700 Avg. Training loss: 4.0818 0.2620 sec/batch\n",
      "Epoch 15/50 Iteration: 31800 Avg. Training loss: 4.0811 0.2579 sec/batch\n",
      "Epoch 15/50 Iteration: 31900 Avg. Training loss: 4.0792 0.2568 sec/batch\n",
      "Epoch 15/50 Iteration: 32000 Avg. Training loss: 4.0716 0.2599 sec/batch\n",
      "Nearest to was: because, interwiki, collectible, once, angelina, monasteries, ministers, vera,\n",
      "Nearest to them: untagged, they, read, contr, hours, following, paddybriggs, useif,\n",
      "Nearest to on: for, talk, this, four, and, check, page, interest,\n",
      "Nearest to not: that, well, try, from, bs, raptor, stp, second,\n",
      "Nearest to use: fair, uploading, boilerplate, fairuse, specifies, page, or, bongwarriorcongratualtions,\n",
      "Nearest to does: hom, real, included, basic, theocracy, southgate, 613, angular,\n",
      "Nearest to the: one, be, of, if, that, would, page, please,\n",
      "Nearest to but: vertigo, existing, aware, think, wikipediabusiness, that, 5i, enhances,\n",
      "Nearest to poor: aholes, plaque, meal, tower, offtopic, soft, paradigm, criticized,\n",
      "Nearest to wonder: assure, deceitful, sf, rn, connects, hogan, ambrose, wikipediaarticles,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, churn, defender, counterexamples,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, archeology, flynn, solus, vivekananda,\n",
      "Nearest to religion: litmus, industrialized, vaishnavism, behe, veda, criticise, atheism, principle,\n",
      "Nearest to difficult: descriptions, treatises, restructuring, pervasive, calvinism, 1215, opine, gaps,\n",
      "Nearest to french: italians, france, crowns, tenor, wll, franoisbernard, lindzen, themthis,\n",
      "Nearest to event: furries, povi, banu, candice, occurrences, change, irreversible, lined,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 Iteration: 32100 Avg. Training loss: 3.5355 0.1763 sec/batch\n",
      "Epoch 16/50 Iteration: 32200 Avg. Training loss: 3.8973 0.2458 sec/batch\n",
      "Epoch 16/50 Iteration: 32300 Avg. Training loss: 4.0657 0.2409 sec/batch\n",
      "Epoch 16/50 Iteration: 32400 Avg. Training loss: 4.0492 0.2407 sec/batch\n",
      "Epoch 16/50 Iteration: 32500 Avg. Training loss: 4.0724 0.2398 sec/batch\n",
      "Epoch 16/50 Iteration: 32600 Avg. Training loss: 4.0613 0.2407 sec/batch\n",
      "Epoch 16/50 Iteration: 32700 Avg. Training loss: 4.0681 0.2397 sec/batch\n",
      "Epoch 16/50 Iteration: 32800 Avg. Training loss: 4.0578 0.2438 sec/batch\n",
      "Epoch 16/50 Iteration: 32900 Avg. Training loss: 4.0378 0.2497 sec/batch\n",
      "Epoch 16/50 Iteration: 33000 Avg. Training loss: 4.0656 1.0677 sec/batch\n",
      "Nearest to was: because, interwiki, collectible, previous, ministers, enjoying, once, cyde,\n",
      "Nearest to them: untagged, they, read, paddybriggs, useif, hours, leningrad, contr,\n",
      "Nearest to on: for, talk, this, four, check, and, of, interest,\n",
      "Nearest to not: that, people, well, subjects, try, second, but, bs,\n",
      "Nearest to use: fair, uploading, specifies, boilerplate, or, page, fairuse, include,\n",
      "Nearest to does: hom, included, real, basic, theocracy, southgate, 613, space,\n",
      "Nearest to the: one, of, be, that, if, page, would, please,\n",
      "Nearest to but: aware, existing, that, vertigo, 5i, think, beans, labyrinth,\n",
      "Nearest to poor: plaque, aholes, meal, tower, of, gimme, offtopic, amicus,\n",
      "Nearest to wonder: assure, deceitful, sf, ambrose, contributions, hogan, connects, wikipediaarticles,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, counterexamples,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, remark,\n",
      "Nearest to religion: litmus, industrialized, vaishnavism, behe, atheism, veda, traditional, religions,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, 1215, restructuring, pervasive, travelled, opine,\n",
      "Nearest to french: italians, crowns, france, tenor, franoisbernard, wll, michel, themthis,\n",
      "Nearest to event: furries, povi, candice, occurrences, change, irreversible, banu, rescuing,\n",
      "Epoch 16/50 Iteration: 33100 Avg. Training loss: 4.0926 0.2768 sec/batch\n",
      "Epoch 16/50 Iteration: 33200 Avg. Training loss: 4.0338 0.2496 sec/batch\n",
      "Epoch 16/50 Iteration: 33300 Avg. Training loss: 4.0517 0.2580 sec/batch\n",
      "Epoch 16/50 Iteration: 33400 Avg. Training loss: 4.0636 0.2402 sec/batch\n",
      "Epoch 16/50 Iteration: 33500 Avg. Training loss: 4.0605 0.2446 sec/batch\n",
      "Epoch 16/50 Iteration: 33600 Avg. Training loss: 4.0887 0.2399 sec/batch\n",
      "Epoch 16/50 Iteration: 33700 Avg. Training loss: 4.0465 0.2399 sec/batch\n",
      "Epoch 16/50 Iteration: 33800 Avg. Training loss: 4.0592 0.2394 sec/batch\n",
      "Epoch 16/50 Iteration: 33900 Avg. Training loss: 4.0393 0.2403 sec/batch\n",
      "Epoch 16/50 Iteration: 34000 Avg. Training loss: 4.0563 0.2398 sec/batch\n",
      "Nearest to was: because, collectible, interwiki, unicorn, angelina, shop, hoe, times,\n",
      "Nearest to them: untagged, they, read, hours, contr, 0200, proximity, reference,\n",
      "Nearest to on: for, this, talk, four, page, check, of, and,\n",
      "Nearest to not: that, bs, people, well, donaire, from, try, tumble,\n",
      "Nearest to use: fair, specifies, or, uploading, page, boilerplate, fairuse, include,\n",
      "Nearest to does: hom, included, basic, real, 613, theocracy, via, angular,\n",
      "Nearest to the: one, of, that, be, if, page, may, would,\n",
      "Nearest to but: existing, beans, vertigo, labyrinth, think, commentsthe, would, aware,\n",
      "Nearest to poor: plaque, aholes, criticized, talkyou, offtopic, gimme, meal, scarce,\n",
      "Nearest to wonder: assure, sf, deceitful, ambrose, rn, contributions, connects, intrusion,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, churn, defender, efforts,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, cannon,\n",
      "Nearest to religion: litmus, industrialized, behe, vaishnavism, veda, saxons, atheism, religions,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, restructuring, 1215, opine, whod, policyif,\n",
      "Nearest to french: italians, france, crowns, tenor, franoisbernard, themthis, wll, stubbornly,\n",
      "Nearest to event: povi, furries, occurrences, candice, change, events, irreversible, venture,\n",
      "Epoch 16/50 Iteration: 34100 Avg. Training loss: 4.0720 0.2438 sec/batch\n",
      "Epoch 17/50 Iteration: 34200 Avg. Training loss: 3.6510 0.0863 sec/batch\n",
      "Epoch 17/50 Iteration: 34300 Avg. Training loss: 3.7872 0.2400 sec/batch\n",
      "Epoch 17/50 Iteration: 34400 Avg. Training loss: 3.9905 0.2495 sec/batch\n",
      "Epoch 17/50 Iteration: 34500 Avg. Training loss: 4.0404 0.2550 sec/batch\n",
      "Epoch 17/50 Iteration: 34600 Avg. Training loss: 4.0481 0.2552 sec/batch\n",
      "Epoch 17/50 Iteration: 34700 Avg. Training loss: 4.0519 0.2543 sec/batch\n",
      "Epoch 17/50 Iteration: 34800 Avg. Training loss: 4.0424 0.4482 sec/batch\n",
      "Epoch 17/50 Iteration: 34900 Avg. Training loss: 4.0427 0.3735 sec/batch\n",
      "Epoch 17/50 Iteration: 35000 Avg. Training loss: 4.0364 0.2825 sec/batch\n",
      "Nearest to was: because, collectible, unicorn, interwiki, cyde, hoe, ledrush, problems,\n",
      "Nearest to them: untagged, they, read, hours, contr, reference, useif, following,\n",
      "Nearest to on: for, this, talk, four, of, check, page, and,\n",
      "Nearest to not: that, bs, try, people, second, well, familiarize, subjects,\n",
      "Nearest to use: fair, specifies, uploading, boilerplate, or, page, fairuse, include,\n",
      "Nearest to does: hom, included, basic, real, theocracy, via, 613, angular,\n",
      "Nearest to the: of, one, that, be, page, can, would, please,\n",
      "Nearest to but: existing, 5i, vertigo, beans, wpbefore, labyrinth, get, welcomeand,\n",
      "Nearest to poor: plaque, aholes, criticized, talkyou, gimme, bandera, embodiment, meal,\n",
      "Nearest to wonder: assure, deceitful, ambrose, sf, contributions, connects, rn, site,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, counterexamples,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, cannon,\n",
      "Nearest to religion: litmus, industrialized, vaishnavism, behe, veda, religions, fad, traditional,\n",
      "Nearest to difficult: descriptions, treatises, restructuring, calvinism, 1215, whod, travelled, opine,\n",
      "Nearest to french: italians, crowns, france, tenor, franoisbernard, wll, themthis, most,\n",
      "Nearest to event: povi, furries, occurrences, candice, club, change, surpasses, irreversible,\n",
      "Epoch 17/50 Iteration: 35100 Avg. Training loss: 4.0542 0.2797 sec/batch\n",
      "Epoch 17/50 Iteration: 35200 Avg. Training loss: 4.0704 0.2738 sec/batch\n",
      "Epoch 17/50 Iteration: 35300 Avg. Training loss: 4.0723 0.3297 sec/batch\n",
      "Epoch 17/50 Iteration: 35400 Avg. Training loss: 4.0418 0.2851 sec/batch\n",
      "Epoch 17/50 Iteration: 35500 Avg. Training loss: 4.0392 0.3042 sec/batch\n",
      "Epoch 17/50 Iteration: 35600 Avg. Training loss: 4.0402 0.3473 sec/batch\n",
      "Epoch 17/50 Iteration: 35700 Avg. Training loss: 4.0684 0.2998 sec/batch\n",
      "Epoch 17/50 Iteration: 35800 Avg. Training loss: 4.0473 0.2784 sec/batch\n",
      "Epoch 17/50 Iteration: 35900 Avg. Training loss: 4.0335 0.2781 sec/batch\n",
      "Epoch 17/50 Iteration: 36000 Avg. Training loss: 4.0713 0.3183 sec/batch\n",
      "Nearest to was: because, collectible, ministers, once, cyde, vera, unicorn, enjoying,\n",
      "Nearest to them: untagged, they, read, hours, contr, satirical, following, reference,\n",
      "Nearest to on: for, this, talk, of, and, page, four, check,\n",
      "Nearest to not: that, bs, well, try, workthe, people, tumble, argue,\n",
      "Nearest to use: fair, specifies, uploading, or, page, boilerplate, image, include,\n",
      "Nearest to does: hom, included, basic, real, 613, theocracy, refuse, wpredflag,\n",
      "Nearest to the: of, one, that, be, page, if, may, please,\n",
      "Nearest to but: existing, that, aware, think, would, commentsthe, vertigo, wikipediabusiness,\n",
      "Nearest to poor: plaque, aholes, criticized, prospects, embodiment, suffers, tower, offtopic,\n",
      "Nearest to wonder: assure, ambrose, sf, contributions, connects, deceitful, rn, intrusion,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, churn, defender, counterexamples,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, solus,\n",
      "Nearest to religion: litmus, industrialized, vaishnavism, behe, veda, traditional, fad, religions,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, whod, restructuring, policyif, 1215, travelled,\n",
      "Nearest to french: italians, crowns, france, tenor, franoisbernard, most, worthless, stubbornly,\n",
      "Nearest to event: povi, furries, occurrences, candice, change, events, venture, surpasses,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 Iteration: 36100 Avg. Training loss: 4.0447 0.3394 sec/batch\n",
      "Epoch 17/50 Iteration: 36200 Avg. Training loss: 4.0676 0.3614 sec/batch\n",
      "Epoch 18/50 Iteration: 36300 Avg. Training loss: 3.9688 0.0152 sec/batch\n",
      "Epoch 18/50 Iteration: 36400 Avg. Training loss: 3.5106 0.3680 sec/batch\n",
      "Epoch 18/50 Iteration: 36500 Avg. Training loss: 3.9039 0.2954 sec/batch\n",
      "Epoch 18/50 Iteration: 36600 Avg. Training loss: 4.0772 0.3014 sec/batch\n",
      "Epoch 18/50 Iteration: 36700 Avg. Training loss: 4.0384 0.3037 sec/batch\n",
      "Epoch 18/50 Iteration: 36800 Avg. Training loss: 4.0140 0.2943 sec/batch\n",
      "Epoch 18/50 Iteration: 36900 Avg. Training loss: 4.0377 0.3141 sec/batch\n",
      "Epoch 18/50 Iteration: 37000 Avg. Training loss: 4.0417 0.3818 sec/batch\n",
      "Nearest to was: because, once, hoe, collectible, angelina, ministers, interwiki, vera,\n",
      "Nearest to them: untagged, they, read, hours, wherever, paddybriggs, reference, contr,\n",
      "Nearest to on: for, this, talk, four, of, check, and, my,\n",
      "Nearest to not: that, bs, try, well, second, people, subjects, familiarize,\n",
      "Nearest to use: fair, uploading, specifies, boilerplate, or, bongwarriorcongratualtions, image, fairuse,\n",
      "Nearest to does: hom, basic, included, real, 613, theocracy, refuse, via,\n",
      "Nearest to the: of, one, that, be, may, can, if, page,\n",
      "Nearest to but: existing, vertigo, 5i, think, aware, labyrinth, wikipediabusiness, that,\n",
      "Nearest to poor: plaque, aholes, tower, suffers, talkyou, prospects, of, amicus,\n",
      "Nearest to wonder: assure, ambrose, site, sf, deceitful, contributions, elseyou, connects,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, 11em,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, cannon,\n",
      "Nearest to religion: litmus, industrialized, vaishnavism, behe, traditional, fad, veda, criticise,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, whod, policyif, restructuring, pervasive, gaps,\n",
      "Nearest to french: italians, crowns, france, tenor, franoisbernard, most, themthis, stubbornly,\n",
      "Nearest to event: povi, furries, occurrences, candice, events, venture, irreversible, change,\n",
      "Epoch 18/50 Iteration: 37100 Avg. Training loss: 4.0379 0.4611 sec/batch\n",
      "Epoch 18/50 Iteration: 37200 Avg. Training loss: 4.0489 0.3131 sec/batch\n",
      "Epoch 18/50 Iteration: 37300 Avg. Training loss: 4.0409 0.2857 sec/batch\n",
      "Epoch 18/50 Iteration: 37400 Avg. Training loss: 4.0653 0.2913 sec/batch\n",
      "Epoch 18/50 Iteration: 37500 Avg. Training loss: 4.0218 0.2937 sec/batch\n",
      "Epoch 18/50 Iteration: 37600 Avg. Training loss: 4.0130 0.3072 sec/batch\n",
      "Epoch 18/50 Iteration: 37700 Avg. Training loss: 4.0355 0.3365 sec/batch\n",
      "Epoch 18/50 Iteration: 37800 Avg. Training loss: 4.0383 0.3092 sec/batch\n",
      "Epoch 18/50 Iteration: 37900 Avg. Training loss: 4.0591 0.3466 sec/batch\n",
      "Epoch 18/50 Iteration: 38000 Avg. Training loss: 4.0115 0.3163 sec/batch\n",
      "Nearest to was: because, enjoying, collectible, interwiki, hoe, angelina, ministers, once,\n",
      "Nearest to them: untagged, they, read, hours, following, useif, after, wherever,\n",
      "Nearest to on: for, talk, this, check, four, of, and, page,\n",
      "Nearest to not: that, well, bs, people, try, but, test, second,\n",
      "Nearest to use: fair, uploading, specifies, boilerplate, or, wikipediause, image, bongwarriorcongratualtions,\n",
      "Nearest to does: hom, 613, included, basic, real, southgate, refuse, pulleys,\n",
      "Nearest to the: of, one, that, be, may, please, if, page,\n",
      "Nearest to but: that, think, existing, many, aware, not, 5i, labyrinth,\n",
      "Nearest to poor: plaque, aholes, talkyou, suffers, embodiment, prospects, tower, meal,\n",
      "Nearest to wonder: assure, contributions, deceitful, ambrose, connects, sf, elseyou, talkedits,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, 11em,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, bryant,\n",
      "Nearest to religion: litmus, vaishnavism, industrialized, behe, traditional, veda, fad, saxons,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, whod, gaps, 1215, policyif, restructuring,\n",
      "Nearest to french: italians, france, crowns, tenor, franoisbernard, stubbornly, most, aires,\n",
      "Nearest to event: povi, furries, occurrences, candice, events, venture, change, lined,\n",
      "Epoch 18/50 Iteration: 38100 Avg. Training loss: 4.0622 0.3280 sec/batch\n",
      "Epoch 18/50 Iteration: 38200 Avg. Training loss: 4.0396 0.2700 sec/batch\n",
      "Epoch 18/50 Iteration: 38300 Avg. Training loss: 4.0582 0.2765 sec/batch\n",
      "Epoch 18/50 Iteration: 38400 Avg. Training loss: 4.0296 0.2936 sec/batch\n",
      "Epoch 19/50 Iteration: 38500 Avg. Training loss: 3.5369 0.1863 sec/batch\n",
      "Epoch 19/50 Iteration: 38600 Avg. Training loss: 3.8501 0.2676 sec/batch\n",
      "Epoch 19/50 Iteration: 38700 Avg. Training loss: 4.0140 0.2983 sec/batch\n",
      "Epoch 19/50 Iteration: 38800 Avg. Training loss: 4.0448 0.3311 sec/batch\n",
      "Epoch 19/50 Iteration: 38900 Avg. Training loss: 4.0263 0.2884 sec/batch\n",
      "Epoch 19/50 Iteration: 39000 Avg. Training loss: 4.0284 0.3111 sec/batch\n",
      "Nearest to was: because, enjoying, hoe, angelina, collectible, cyde, problems, ministers,\n",
      "Nearest to them: untagged, they, read, hours, useif, following, contr, wherever,\n",
      "Nearest to on: for, talk, this, check, four, of, page, and,\n",
      "Nearest to not: that, bs, try, test, people, well, donaire, second,\n",
      "Nearest to use: fair, uploading, specifies, boilerplate, or, bongwarriorcongratualtions, image, logogif,\n",
      "Nearest to does: hom, real, 613, basic, theocracy, included, via, refuse,\n",
      "Nearest to the: of, one, that, please, be, page, if, may,\n",
      "Nearest to but: existing, vertigo, 5i, that, many, think, labyrinth, aware,\n",
      "Nearest to poor: aholes, plaque, suffers, of, talkyou, prospects, criticized, gimme,\n",
      "Nearest to wonder: assure, sf, deceitful, contributions, ambrose, elseyou, connects, wheeler,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, 11em, defender,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, bryant,\n",
      "Nearest to religion: litmus, vaishnavism, industrialized, veda, traditional, behe, fad, religions,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, whod, opine, gaps, 1215, policyif,\n",
      "Nearest to french: italians, crowns, france, franoisbernard, tenor, stubbornly, aires, most,\n",
      "Nearest to event: povi, occurrences, furries, events, candice, venture, lined, warrant,\n",
      "Epoch 19/50 Iteration: 39100 Avg. Training loss: 4.0369 0.4726 sec/batch\n",
      "Epoch 19/50 Iteration: 39200 Avg. Training loss: 4.0211 0.4262 sec/batch\n",
      "Epoch 19/50 Iteration: 39300 Avg. Training loss: 4.0023 0.3687 sec/batch\n",
      "Epoch 19/50 Iteration: 39400 Avg. Training loss: 4.0284 0.2917 sec/batch\n",
      "Epoch 19/50 Iteration: 39500 Avg. Training loss: 4.0210 0.3068 sec/batch\n",
      "Epoch 19/50 Iteration: 39600 Avg. Training loss: 4.0237 0.2876 sec/batch\n",
      "Epoch 19/50 Iteration: 39700 Avg. Training loss: 4.0210 0.3158 sec/batch\n",
      "Epoch 19/50 Iteration: 39800 Avg. Training loss: 4.0294 0.2953 sec/batch\n",
      "Epoch 19/50 Iteration: 39900 Avg. Training loss: 4.0526 0.3123 sec/batch\n",
      "Epoch 19/50 Iteration: 40000 Avg. Training loss: 4.0491 0.3063 sec/batch\n",
      "Nearest to was: because, enjoying, angelina, once, hoe, collectible, cyde, monasteries,\n",
      "Nearest to them: untagged, they, read, hours, useif, following, after, contr,\n",
      "Nearest to on: for, talk, this, check, four, page, of, my,\n",
      "Nearest to not: that, bs, well, people, it, ethereal, try, please,\n",
      "Nearest to use: fair, or, specifies, uploading, boilerplate, image, used, other,\n",
      "Nearest to does: included, real, hom, 613, theocracy, via, pulleys, space,\n",
      "Nearest to the: one, of, be, that, page, please, if, at,\n",
      "Nearest to but: that, vertigo, existing, 5i, think, many, popup, is,\n",
      "Nearest to poor: aholes, plaque, prospects, suffers, talkyou, criticized, embodiment, paradigm,\n",
      "Nearest to wonder: assure, sf, contributions, talkedits, deceitful, connects, hogan, wheeler,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, 11em,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, bryant,\n",
      "Nearest to religion: vaishnavism, litmus, industrialized, veda, behe, traditional, religions, wicca,\n",
      "Nearest to difficult: descriptions, calvinism, treatises, 1215, gaps, policyif, whod, opine,\n",
      "Nearest to french: italians, france, crowns, franoisbernard, tenor, most, aires, wll,\n",
      "Nearest to event: povi, occurrences, events, furries, change, candice, venture, warrant,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 Iteration: 40100 Avg. Training loss: 3.9972 0.2978 sec/batch\n",
      "Epoch 19/50 Iteration: 40200 Avg. Training loss: 4.0085 0.3108 sec/batch\n",
      "Epoch 19/50 Iteration: 40300 Avg. Training loss: 4.0379 0.3565 sec/batch\n",
      "Epoch 19/50 Iteration: 40400 Avg. Training loss: 4.0256 0.3096 sec/batch\n",
      "Epoch 19/50 Iteration: 40500 Avg. Training loss: 4.0233 0.3202 sec/batch\n",
      "Epoch 20/50 Iteration: 40600 Avg. Training loss: 3.6437 0.0963 sec/batch\n",
      "Epoch 20/50 Iteration: 40700 Avg. Training loss: 3.7632 0.2953 sec/batch\n",
      "Epoch 20/50 Iteration: 40800 Avg. Training loss: 3.9383 0.3123 sec/batch\n",
      "Epoch 20/50 Iteration: 40900 Avg. Training loss: 3.9955 0.2954 sec/batch\n",
      "Epoch 20/50 Iteration: 41000 Avg. Training loss: 4.0242 0.2988 sec/batch\n",
      "Nearest to was: because, once, 6912122197, hoe, enjoying, cyde, angelina, collectible,\n",
      "Nearest to them: they, untagged, read, following, hours, useif, contr, have,\n",
      "Nearest to on: for, this, talk, check, four, page, of, my,\n",
      "Nearest to not: people, that, it, bs, well, test, please, to,\n",
      "Nearest to use: fair, specifies, boilerplate, uploading, bongwarriorcongratualtions, or, image, logogif,\n",
      "Nearest to does: hom, real, refuse, via, utterly, theocracy, included, basic,\n",
      "Nearest to the: one, of, that, be, page, may, please, if,\n",
      "Nearest to but: that, existing, 5i, would, vertigo, is, think, many,\n",
      "Nearest to poor: aholes, plaque, of, suffers, talkyou, prospects, criticized, amicus,\n",
      "Nearest to wonder: assure, sf, ambrose, contributions, wheeler, connects, deceitful, elseyou,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, barnstars,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, greg, bryant,\n",
      "Nearest to religion: vaishnavism, litmus, industrialized, veda, religions, behe, traditional, fairbairn,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, 1215, whod, policyif, gaps, coding,\n",
      "Nearest to french: italians, france, crowns, franoisbernard, wll, most, aires, michel,\n",
      "Nearest to event: povi, events, furries, occurrences, change, venture, candice, warrant,\n",
      "Epoch 20/50 Iteration: 41100 Avg. Training loss: 3.9929 0.2968 sec/batch\n",
      "Epoch 20/50 Iteration: 41200 Avg. Training loss: 4.0050 0.3256 sec/batch\n",
      "Epoch 20/50 Iteration: 41300 Avg. Training loss: 4.0375 0.3360 sec/batch\n",
      "Epoch 20/50 Iteration: 41400 Avg. Training loss: 4.0119 0.4219 sec/batch\n",
      "Epoch 20/50 Iteration: 41500 Avg. Training loss: 4.0131 0.4046 sec/batch\n",
      "Epoch 20/50 Iteration: 41600 Avg. Training loss: 4.0173 0.5773 sec/batch\n",
      "Epoch 20/50 Iteration: 41700 Avg. Training loss: 4.0555 0.6565 sec/batch\n",
      "Epoch 20/50 Iteration: 41800 Avg. Training loss: 4.0047 0.6149 sec/batch\n",
      "Epoch 20/50 Iteration: 41900 Avg. Training loss: 3.9960 0.6458 sec/batch\n",
      "Epoch 20/50 Iteration: 42000 Avg. Training loss: 4.0168 0.6546 sec/batch\n",
      "Nearest to was: because, collectible, once, raja, monasteries, hoe, enjoying, 6912122197,\n",
      "Nearest to them: untagged, they, read, hours, contr, following, satirical, useif,\n",
      "Nearest to on: talk, for, this, check, four, page, of, my,\n",
      "Nearest to not: that, try, bs, people, it, well, second, argue,\n",
      "Nearest to use: fair, specifies, or, boilerplate, uploading, image, used, bongwarriorcongratualtions,\n",
      "Nearest to does: included, real, hom, via, theocracy, 613, southgate, space,\n",
      "Nearest to the: of, one, be, page, at, that, if, time,\n",
      "Nearest to but: vertigo, existing, that, 5i, many, there, what, wpbefore,\n",
      "Nearest to poor: plaque, aholes, prospects, of, amicus, suffers, criticized, talkyou,\n",
      "Nearest to wonder: assure, sf, ambrose, wheeler, hogan, contributions, connects, talkedits,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, churn, defender, barnstars,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, archeology, bryant, greg,\n",
      "Nearest to religion: vaishnavism, litmus, veda, industrialized, religions, behe, wicca, traditional,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, 1215, policyif, gaps, whod, travelled,\n",
      "Nearest to french: italians, france, crowns, franoisbernard, tenor, aires, most, des,\n",
      "Nearest to event: events, povi, occurrences, change, furries, venture, candice, warrant,\n",
      "Epoch 20/50 Iteration: 42100 Avg. Training loss: 4.0373 0.6835 sec/batch\n",
      "Epoch 20/50 Iteration: 42200 Avg. Training loss: 4.0231 0.6313 sec/batch\n",
      "Epoch 20/50 Iteration: 42300 Avg. Training loss: 3.9907 0.7236 sec/batch\n",
      "Epoch 20/50 Iteration: 42400 Avg. Training loss: 4.0407 0.7663 sec/batch\n",
      "Epoch 20/50 Iteration: 42500 Avg. Training loss: 4.0151 0.8871 sec/batch\n",
      "Epoch 20/50 Iteration: 42600 Avg. Training loss: 4.0266 0.7514 sec/batch\n",
      "Epoch 20/50 Iteration: 42700 Avg. Training loss: 4.0187 0.7134 sec/batch\n",
      "Epoch 21/50 Iteration: 42800 Avg. Training loss: 3.4160 0.6500 sec/batch\n",
      "Epoch 21/50 Iteration: 42900 Avg. Training loss: 3.8622 0.4217 sec/batch\n",
      "Epoch 21/50 Iteration: 43000 Avg. Training loss: 4.0525 0.3827 sec/batch\n",
      "Nearest to was: because, once, hoe, angelina, collectible, until, ministers, shop,\n",
      "Nearest to them: they, untagged, read, following, hours, have, useif, these,\n",
      "Nearest to on: talk, for, this, and, my, of, check, page,\n",
      "Nearest to not: that, people, try, bs, it, from, with, to,\n",
      "Nearest to use: fair, specifies, or, boilerplate, image, bongwarriorcongratualtions, uploading, other,\n",
      "Nearest to does: hom, via, real, licks, included, basic, refuse, pulleys,\n",
      "Nearest to the: of, one, be, if, page, that, time, at,\n",
      "Nearest to but: that, is, think, existing, vertigo, many, not, the,\n",
      "Nearest to poor: plaque, aholes, of, prospects, suffers, talkyou, amicus, tryin,\n",
      "Nearest to wonder: assure, sf, ambrose, wheeler, elseyou, connects, saying, site,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, churn, defender, barnstars,\n",
      "Nearest to controversial: hovind, sherrod, remarks, bernard, flynn, bryant, archeology, cannon,\n",
      "Nearest to religion: litmus, vaishnavism, industrialized, veda, fairbairn, religions, behe, traditional,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, 1215, policyif, whod, gaps, coding,\n",
      "Nearest to french: italians, france, crowns, franoisbernard, most, wll, michel, aires,\n",
      "Nearest to event: events, povi, occurrences, change, furries, venture, candice, warrant,\n",
      "Epoch 21/50 Iteration: 43100 Avg. Training loss: 4.0170 0.4178 sec/batch\n",
      "Epoch 21/50 Iteration: 43200 Avg. Training loss: 3.9974 0.4264 sec/batch\n",
      "Epoch 21/50 Iteration: 43300 Avg. Training loss: 4.0134 0.4057 sec/batch\n",
      "Epoch 21/50 Iteration: 43400 Avg. Training loss: 3.9961 0.4069 sec/batch\n",
      "Epoch 21/50 Iteration: 43500 Avg. Training loss: 3.9903 0.4448 sec/batch\n",
      "Epoch 21/50 Iteration: 43600 Avg. Training loss: 4.0104 0.4238 sec/batch\n",
      "Epoch 21/50 Iteration: 43700 Avg. Training loss: 4.0123 0.4330 sec/batch\n",
      "Epoch 21/50 Iteration: 43800 Avg. Training loss: 4.0186 0.4042 sec/batch\n",
      "Epoch 21/50 Iteration: 43900 Avg. Training loss: 3.9926 0.3962 sec/batch\n",
      "Epoch 21/50 Iteration: 44000 Avg. Training loss: 4.0014 0.4025 sec/batch\n",
      "Nearest to was: because, once, raja, collectible, were, angelina, until, snobbery,\n",
      "Nearest to them: they, untagged, read, useif, hours, satirical, following, after,\n",
      "Nearest to on: talk, for, this, and, check, four, of, page,\n",
      "Nearest to not: that, people, try, well, but, bs, it, second,\n",
      "Nearest to use: fair, specifies, image, or, other, uploading, boilerplate, page,\n",
      "Nearest to does: included, hom, via, real, basic, 613, cho, theocracy,\n",
      "Nearest to the: of, one, be, page, if, at, that, please,\n",
      "Nearest to but: think, that, existing, many, is, vertigo, not, 5i,\n",
      "Nearest to poor: plaque, suffers, aholes, prospects, amicus, of, criticized, talkyou,\n",
      "Nearest to wonder: assure, sf, ambrose, wheeler, connects, saying, category, esperanto,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, churn, defender, barnstars,\n",
      "Nearest to controversial: hovind, sherrod, remarks, bernard, flynn, bryant, archeology, remark,\n",
      "Nearest to religion: vaishnavism, litmus, industrialized, religions, veda, traditional, behe, fairbairn,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, 1215, coding, gaps, nonpov, travelled,\n",
      "Nearest to french: france, italians, crowns, wll, most, franoisbernard, tenor, michel,\n",
      "Nearest to event: occurrences, events, povi, change, furries, venture, candice, warrant,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 Iteration: 44100 Avg. Training loss: 4.0035 0.4558 sec/batch\n",
      "Epoch 21/50 Iteration: 44200 Avg. Training loss: 4.0290 0.4189 sec/batch\n",
      "Epoch 21/50 Iteration: 44300 Avg. Training loss: 4.0267 0.5020 sec/batch\n",
      "Epoch 21/50 Iteration: 44400 Avg. Training loss: 3.9705 0.4971 sec/batch\n",
      "Epoch 21/50 Iteration: 44500 Avg. Training loss: 4.0314 0.5131 sec/batch\n",
      "Epoch 21/50 Iteration: 44600 Avg. Training loss: 4.0039 0.4899 sec/batch\n",
      "Epoch 21/50 Iteration: 44700 Avg. Training loss: 4.0204 0.5599 sec/batch\n",
      "Epoch 21/50 Iteration: 44800 Avg. Training loss: 4.0037 0.7317 sec/batch\n",
      "Epoch 22/50 Iteration: 44900 Avg. Training loss: 3.4949 0.2973 sec/batch\n",
      "Epoch 22/50 Iteration: 45000 Avg. Training loss: 3.8260 0.4833 sec/batch\n",
      "Nearest to was: because, once, hoe, just, were, got, angelina, shop,\n",
      "Nearest to them: they, untagged, read, have, hours, that, after, these,\n",
      "Nearest to on: for, this, talk, and, my, of, a, to,\n",
      "Nearest to not: that, to, people, it, but, from, try, is,\n",
      "Nearest to use: fair, specifies, image, uploading, boilerplate, bongwarriorcongratualtions, fairuse, strikethrough,\n",
      "Nearest to does: licks, via, real, hom, refuse, basic, utterly, included,\n",
      "Nearest to the: of, one, be, that, to, if, time, a,\n",
      "Nearest to but: think, that, is, get, what, to, would, the,\n",
      "Nearest to poor: aholes, of, plaque, suffers, prospects, amicus, talkyou, criticized,\n",
      "Nearest to wonder: assure, sf, ambrose, wheeler, site, elseyou, saying, pointless,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, defender, barnstars, churn,\n",
      "Nearest to controversial: hovind, sherrod, remarks, bernard, flynn, bryant, greg, archeology,\n",
      "Nearest to religion: litmus, vaishnavism, industrialized, veda, fairbairn, behe, polarized, togetheri,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, 1215, gaps, coding, nonpov, whod,\n",
      "Nearest to french: france, italians, most, crowns, franoisbernard, wll, amerindian, aires,\n",
      "Nearest to event: occurrences, events, povi, venture, change, furries, rescuing, candice,\n",
      "Epoch 22/50 Iteration: 45100 Avg. Training loss: 3.9572 0.5337 sec/batch\n",
      "Epoch 22/50 Iteration: 45200 Avg. Training loss: 3.9946 0.4993 sec/batch\n",
      "Epoch 22/50 Iteration: 45300 Avg. Training loss: 4.0135 0.6078 sec/batch\n",
      "Epoch 22/50 Iteration: 45400 Avg. Training loss: 3.9743 0.5380 sec/batch\n",
      "Epoch 22/50 Iteration: 45500 Avg. Training loss: 4.0077 0.3655 sec/batch\n",
      "Epoch 22/50 Iteration: 45600 Avg. Training loss: 3.9951 0.3498 sec/batch\n",
      "Epoch 22/50 Iteration: 45700 Avg. Training loss: 3.9839 0.3459 sec/batch\n",
      "Epoch 22/50 Iteration: 45800 Avg. Training loss: 4.0113 0.3401 sec/batch\n",
      "Epoch 22/50 Iteration: 45900 Avg. Training loss: 4.0139 0.3787 sec/batch\n",
      "Epoch 22/50 Iteration: 46000 Avg. Training loss: 3.9995 0.3610 sec/batch\n",
      "Nearest to was: because, once, had, angelina, collectible, were, missed, shaun,\n",
      "Nearest to them: untagged, they, useif, after, satirical, have, read, following,\n",
      "Nearest to on: talk, for, check, this, and, pages, of, my,\n",
      "Nearest to not: that, try, is, to, well, but, from, second,\n",
      "Nearest to use: fair, specifies, boilerplate, image, or, include, uploading, other,\n",
      "Nearest to does: included, hom, via, real, licks, basic, refuse, 613,\n",
      "Nearest to the: of, one, be, if, to, page, that, please,\n",
      "Nearest to but: that, think, existing, aware, is, wikipediabusiness, the, not,\n",
      "Nearest to poor: plaque, suffers, aholes, amicus, prospects, thrill, criticized, talkyou,\n",
      "Nearest to wonder: assure, sf, wheeler, ambrose, deegan, category, contributions, mac,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, defender, barnstars, churn,\n",
      "Nearest to controversial: hovind, sherrod, remarks, bernard, flynn, bryant, greg, archeology,\n",
      "Nearest to religion: vaishnavism, litmus, veda, fairbairn, industrialized, traditional, behe, religions,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, 1215, coding, travelled, gaps, nonpov,\n",
      "Nearest to french: italians, france, crowns, most, amerindian, worthless, franoisbernard, facial,\n",
      "Nearest to event: occurrences, events, povi, change, rescuing, venture, candice, furries,\n",
      "Epoch 22/50 Iteration: 46100 Avg. Training loss: 3.9834 0.3226 sec/batch\n",
      "Epoch 22/50 Iteration: 46200 Avg. Training loss: 3.9815 0.3253 sec/batch\n",
      "Epoch 22/50 Iteration: 46300 Avg. Training loss: 4.0153 0.3583 sec/batch\n",
      "Epoch 22/50 Iteration: 46400 Avg. Training loss: 4.0162 0.3649 sec/batch\n",
      "Epoch 22/50 Iteration: 46500 Avg. Training loss: 3.9840 0.3544 sec/batch\n",
      "Epoch 22/50 Iteration: 46600 Avg. Training loss: 3.9958 0.3427 sec/batch\n",
      "Epoch 22/50 Iteration: 46700 Avg. Training loss: 4.0056 0.3376 sec/batch\n",
      "Epoch 22/50 Iteration: 46800 Avg. Training loss: 4.0004 0.3319 sec/batch\n",
      "Epoch 22/50 Iteration: 46900 Avg. Training loss: 3.9896 0.3104 sec/batch\n",
      "Epoch 23/50 Iteration: 47000 Avg. Training loss: 3.6494 0.0735 sec/batch\n",
      "Nearest to was: because, once, angelina, were, collectible, had, hoe, missed,\n",
      "Nearest to them: they, untagged, read, satirical, have, these, following, useif,\n",
      "Nearest to on: talk, for, this, check, pages, four, page, and,\n",
      "Nearest to not: that, well, but, try, test, donaire, from, familiarize,\n",
      "Nearest to use: fair, image, boilerplate, specifies, uploading, sandbox, used, checking,\n",
      "Nearest to does: hom, refuse, via, included, 613, elements, southgate, pulleys,\n",
      "Nearest to the: one, be, of, if, please, page, at, to,\n",
      "Nearest to but: commentsthe, think, aware, existing, many, not, would, labyrinth,\n",
      "Nearest to poor: suffers, aholes, plaque, of, criticized, prospects, talkyou, bandera,\n",
      "Nearest to wonder: assure, wheeler, sf, deegan, ambrose, mac, enterprising, esperanto,\n",
      "Nearest to barnstar: tireless, hereby, kindness, antivandalism, award, defender, barnstars, churn,\n",
      "Nearest to controversial: hovind, sherrod, bernard, remarks, flynn, bryant, archeology, greg,\n",
      "Nearest to religion: vaishnavism, litmus, veda, fairbairn, behe, religions, fad, togetheri,\n",
      "Nearest to difficult: descriptions, treatises, 1215, calvinism, gaps, travelled, whod, coding,\n",
      "Nearest to french: france, italians, most, crowns, franoisbernard, michel, themthis, amerindian,\n",
      "Nearest to event: occurrences, events, povi, venture, change, rescuing, furries, candice,\n",
      "Epoch 23/50 Iteration: 47100 Avg. Training loss: 3.7025 0.3422 sec/batch\n",
      "Epoch 23/50 Iteration: 47200 Avg. Training loss: 3.9150 0.3536 sec/batch\n",
      "Epoch 23/50 Iteration: 47300 Avg. Training loss: 3.9953 0.3752 sec/batch\n",
      "Epoch 23/50 Iteration: 47400 Avg. Training loss: 4.0191 0.4168 sec/batch\n",
      "Epoch 23/50 Iteration: 47500 Avg. Training loss: 3.9701 0.4376 sec/batch\n",
      "Epoch 23/50 Iteration: 47600 Avg. Training loss: 4.0084 0.4394 sec/batch\n",
      "Epoch 23/50 Iteration: 47700 Avg. Training loss: 4.0045 0.3836 sec/batch\n",
      "Epoch 23/50 Iteration: 47800 Avg. Training loss: 3.9790 0.3783 sec/batch\n",
      "Epoch 23/50 Iteration: 47900 Avg. Training loss: 3.9991 0.3962 sec/batch\n",
      "Epoch 23/50 Iteration: 48000 Avg. Training loss: 4.0113 0.3785 sec/batch\n",
      "Nearest to was: because, once, missed, angelina, collectible, had, it, ministers,\n",
      "Nearest to them: untagged, they, after, useif, read, hours, have, satirical,\n",
      "Nearest to on: for, talk, check, this, and, page, of, pages,\n",
      "Nearest to not: that, but, to, with, second, people, from, try,\n",
      "Nearest to use: fair, image, specifies, boilerplate, uploading, include, sandbox, wikipediause,\n",
      "Nearest to does: included, refuse, hom, as, licks, via, basic, space,\n",
      "Nearest to the: one, of, be, page, if, to, time, may,\n",
      "Nearest to but: think, that, not, aware, the, is, would, labyrinth,\n",
      "Nearest to poor: suffers, aholes, plaque, of, prospects, talkyou, criticized, thrill,\n",
      "Nearest to wonder: assure, wheeler, sf, deegan, ambrose, contributions, mac, category,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, barnstars, defender, teamwork,\n",
      "Nearest to controversial: hovind, sherrod, remarks, bernard, flynn, bryant, greg, archeology,\n",
      "Nearest to religion: vaishnavism, litmus, fairbairn, veda, religions, behe, traditional, propagated,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, coding, travelled, gaps, things, 1215,\n",
      "Nearest to french: france, italians, franoisbernard, most, michel, crowns, amerindian, des,\n",
      "Nearest to event: occurrences, events, povi, venture, change, afghani, rescuing, furries,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 Iteration: 48100 Avg. Training loss: 4.0015 0.3592 sec/batch\n",
      "Epoch 23/50 Iteration: 48200 Avg. Training loss: 3.9742 0.3548 sec/batch\n",
      "Epoch 23/50 Iteration: 48300 Avg. Training loss: 3.9860 0.3867 sec/batch\n",
      "Epoch 23/50 Iteration: 48400 Avg. Training loss: 3.9863 0.3958 sec/batch\n",
      "Epoch 23/50 Iteration: 48500 Avg. Training loss: 4.0282 0.3837 sec/batch\n",
      "Epoch 23/50 Iteration: 48600 Avg. Training loss: 4.0160 0.4274 sec/batch\n",
      "Epoch 23/50 Iteration: 48700 Avg. Training loss: 3.9751 0.3789 sec/batch\n",
      "Epoch 23/50 Iteration: 48800 Avg. Training loss: 3.9923 0.3688 sec/batch\n",
      "Epoch 23/50 Iteration: 48900 Avg. Training loss: 3.9703 0.4266 sec/batch\n",
      "Epoch 23/50 Iteration: 49000 Avg. Training loss: 3.9998 0.4417 sec/batch\n",
      "Nearest to was: because, once, angelina, hoe, were, raja, collectible, 2014the,\n",
      "Nearest to them: they, untagged, after, satirical, useif, read, have, contr,\n",
      "Nearest to on: for, talk, this, and, check, page, my, you,\n",
      "Nearest to not: to, that, well, from, is, want, with, but,\n",
      "Nearest to use: fair, specifies, image, boilerplate, uploading, checking, wikipediause, sandbox,\n",
      "Nearest to does: included, hom, refuse, via, real, space, band, 613,\n",
      "Nearest to the: one, of, be, page, if, that, to, top,\n",
      "Nearest to but: think, that, the, is, commentsthe, would, time, not,\n",
      "Nearest to poor: aholes, of, suffers, talkyou, plaque, prospects, embodiment, thrill,\n",
      "Nearest to wonder: assure, deegan, sf, wheeler, ambrose, runins, category, pointless,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, defender, barnstars, teamwork,\n",
      "Nearest to controversial: hovind, sherrod, remarks, bernard, flynn, bryant, archeology, greg,\n",
      "Nearest to religion: vaishnavism, litmus, fairbairn, veda, religions, propagated, behe, jainism,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, 1215, travelled, gaps, coding, things,\n",
      "Nearest to french: france, italians, franoisbernard, most, michel, worthless, crowns, aires,\n",
      "Nearest to event: occurrences, events, povi, venture, change, afghani, candice, rescuing,\n",
      "Epoch 23/50 Iteration: 49100 Avg. Training loss: 3.9928 0.4648 sec/batch\n",
      "Epoch 24/50 Iteration: 49200 Avg. Training loss: 3.3723 0.3610 sec/batch\n",
      "Epoch 24/50 Iteration: 49300 Avg. Training loss: 3.8463 0.4028 sec/batch\n",
      "Epoch 24/50 Iteration: 49400 Avg. Training loss: 4.0029 0.4257 sec/batch\n",
      "Epoch 24/50 Iteration: 49500 Avg. Training loss: 4.0048 0.4414 sec/batch\n",
      "Epoch 24/50 Iteration: 49600 Avg. Training loss: 3.9661 0.4187 sec/batch\n",
      "Epoch 24/50 Iteration: 49700 Avg. Training loss: 4.0013 0.4774 sec/batch\n",
      "Epoch 24/50 Iteration: 49800 Avg. Training loss: 3.9889 0.4064 sec/batch\n",
      "Epoch 24/50 Iteration: 49900 Avg. Training loss: 3.9857 0.4072 sec/batch\n",
      "Epoch 24/50 Iteration: 50000 Avg. Training loss: 3.9772 0.4227 sec/batch\n",
      "Nearest to was: because, once, hoe, had, raja, 2014the, missed, angelina,\n",
      "Nearest to them: they, untagged, after, satirical, useif, hours, following, these,\n",
      "Nearest to on: for, talk, check, this, of, and, my, page,\n",
      "Nearest to not: that, to, well, want, with, but, second, simply,\n",
      "Nearest to use: fair, specifies, boilerplate, uploading, image, constitutes, wikipediause, include,\n",
      "Nearest to does: hom, refuse, included, as, licks, real, via, space,\n",
      "Nearest to the: one, of, be, page, time, can, to, that,\n",
      "Nearest to but: that, think, is, the, would, commentsthe, not, wikipediabusiness,\n",
      "Nearest to poor: of, suffers, aholes, talkyou, prospects, thrill, plaque, at,\n",
      "Nearest to wonder: assure, wheeler, deegan, sf, barrage, runins, ambrose, pointless,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, barnstars, defender, teamwork,\n",
      "Nearest to controversial: hovind, sherrod, remarks, bernard, flynn, bryant, greg, archeology,\n",
      "Nearest to religion: vaishnavism, litmus, fairbairn, veda, religions, togetheri, rastafarian, jainism,\n",
      "Nearest to difficult: descriptions, treatises, calvinism, coding, gaps, travelled, 1215, things,\n",
      "Nearest to french: france, most, italians, franoisbernard, michel, facial, crowns, worthless,\n",
      "Nearest to event: occurrences, events, povi, venture, afghani, rescuing, change, open,\n",
      "Epoch 24/50 Iteration: 50100 Avg. Training loss: 3.9852 0.4016 sec/batch\n",
      "Epoch 24/50 Iteration: 50200 Avg. Training loss: 3.9711 0.3848 sec/batch\n",
      "Epoch 24/50 Iteration: 50300 Avg. Training loss: 3.9695 0.4223 sec/batch\n",
      "Epoch 24/50 Iteration: 50400 Avg. Training loss: 3.9669 0.4816 sec/batch\n",
      "Epoch 24/50 Iteration: 50500 Avg. Training loss: 3.9712 0.3926 sec/batch\n",
      "Epoch 24/50 Iteration: 50600 Avg. Training loss: 4.0073 0.4521 sec/batch\n",
      "Epoch 24/50 Iteration: 50700 Avg. Training loss: 4.0258 0.4635 sec/batch\n",
      "Epoch 24/50 Iteration: 50800 Avg. Training loss: 3.9279 0.4070 sec/batch\n",
      "Epoch 24/50 Iteration: 50900 Avg. Training loss: 4.0053 0.3585 sec/batch\n",
      "Epoch 24/50 Iteration: 51000 Avg. Training loss: 3.9807 0.3862 sec/batch\n",
      "Nearest to was: because, hoe, once, were, had, werent, missed, collectible,\n",
      "Nearest to them: they, untagged, satirical, after, these, hours, read, useif,\n",
      "Nearest to on: for, talk, this, check, of, page, and, you,\n",
      "Nearest to not: that, well, but, want, is, second, test, try,\n",
      "Nearest to use: fair, specifies, image, sandbox, uploading, boilerplate, used, checking,\n",
      "Nearest to does: included, hom, real, as, via, elements, band, space,\n",
      "Nearest to the: one, of, be, that, page, time, may, at,\n",
      "Nearest to but: that, think, would, the, is, time, commentsthe, not,\n",
      "Nearest to poor: suffers, aholes, of, prospects, plaque, thrill, criticized, talksee,\n",
      "Nearest to wonder: assure, sf, wheeler, barrage, deegan, runins, category, blazing,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, barnstars, teamwork, defender,\n",
      "Nearest to controversial: hovind, sherrod, remarks, flynn, bernard, bryant, archeology, astronomer,\n",
      "Nearest to religion: vaishnavism, litmus, fairbairn, religions, rastafarian, veda, propagated, criticise,\n",
      "Nearest to difficult: descriptions, treatises, gaps, 1215, calvinism, travelled, things, coding,\n",
      "Nearest to french: france, italians, most, franoisbernard, michel, facial, amerindian, worthless,\n",
      "Nearest to event: occurrences, events, venture, povi, afghani, change, warrant, candice,\n",
      "Epoch 24/50 Iteration: 51100 Avg. Training loss: 3.9891 0.4153 sec/batch\n",
      "Epoch 24/50 Iteration: 51200 Avg. Training loss: 3.9774 0.4452 sec/batch\n",
      "Epoch 25/50 Iteration: 51300 Avg. Training loss: 3.4897 0.2147 sec/batch\n",
      "Epoch 25/50 Iteration: 51400 Avg. Training loss: 3.7769 0.3570 sec/batch\n",
      "Epoch 25/50 Iteration: 51500 Avg. Training loss: 3.9647 0.4237 sec/batch\n",
      "Epoch 25/50 Iteration: 51600 Avg. Training loss: 3.9699 0.3976 sec/batch\n",
      "Epoch 25/50 Iteration: 51700 Avg. Training loss: 3.9627 0.3812 sec/batch\n",
      "Epoch 25/50 Iteration: 51800 Avg. Training loss: 3.9688 0.3611 sec/batch\n",
      "Epoch 25/50 Iteration: 51900 Avg. Training loss: 3.9883 0.3601 sec/batch\n",
      "Epoch 25/50 Iteration: 52000 Avg. Training loss: 3.9777 0.4101 sec/batch\n",
      "Nearest to was: because, once, hoe, had, missed, angelina, villains, were,\n",
      "Nearest to them: they, untagged, hours, satirical, after, read, these, wherever,\n",
      "Nearest to on: for, talk, check, and, four, this, page, of,\n",
      "Nearest to not: that, well, it, but, with, people, want, is,\n",
      "Nearest to use: fair, specifies, image, uploading, sandbox, strikethrough, or, boilerplate,\n",
      "Nearest to does: licks, included, band, hom, real, via, refuse, as,\n",
      "Nearest to the: one, of, page, be, can, at, if, that,\n",
      "Nearest to but: think, commentsthe, many, would, is, not, get, that,\n",
      "Nearest to poor: suffers, prospects, aholes, thrill, of, plaque, talksee, eratosthenes,\n",
      "Nearest to wonder: assure, sf, wheeler, ambrose, pavlicevic, category, deegan, barrage,\n",
      "Nearest to barnstar: tireless, hereby, antivandalism, kindness, award, barnstars, churn, malign,\n",
      "Nearest to controversial: hovind, sherrod, remarks, bernard, flynn, bryant, greg, archeology,\n",
      "Nearest to religion: vaishnavism, fairbairn, litmus, veda, traditional, religions, rastafarian, rastafari,\n",
      "Nearest to difficult: descriptions, treatises, travelled, 1215, calvinism, gaps, coding, higher,\n",
      "Nearest to french: france, most, italians, michel, facial, crowns, franoisbernard, worthless,\n",
      "Nearest to event: occurrences, events, povi, venture, change, afghani, rescuing, open,\n",
      "Epoch 25/50 Iteration: 52100 Avg. Training loss: 3.9396 0.3902 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 Iteration: 52200 Avg. Training loss: 3.9991 0.4388 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 1000\n",
    "window_size = 10\n",
    "\n",
    "with train_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    iteration = 1\n",
    "    loss = 0\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for e in range(1, epochs+1):\n",
    "        batches = get_batches(train_words, batch_size, window_size)\n",
    "        start = time.time()\n",
    "        for x, y in batches:\n",
    "            \n",
    "            feed = {inputs: x,\n",
    "                    labels: np.array(y)[:, None]}\n",
    "            train_loss, _ = sess.run([cost, optimizer], feed_dict=feed)\n",
    "            \n",
    "            loss += train_loss\n",
    "            \n",
    "            if iteration % 100 == 0: \n",
    "                end = time.time()\n",
    "                print(\"Epoch {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {}\".format(iteration),\n",
    "                      \"Avg. Training loss: {:.4f}\".format(loss/100),\n",
    "                      \"{:.4f} sec/batch\".format((end-start)/100))\n",
    "                loss = 0\n",
    "                start = time.time()\n",
    "            \n",
    "            if iteration % 1000 == 0:\n",
    "                # note that this is expensive (~20% slowdown if computed every 500 steps)\n",
    "                sim = similarity.eval()\n",
    "                for i in range(valid_size):\n",
    "                    valid_word = int_to_vocab[valid_examples[i]]\n",
    "                    top_k = 8 # number of nearest neighbors\n",
    "                    nearest = (-sim[i, :]).argsort()[1:top_k+1]\n",
    "                    log = 'Nearest to %s:' % valid_word\n",
    "                    for k in range(top_k):\n",
    "                        close_word = int_to_vocab[nearest[k]]\n",
    "                        log = '%s %s,' % (log, close_word)\n",
    "                    print(log)\n",
    "            \n",
    "            iteration += 1\n",
    "    save_path = saver.save(sess, \"../data/checkpoints/w2v_3allwords.ckpt\")\n",
    "    embed_mat = sess.run(normalized_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with train_graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('../data/checkpoints'))\n",
    "    embed_mat = sess.run(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "viz_words = 500\n",
    "tsne = TSNE()\n",
    "embed_tsne = tsne.fit_transform(embed_mat[:viz_words, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 14))\n",
    "ax.axis([-200.0,200.0, -200.0,200.0])\n",
    "ax = fig.gca()\n",
    "ax.set_autoscale_on(False)\n",
    "\n",
    "for idx in range(viz_words):\n",
    "    plt.scatter(*embed_tsne[idx, :], color='steelblue')\n",
    "    plt.annotate(int_to_vocab[idx], (embed_tsne[idx, 0], embed_tsne[idx, 1]), alpha=0.7)\n",
    "plt.savefig('w2v_3_AllWords.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
