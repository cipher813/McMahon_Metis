{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Generator LSTM Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/cipher000/anaconda3/envs/magenta/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install intervaltree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \n",
      "Music21 v.4 is the last version that will support Python 2.\n",
      "Please start using Python 3 instead.\n",
      "\n",
      "Set music21.environment.UserSettings()['warnings'] = 0\n",
      "to disable this message.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "module compiled against API version 0xb but this version of numpy is 0xa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: module compiled against API version 0xb but this version of numpy is 0xa"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from IPython.display import Audio\n",
    "from intervaltree import Interval, IntervalTree\n",
    "\n",
    "# from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes_file = '../data/notes'\n",
    "midi_files = '../data/Bach/*.mid'\n",
    "# midi_files = \"../midi_songs/*.mid\"\n",
    "# MusicNet_file = '/media/cipher000/DATA/Dropbox/Programming/MusicNet/Dataset/musicnet.npz'\n",
    "\n",
    "sequence_length = 100 # the lstm will predict the next note based on the last set of notes heard\n",
    "node1 = 512\n",
    "node2 = 256\n",
    "drop = 0.3\n",
    "epochs = 10 # 200\n",
    "batch_size = 64\n",
    "notes_generated = 500\n",
    "\n",
    "fs = 44100      # samples/second\n",
    "d = 2048        # input dimensions\n",
    "m = 128         # number of notes\n",
    "features = 0    # first element of (X,Y) data tuple\n",
    "labels = 1      # second element of (X,Y) data tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Midi Files from MusicNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notes():\n",
    "    \"\"\" Get all the notes and chords from the midi files in the ./midi_songs directory \"\"\"\n",
    "    notes = []\n",
    "    notes_dict = {}\n",
    "    cnt = 0\n",
    "\n",
    "#     for file in train_data.files:\n",
    "    for file in glob.glob(midi_files):\n",
    "        print(file)\n",
    "        notes_per_file = []\n",
    "#         print(\"Type: {} Length: {} Contents: {}\".format(type(file),len(file),file))\n",
    "#         print(\"Y Type: {} Length: {} Contents: {}\".format(type(Y),len(Y),Y))\n",
    "\n",
    "        midi = converter.parse(file)\n",
    "#         print(type(midi))\n",
    "#         notes_to_parse = None\n",
    "\n",
    "        parts = instrument.partitionByInstrument(midi)\n",
    "#         print(type(parts))\n",
    "        if parts: # file has instrument parts\n",
    "            notes_to_parse = parts.parts[0].recurse()\n",
    "        else: # file has notes in a flat structure\n",
    "            notes_to_parse = midi.flat.notes\n",
    "        \n",
    "        for element in notes_to_parse:\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "                notes_per_file.append(str(element.pitch))\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                to_append = '.'.join(str(n) for n in element.normalOrder)\n",
    "                notes.append(to_append)\n",
    "                notes_per_file.append(to_append)\n",
    "        notes_dict[file] = notes_per_file\n",
    "        cnt +=1\n",
    "    with open(notes_file, 'wb') as filepath:\n",
    "        pickle.dump(notes, filepath)\n",
    "    print(\"{} midi files and {} notes\".format(cnt,type(notes)))\n",
    "    return notes,cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/Bach/B0304.mid\n",
      "../data/Bach/B0101.mid\n",
      "../data/Bach/B0102.mid\n",
      "../data/Bach/B0103.mid\n",
      "../data/Bach/B0104.mid\n",
      "../data/Bach/B0105.mid\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-fc3ec0ef3d4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnotes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_notes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-4030ffe06e73>\u001b[0m in \u001b[0;36mget_notes\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         print(\"Y Type: {} Length: {} Contents: {}\".format(type(Y),len(Y),Y))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mmidi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#         print(type(midi))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         notes_to_parse = None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/converter/__init__.pyc\u001b[0m in \u001b[0;36mparse\u001b[0;34m(value, *args, **keywords)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m         return parseFile(value, number=number, format=m21Format,\n\u001b[0;32m-> 1110\u001b[0;31m                          forceSource=forceSource, **keywords)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         return parseFile(common.cleanpath(value), number=number, format=m21Format,\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/converter/__init__.pyc\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m     \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcleanpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforceSource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/converter/__init__.pyc\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(self, fp, number, format, forceSource, storePickle, **keywords)\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0menvironLocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintDebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading original version\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFileNoPickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwritePickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTrue\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfpPickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mstorePickle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m                 \u001b[0;31m# save the stream to disk...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/converter/__init__.pyc\u001b[0m in \u001b[0;36mparseFileNoPickle\u001b[0;34m(self, fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubConverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparseFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mConverterFileException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File is not in a correct format: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/converter/subConverters.pyc\u001b[0m in \u001b[0;36mparseFile\u001b[0;34m(self, fp, number, **keywords)\u001b[0m\n\u001b[1;32m    917\u001b[0m         '''\n\u001b[1;32m    918\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mmusic21\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtranslate\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmidiTranslate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         \u001b[0mmidiTranslate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidiFilePathToStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/midi/translate.pyc\u001b[0m in \u001b[0;36mmidiFilePathToStream\u001b[0;34m(filePath, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   1950\u001b[0m     \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1951\u001b[0m     \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1952\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmidiFileToStream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputM21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/midi/translate.pyc\u001b[0m in \u001b[0;36mmidiFileToStream\u001b[0;34m(mf, inputM21, quantizePost, **keywords)\u001b[0m\n\u001b[1;32m   2091\u001b[0m                             \u001b[0mquantizePost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquantizePost\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2092\u001b[0m                             \u001b[0minputM21\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2093\u001b[0;31m                             **keywords)\n\u001b[0m\u001b[1;32m   2094\u001b[0m         \u001b[0;31m#s._setMidiTracks(mf.tracks, mf.ticksPerQuarterNote)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/midi/translate.pyc\u001b[0m in \u001b[0;36mmidiTracksToStreams\u001b[0;34m(midiTracks, ticksPerQuarter, quantizePost, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   1852\u001b[0m             \u001b[0mstreamPart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# create a part instance for each part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m             midiTrackToStream(mt, ticksPerQuarter, quantizePost,\n\u001b[0;32m-> 1854\u001b[0;31m                               inputM21=streamPart, **keywords)\n\u001b[0m\u001b[1;32m   1855\u001b[0m \u001b[0;31m#             streamPart._setMidiTracksPart(mt,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[0;31m#                 ticksPerQuarter=ticksPerQuarter, quantizePost=quantizePost)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/midi/translate.pyc\u001b[0m in \u001b[0;36mmidiTrackToStream\u001b[0;34m(mt, ticksPerQuarter, quantizePost, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   1637\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1638\u001b[0m         \u001b[0;31m# this procedure will make the appropriate rests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1639\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakeVoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minPlace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillGaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1640\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1641\u001b[0m         \u001b[0;31m# always need to fill gaps, as rests are not found in any other way\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/stream/__init__.pyc\u001b[0m in \u001b[0;36mmakeVoices\u001b[0;34m(self, inPlace, fillGaps)\u001b[0m\n\u001b[1;32m   9807\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturnObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misSorted\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9808\u001b[0m             \u001b[0mreturnObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9809\u001b[0;31m         \u001b[0molDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturnObj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOverlaps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9810\u001b[0m         \u001b[0;31m#environLocal.printDebug(['makeVoices(): olDict', olDict])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9811\u001b[0m         \u001b[0;31m# find the max necessary voices by finding the max number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/stream/__init__.pyc\u001b[0m in \u001b[0;36mgetOverlaps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   9462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9463\u001b[0m         '''\n\u001b[0;32m-> 9464\u001b[0;31m         \u001b[0moverlapMap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_findLayering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9465\u001b[0m         \u001b[0;31m#environLocal.printDebug(['overlapMap', overlapMap])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/cipher000/anaconda3/envs/magenta/lib/python2.7/site-packages/music21/stream/__init__.pyc\u001b[0m in \u001b[0;36m_findLayering\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   9276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9277\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9278\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mdurSpanOverlapCache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhashKey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   9279\u001b[0m                         \u001b[0moverlapMap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9280\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "notes, cnt = get_notes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "\n",
    "\n",
    "    # get all pitch names\n",
    "    pitchnames = sorted(set(item for item in notes))\n",
    "\n",
    "     # create a dictionary to map pitches to integers\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "\n",
    "    network_input = []\n",
    "    network_output = []\n",
    "\n",
    "    # create input sequences and the corresponding outputs\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "#         print(\"Sequence in: {}\".format(sequence_in))\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "#         print(\"Sequence out: {}\".format(sequence_out))\n",
    "        input_append = [note_to_int[char] for char in sequence_in]\n",
    "        network_input.append(input_append)\n",
    "#         print(\"Network input: {}\".format(input_append))\n",
    "        output_append = note_to_int[sequence_out]\n",
    "        network_output.append(output_append)\n",
    "#         print(\"Network output: {}\".format(output_append))\n",
    "\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    print(\"Number of Patterns: {}\".format(n_patterns))\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    print(\"Network input reshaped: {}\".format(network_input.shape))\n",
    "    \n",
    "    # normalize input\n",
    "    network_input = network_input / float(n_vocab)\n",
    "    print(\"Network input over float n_vocab: {}\".format(network_input.shape))\n",
    "\n",
    "    network_output = np_utils.to_categorical(network_output)\n",
    "    print(\"Network output: {}\".format(network_output.shape))\n",
    "\n",
    "    return (network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = len(set(notes))\n",
    "\n",
    "network_input, network_output = prepare_sequences(notes, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(network_input, n_vocab,weights_file=None):\n",
    "    \"\"\" create the structure of the neural network \"\"\"\n",
    "\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(node1,input_shape=(network_input.shape[1], network_input.shape[2]),return_sequences=True))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(LSTM(node1, return_sequences=True))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(LSTM(node1))\n",
    "    model.add(Dense(node2))\n",
    "    model.add(Dropout(drop))\n",
    "    model.add(Dense(n_vocab))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    # Load the weights to each node\n",
    "    try:\n",
    "        model.load_weights(weights_file)\n",
    "        print(\"Weights file loaded: {}\".format(weights_file))\n",
    "    except Exception as e:\n",
    "        print(\"Training mode (No weights file)\")\n",
    "#         print(e)\n",
    "        pass\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(network_input, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, network_input, network_output):\n",
    "    \"\"\" train the neural network \"\"\"\n",
    "\n",
    "    filepath = \"../weights/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
    "    weights_file = filepath\n",
    "    print(\"Weights File Update to {}\".format(weights_file))\n",
    "#     print(filepath)\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        filepath,\n",
    "        monitor='loss',\n",
    "        verbose=0,\n",
    "        save_best_only=True,\n",
    "        mode='min'\n",
    "    )\n",
    "    callbacks_list = [checkpoint]\n",
    "\n",
    "    model.fit(network_input, network_output, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, network_input, network_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test and Create Midi File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = '../weights/weights.hdf5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the notes used to train the model\n",
    "with open(notes_file, 'rb') as filepath:\n",
    "    notes = pickle.load(filepath)\n",
    "print(\"Length of notes: {}\".format(len(notes)))\n",
    "# Get all pitch names\n",
    "pitchnames = sorted(set(item for item in notes))\n",
    "print(\"Length of Pitch Names: {}\".format(len(pitchnames)))\n",
    "\n",
    "# Get all pitch names\n",
    "n_vocab = len(set(notes))\n",
    "print(\"Length of N Vocab: {}\".format(n_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequences(notes, pitchnames, n_vocab):\n",
    "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
    "#     sequence_length = 100\n",
    "    network_input = []\n",
    "    output = []\n",
    "    \n",
    "    # map between notes and integers and back\n",
    "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
    "    print(\"Note to Integer Dictionary Length: {}\".format(len(note_to_int)))\n",
    "\n",
    "    for i in range(0, len(notes) - sequence_length, 1):\n",
    "        sequence_in = notes[i:i + sequence_length]\n",
    "        sequence_out = notes[i + sequence_length]\n",
    "        network_input.append([note_to_int[char] for char in sequence_in])\n",
    "        output.append(note_to_int[sequence_out])\n",
    "#         print(\"Preparation {}: {}\".format(i,note_to_int[sequence_out]))\n",
    "\n",
    "    n_patterns = len(network_input)\n",
    "    print(\"N Patterns Length: {}\".format(n_patterns))\n",
    "\n",
    "    # reshape the input into a format compatible with LSTM layers\n",
    "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
    "    # normalize input\n",
    "    normalized_input = normalized_input / float(n_vocab)\n",
    "    print(\"Network Input Shape: {}  Normalized Input Shape: {}\".format(len(network_input), len(normalized_input)))\n",
    "\n",
    "    return (network_input, normalized_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(normalized_input, n_vocab,weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
    "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
    "    # pick a random sequence from the input as a starting point for the prediction\n",
    "    start = np.random.randint(0, len(network_input)-1)\n",
    "    print(\"Start: {}\".format(start))\n",
    "\n",
    "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
    "    print(\"Int to Note Length: {}\".format(len(int_to_note)))\n",
    "    \n",
    "    pattern = network_input[start]\n",
    "    prediction_output = []\n",
    "#     print(\"Pattern: {}  Prediction Output: {}\".format(pattern, prediction_output))\n",
    "\n",
    "    # generate 500 notes\n",
    "    for note_index in range(notes_generated):\n",
    "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
    "        prediction_input = prediction_input / float(n_vocab)\n",
    "\n",
    "        prediction = model.predict(prediction_input, verbose=0)\n",
    "\n",
    "        index = np.argmax(prediction)\n",
    "        result = int_to_note[index]\n",
    "        prediction_output.append(result)\n",
    "\n",
    "        pattern.append(index)\n",
    "        pattern = pattern[1:len(pattern)]\n",
    "#         print(\"Pattern: {}\".format(pattern))\n",
    "#     print(\"Prediction Output: {}\".format(prediction_output))\n",
    "    print(\"Notes generated: {}\".format(notes_generated))\n",
    "    return prediction_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_midi(prediction_output):\n",
    "    \"\"\" convert the output from the prediction to notes and create a midi file\n",
    "        from the notes \"\"\"\n",
    "    offset = 0\n",
    "    output_notes = []\n",
    "\n",
    "    # create note and chord objects based on the values generated by the model\n",
    "#     print(\"Prediction Output: {}\".format(prediction_output))\n",
    "    for pattern in prediction_output:\n",
    "        # pattern is a chord\n",
    "        if ('.' in pattern) or pattern.isdigit():\n",
    "            notes_in_chord = pattern.split('.')\n",
    "            notes = []\n",
    "            for current_note in notes_in_chord:\n",
    "                new_note = note.Note(int(current_note))\n",
    "                new_note.storedInstrument = instrument.Piano()\n",
    "                notes.append(new_note)\n",
    "            new_chord = chord.Chord(notes)\n",
    "            new_chord.offset = offset\n",
    "            output_notes.append(new_chord)\n",
    "#             print(\"Pattern: {} New Chord: {}\".format(pattern, new_chord))\n",
    "        # pattern is a note\n",
    "        else:\n",
    "            new_note = note.Note(pattern)\n",
    "            new_note.offset = offset\n",
    "            new_note.storedInstrument = instrument.Piano()\n",
    "            output_notes.append(new_note)\n",
    "#             print(\"Pattern: {} New Note: {}\".format(pattern, new_note))\n",
    "\n",
    "        # increase offset each iteration so that notes do not stack\n",
    "        offset += 0.5\n",
    "\n",
    "    midi_stream = stream.Stream(output_notes)\n",
    "    print(\"Midi Stream: {}\".format(midi_stream))\n",
    "    output_file = '../output/{}{}.mid'.format(weights_file,epochs)\n",
    "\n",
    "    midi_stream.write('midi', fp=output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_midi(prediction_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model adapted from Towards Data Science blog [here](https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5)\n",
    "with accompanying \"Classical Piano Composer\" github repo [here](https://github.com/Skuldur/Classical-Piano-Composer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download MusicNet from http://homes.cs.washington.edu/~thickstn/musicnet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
