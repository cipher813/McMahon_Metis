{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter: Classification\n",
    "Tests Include:\n",
    "-KNN\n",
    "-Logistic Regression\n",
    "-Decision Trees\n",
    "-Random Forest\n",
    "-SVM\n",
    "-Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB,MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.cross_validation import train_test_split, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import label_binarize, scale, StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomTreesEmbedding, RandomForestClassifier,\n",
    "                              GradientBoostingClassifier)\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #, category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# env variable at tensorflow1.4 per https://conda.io/docs/user-guide/tasks/manage-environments.html#saving-environment-variables\n",
    "# and https://vsupalov.com/flask-sqlalchemy-postgres/\n",
    "\n",
    "def get_env_variable(name):\n",
    "    try:\n",
    "        return os.environ[name]\n",
    "    except KeyError:\n",
    "        message = \"Expected environment variable '{}' not set.\".format(name)\n",
    "        raise Exception(message)\n",
    "\n",
    "# the values of those depend on your setup\n",
    "POSTGRES_URL = get_env_variable(\"POSTGRES_URL\")\n",
    "POSTGRES_USER = get_env_variable(\"POSTGRES_USER\")\n",
    "POSTGRES_PW = get_env_variable(\"POSTGRES_PW\")\n",
    "POSTGRES_DB = get_env_variable(\"POSTGRES_DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_URL = 'postgresql+psycopg2://{user}:{pw}@{url}/{db}'.format(user=POSTGRES_USER,pw=POSTGRES_PW,url=POSTGRES_URL,db=POSTGRES_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine_var = DB_URL\n",
    "engine = create_engine(engine_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19291, 67)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>main_category</th>\n",
       "      <th>main_category</th>\n",
       "      <th>currency</th>\n",
       "      <th>currency</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>successful</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>6083.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>successful</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>11169.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>successful</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>EUR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>30112.5</td>\n",
       "      <td>30615.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>successful</td>\n",
       "      <td>Music</td>\n",
       "      <td>Music</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1743.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>failed</td>\n",
       "      <td>Food</td>\n",
       "      <td>Food</td>\n",
       "      <td>USD</td>\n",
       "      <td>USD</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state main_category main_category currency currency    deadline  \\\n",
       "0  successful    Publishing    Publishing      USD      USD  2018-01-02   \n",
       "1  successful         Music         Music      USD      USD  2018-01-02   \n",
       "2  successful         Music         Music      EUR      EUR  2018-01-02   \n",
       "3  successful         Music         Music      USD      USD  2018-01-02   \n",
       "4      failed          Food          Food      USD      USD  2018-01-02   \n",
       "\n",
       "     launched  usd_goal_real  usd_pledged_real  \n",
       "0  2017-12-06         2000.0           6083.00  \n",
       "1  2017-11-30        10000.0          11169.56  \n",
       "2  2017-11-28        30112.5          30615.02  \n",
       "3  2017-12-09         1000.0           1743.00  \n",
       "4  2017-11-03       200000.0              1.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_pickle('data/kickstarter_data.pkl')\n",
    "df = pd.read_sql_query('''SELECT * FROM kickstarter_data''',engine)\n",
    "print(df.shape)\n",
    "pd.read_sql_query('''SELECT state, main_category, main_category, currency, currency, deadline, launched, usd_goal_real, usd_pledged_real FROM kickstarter_data LIMIT 5''',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['idx', 'state_successful', 'main_category_Comics',\n",
       "       'main_category_Crafts', 'main_category_Dance', 'main_category_Design',\n",
       "       'main_category_Fashion', 'main_category_Film & Video',\n",
       "       'main_category_Food', 'main_category_Games', 'main_category_Journalism',\n",
       "       'main_category_Music', 'main_category_Photography',\n",
       "       'main_category_Publishing', 'main_category_Technology',\n",
       "       'main_category_Theater', 'country_AU', 'country_BE', 'country_CA',\n",
       "       'country_CH', 'country_DE', 'country_DK', 'country_ES', 'country_FR',\n",
       "       'country_GB', 'country_HK', 'country_IE', 'country_IT', 'country_JP',\n",
       "       'country_LU', 'country_MX', 'country_NL', 'country_NO', 'country_NZ',\n",
       "       'country_SE', 'country_SG', 'country_US', 'currency_CAD',\n",
       "       'currency_CHF', 'currency_DKK', 'currency_EUR', 'currency_GBP',\n",
       "       'currency_HKD', 'currency_JPY', 'currency_MXN', 'currency_NOK',\n",
       "       'currency_NZD', 'currency_SEK', 'currency_SGD', 'currency_USD', 'ID',\n",
       "       'name', 'category', 'main_category', 'currency', 'deadline', 'goal',\n",
       "       'launched', 'pledged', 'state', 'backers', 'country', 'usd pledged',\n",
       "       'usd_pledged_real', 'usd_goal_real', 'campaign_length',\n",
       "       'pct_goal_achieved'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19291, 49)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['main_category_Comics', 'main_category_Crafts', 'main_category_Dance',\n",
       "       'main_category_Design', 'main_category_Fashion',\n",
       "       'main_category_Film & Video', 'main_category_Food',\n",
       "       'main_category_Games', 'main_category_Journalism',\n",
       "       'main_category_Music', 'main_category_Photography',\n",
       "       'main_category_Publishing', 'main_category_Technology',\n",
       "       'main_category_Theater', 'country_AU', 'country_BE', 'country_CA',\n",
       "       'country_CH', 'country_DE', 'country_DK', 'country_ES', 'country_FR',\n",
       "       'country_GB', 'country_HK', 'country_IE', 'country_IT', 'country_JP',\n",
       "       'country_LU', 'country_MX', 'country_NL', 'country_NO', 'country_NZ',\n",
       "       'country_SE', 'country_SG', 'country_US', 'currency_CAD',\n",
       "       'currency_CHF', 'currency_DKK', 'currency_EUR', 'currency_GBP',\n",
       "       'currency_HKD', 'currency_JPY', 'currency_MXN', 'currency_NOK',\n",
       "       'currency_NZD', 'currency_SEK', 'currency_SGD', 'currency_USD',\n",
       "       'usd_goal_real'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing all variables that cannot be known before a campaign is launched, such as # backers and $ pledged\n",
    "X = df.drop(['idx','ID','name', 'category', 'main_category', 'currency','pledged', \n",
    "             'state','country', 'usd pledged','deadline','launched','state_successful',\n",
    "             'backers', 'usd_pledged_real','campaign_length','pct_goal_achieved','goal'], 1)\n",
    "# X = df[['usd_goal_real','campaign_length']]\n",
    "y = df['state_successful']\n",
    "\n",
    "print(X.shape)\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13503, 49) (13503,)\n",
      "(5788, 49) (5788,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42, stratify=y)\n",
    "\n",
    "k_range = list(range(1, 101))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-7.02491707e-17  4.57803584e-17  1.05242203e-17  4.52541474e-17\n",
      "  3.52561381e-17  3.57823491e-17 -2.10484407e-18 -1.63125415e-17\n",
      "  3.57823491e-17  1.99960186e-17 -1.68387525e-17 -1.10504313e-17\n",
      "  1.84173856e-17  4.26230923e-17  2.99940279e-17  3.20988720e-17\n",
      "  3.63085601e-17 -3.15726610e-18  3.15726610e-18  1.47339085e-17\n",
      "  1.26290644e-17 -5.52521567e-18  1.02611148e-17 -1.68387525e-17\n",
      " -1.99960186e-17  5.26211017e-19  1.68387525e-17  9.47179830e-18\n",
      "  1.10504313e-17 -2.15746517e-17  2.59158926e-17  1.26290644e-17\n",
      " -1.26290644e-17 -1.15766424e-17 -1.14977107e-16  3.63085601e-17\n",
      " -3.15726610e-18  1.47339085e-17  3.42037161e-17  1.02611148e-17\n",
      " -1.68387525e-17  1.68387525e-17  1.10504313e-17  2.59158926e-17\n",
      "  1.26290644e-17 -1.26290644e-17 -1.15766424e-17 -1.14977107e-16\n",
      " -2.10484407e-18]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1.]\n"
     ]
    }
   ],
   "source": [
    "# https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "print(X_train_s.mean(axis=0))\n",
    "print(X_train_s.std(axis=0))\n",
    "\n",
    "X_combined_s = np.vstack((X_train_s, X_test_s))\n",
    "y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Deeper Dive on Select Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.72      0.69      3277\n",
      "          1       0.59      0.51      0.55      2511\n",
      "\n",
      "avg / total       0.63      0.63      0.63      5788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# pythonml p71\n",
    "lr = LogisticRegressionCV(random_state=42)\n",
    "lr.fit(X_train_s, y_train)\n",
    "predictions = lr.predict(X_test_s)\n",
    "print(classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\t==============================\n",
      "\tAccuracy: 0.6044920525224603\n",
      "\tAUC: 0.5905433851201191\n",
      "\n",
      "\n",
      "[[2276 1001]\n",
      " [1296 1215]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.69      0.66      3277\n",
      "          1       0.55      0.48      0.51      2511\n",
      "\n",
      "avg / total       0.60      0.60      0.60      5788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rf_range = list(range(1,2000,100))\n",
    "# model = ['RandomForest', RandomForestClassifier()]\n",
    "\n",
    "accuracy = []\n",
    "precision = []\n",
    "recall = []\n",
    "f1 = []\n",
    "auc = []\n",
    "error_rate = []\n",
    "\n",
    "# for rf in rf_range:\n",
    "# rfc = RandomForestClassifier(n_estimators=1000)\n",
    "# rfc.fit(X_train,y_train)\n",
    "# predictions = rfc.predict(X_test)\n",
    "# print(classification_report(y_test,predictions))\n",
    "# print(confusion_matrix(y_test,predictions))\n",
    "# print(roc_auc_score(y_test,predictions))\n",
    "\n",
    "kf = KFold(5, random_state=4444, shuffle=True) \n",
    "for train_idx, test_idx in kf.split(X, y=y):\n",
    "    model = RandomForestClassifier(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy.append(accuracy_score(y_test, y_pred))\n",
    "    precision.append(precision_score(y_test, y_pred))\n",
    "    recall.append(recall_score(y_test, y_pred))\n",
    "    f1.append(f1_score(y_test, y_pred))\n",
    "    auc.append(roc_auc_score(y_test, y_pred))\n",
    "    error_rate.append(np.mean(y_pred != y_test))\n",
    "\n",
    "# Calculate mean metric across K-folds\n",
    "mean_accuracy = np.mean(accuracy)\n",
    "mean_precision = np.mean(precision)\n",
    "mean_recall = np.mean(recall)\n",
    "mean_f1 = np.mean(f1)\n",
    "mean_auc = np.mean(auc)\n",
    "\n",
    "# Capture TPR and FPR from last fold for plotting\n",
    "y_score = model.predict_proba(X_test)[:,1]\n",
    "roc[model_name] = roc_curve(y_test, y_score)\n",
    "\n",
    "# Print formatted results\n",
    "print(model)\n",
    "print('\\t==============================')\n",
    "print('\\tAccuracy:', mean_accuracy)\n",
    "print('\\tAUC:', mean_auc)\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\t==============================\n",
      "\tAccuracy: 0.6036627505183138\n",
      "\tAUC: 0.5893176280089304\n",
      "\n",
      "\n",
      "[[2280  997]\n",
      " [1304 1207]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.70      0.66      3277\n",
      "          1       0.55      0.48      0.51      2511\n",
      "\n",
      "avg / total       0.60      0.60      0.60      5788\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models to test\n",
    "model_list = [\n",
    "#                 ['GaussianNB', GaussianNB()], \n",
    "#                 ['BernoulliNB', BernoulliNB()], # F1 0.60\n",
    "#                 ['MultinomialNB', MultinomialNB()], \n",
    "#                 ['DecisionTree', DecisionTreeClassifier()], \n",
    "                ['RandomForest', RandomForestClassifier()]] # F1 0.61\n",
    "#                 ['KNN', KNeighborsClassifier(38)], # best k from KNN model below; scale data\n",
    "#                 ['LogisticRegression', LogisticRegression()], \n",
    "#                 ['LogisticRegressionCV', LogisticRegressionCV()], # scale data; F1 0.62\n",
    "#                 ['SVM', SVC(probability=True)]] # scale data; F1 0.57\n",
    "\n",
    "# model_list_s = [['KNN', KNeighborsClassifier(38)], # best k from KNN model below; scale data\n",
    "# #                 ['LogisticRegression', LogisticRegression()], # scale data\n",
    "#                 ['LogisticRegressionCV', LogisticRegressionCV()], # scale data\n",
    "#                 ['SVM', SVC(probability=True)]] # scale data\n",
    "\n",
    "# Calculate metrics for each model\n",
    "roc = {}\n",
    "for model in model_list:\n",
    "#     if model in model_list_s:\n",
    "#         X_train = X_train_s\n",
    "#         X_test = X_test_s\n",
    "    \n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "    error_rate = []\n",
    "\n",
    "    # Perform K-Fold CV and calculate metrics for each fold\n",
    "    kf = KFold(5, random_state=4444, shuffle=True) \n",
    "    for train_idx, test_idx in kf.split(X, y=y):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        auc.append(roc_auc_score(y_test, y_pred))\n",
    "        error_rate.append(np.mean(y_pred != y_test))\n",
    "\n",
    "    # Calculate mean metric across K-folds\n",
    "    mean_accuracy = np.mean(accuracy)\n",
    "    mean_precision = np.mean(precision)\n",
    "    mean_recall = np.mean(recall)\n",
    "    mean_f1 = np.mean(f1)\n",
    "    mean_auc = np.mean(auc)\n",
    "\n",
    "    # Capture TPR and FPR from last fold for plotting\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    roc[model_name] = roc_curve(y_test, y_score)\n",
    "\n",
    "    # Print formatted results\n",
    "    print(model)\n",
    "    print('\\t==============================')\n",
    "    print('\\tAccuracy:', mean_accuracy)\n",
    "    print('\\tAUC:', mean_auc)\n",
    "    print('\\n')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_acc = []\n",
    "error_rate = []\n",
    "\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train_s, y_train)\n",
    "    pred_k = knn.predict(X_test_s)\n",
    "    k_acc.append(accuracy_score(y_test, pred_k))\n",
    "    error_rate.append(np.mean(pred_k != y_test))\n",
    "    \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(k_range, k_acc, '-', label = 'K Nearest Neighbor')\n",
    "# plt.plot(k_range,error_rate, '-',label = 'Error Rate')\n",
    "plt.title('Accuracy vs. Error')\n",
    "plt.xlabel('# of neighbors in knn')\n",
    "plt.ylabel('Accuracy / Error on Test Case')\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO get top 5 k values\n",
    "best_k = k_range[np.argmax(k_acc)]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "knn.fit(X_train_s,y_train)\n",
    "pred = knn.predict(X_test_s)\n",
    "\n",
    "print('WITH Best K')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_decision_regions(X=X_combined_s,\n",
    "#                       y=y_combined,\n",
    "#                       classifier=knn,\n",
    "#                       test_idx=range(105, 150))\n",
    "# plt.xlabel('petal length [standardized]')\n",
    "# plt.ylabel('petal width [standardized]')\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vanilla case\n",
    "# logmodel = LogisticRegression()\n",
    "# logmodel.fit(X_train_s,y_train)\n",
    "\n",
    "# predictions = logmodel.predict(X_test_s)\n",
    "# print(classification_report(y_test,predictions))\n",
    "# # logmodel.coef_\n",
    "# logmodel.predict_proba(X_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vanilla case\n",
    "# logmodel = LogisticRegressionCV()\n",
    "# logmodel.fit(X_train_s,y_train)\n",
    "\n",
    "# predictions = logmodel.predict(X_test_s)\n",
    "# print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Training Examples vs. Accuracy\n",
    "# fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "# plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "# plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "# plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "# ax.set_title('Learning Curves (LogisticRegression)')\n",
    "# ax.set_xlabel('Training Examples')\n",
    "# ax.set_ylabel('Accuracy')\n",
    "# ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "log_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean()\n",
    "log_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(), \n",
    "                                                        X, y,\n",
    "                                                        cv=10, \n",
    "                                                        scoring='accuracy')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predictions = logmodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = svc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtree.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = rfc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(StandardScaler(), \n",
    "                         RandomForestRegressor(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = naive_bayes.GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = naive_bayes.BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = scale(X_train)\n",
    "X_test = scale(X_test)\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the weighted precision and recall\n",
    "print('Weighted Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted Recall:', recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred)) #, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = OneVsRestClassifier(LogisticRegression())\n",
    "logreg.fit(X_train, y_train)\n",
    "y_score = logreg.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Micro Average Precision:', average_precision_score(y_test, y_score, average='micro'))\n",
    "print('Macro Average Precision:', average_precision_score(y_test, y_score, average='macro'))\n",
    "print('Weighted Average Precision:', average_precision_score(y_test, y_score, average='weighted'))\n",
    "print('Precision for each Class:', average_precision_score(y_test, y_score, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test.ravel(), y_score.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_score = logreg.predict_proba(X_test)[:,1]\n",
    "# # print(y_score)\n",
    "# # print(y_test)\n",
    "# fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "# # print(fpr)\n",
    "# # print(tpr)\n",
    "# roc_auc = auc([fpr, tpr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# # Plot 50-50 Line\n",
    "# ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "# # Plot Logistic ROC curve\n",
    "# ax.plot(fpr, tpr, color='b', label='Logistic: %.3f' % roc_auc)\n",
    "    \n",
    "# ax.set_xlabel('FPR')\n",
    "# ax.set_ylabel('TPR')\n",
    "# ax.set_title('Logistic ROC Curve')\n",
    "# ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
