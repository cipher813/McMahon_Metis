{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Success of A Kickstarter Campaign\n",
    "Part 1. Initial screening of an assortment of ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB,MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import (accuracy_score, classification_report,confusion_matrix, precision_score, \n",
    "                             recall_score, f1_score, roc_curve, roc_auc_score, average_precision_score, \n",
    "                             precision_recall_curve, auc)\n",
    "\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.model_selection import KFold  \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# env variable at tensorflow1.4 per https://conda.io/docs/user-guide/tasks/manage-environments.html#saving-environment-variables\n",
    "# and https://vsupalov.com/flask-sqlalchemy-postgres/\n",
    "\n",
    "def get_env_variable(name):\n",
    "    try:\n",
    "        return os.environ[name]\n",
    "    except KeyError:\n",
    "        message = \"Expected environment variable '{}' not set.\".format(name)\n",
    "        raise Exception(message)\n",
    "\n",
    "POSTGRES_URL = get_env_variable(\"POSTGRES_URL\")\n",
    "POSTGRES_USER = get_env_variable(\"POSTGRES_USER\")\n",
    "POSTGRES_PW = get_env_variable(\"POSTGRES_PW\")\n",
    "POSTGRES_DB = get_env_variable(\"POSTGRES_DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_URL = 'postgresql+psycopg2://{user}:{pw}@{url}/{db}'.format(user=POSTGRES_USER,pw=POSTGRES_PW,url=POSTGRES_URL,db=POSTGRES_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine_var = DB_URL\n",
    "engine = create_engine(engine_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163425, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>category_main</th>\n",
       "      <th>category_name</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>pct_goal_achieved</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>usd_goal</th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "      <th>campaign_length</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>created</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>creator_name</th>\n",
       "      <th>blurb_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1396766240</th>\n",
       "      <td>1396766240</td>\n",
       "      <td>Ripple Playing Cards - Printed by USPCC</td>\n",
       "      <td>0</td>\n",
       "      <td>games</td>\n",
       "      <td>Playing Cards</td>\n",
       "      <td>131</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3387.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>38</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>2017-10-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B.Y. Eidelman</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065169465</th>\n",
       "      <td>2065169465</td>\n",
       "      <td>Cotton-Top Pastries</td>\n",
       "      <td>1</td>\n",
       "      <td>food</td>\n",
       "      <td>Small Batch</td>\n",
       "      <td>99</td>\n",
       "      <td>1.3</td>\n",
       "      <td>9858.000000</td>\n",
       "      <td>7500.000000</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>30</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Holly Weist</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647325451</th>\n",
       "      <td>1647325451</td>\n",
       "      <td>Code Switch</td>\n",
       "      <td>1</td>\n",
       "      <td>film_and_video</td>\n",
       "      <td>Horror</td>\n",
       "      <td>34</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4611.000000</td>\n",
       "      <td>3000.000000</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>32</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-11</td>\n",
       "      <td>2017-11-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alba Roland</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727157486</th>\n",
       "      <td>727157486</td>\n",
       "      <td>Rain Dog Farm</td>\n",
       "      <td>0</td>\n",
       "      <td>food</td>\n",
       "      <td>Farms</td>\n",
       "      <td>49</td>\n",
       "      <td>0.3</td>\n",
       "      <td>4741.000000</td>\n",
       "      <td>18000.000000</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>38</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Charlie Wainger</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756145145</th>\n",
       "      <td>1756145145</td>\n",
       "      <td>WANGTA: a novel</td>\n",
       "      <td>1</td>\n",
       "      <td>publishing</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>427.185132</td>\n",
       "      <td>427.185132</td>\n",
       "      <td>CA</td>\n",
       "      <td>CAD</td>\n",
       "      <td>21</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D. H. de Bruin</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                     name  state  \\\n",
       "idx                                                                      \n",
       "1396766240  1396766240  Ripple Playing Cards - Printed by USPCC      0   \n",
       "2065169465  2065169465                      Cotton-Top Pastries      1   \n",
       "1647325451  1647325451                              Code Switch      1   \n",
       "727157486    727157486                            Rain Dog Farm      0   \n",
       "1756145145  1756145145                          WANGTA: a novel      1   \n",
       "\n",
       "             category_main  category_name  backers_count  pct_goal_achieved  \\\n",
       "idx                                                                           \n",
       "1396766240           games  Playing Cards            131                0.3   \n",
       "2065169465            food    Small Batch             99                1.3   \n",
       "1647325451  film_and_video         Horror             34                1.5   \n",
       "727157486             food          Farms             49                0.3   \n",
       "1756145145      publishing        Fiction             13                1.0   \n",
       "\n",
       "            usd_pledged      usd_goal country currency  campaign_length  \\\n",
       "idx                                                                       \n",
       "1396766240  3387.000000   9999.000000      US      USD               38   \n",
       "2065169465  9858.000000   7500.000000      US      USD               30   \n",
       "1647325451  4611.000000   3000.000000      US      USD               32   \n",
       "727157486   4741.000000  18000.000000      US      USD               38   \n",
       "1756145145   427.185132    427.185132      CA      CAD               21   \n",
       "\n",
       "              deadline    launched     created  staff_pick  spotlight  \\\n",
       "idx                                                                     \n",
       "1396766240  2018-01-12  2017-12-05  2017-10-08           0          0   \n",
       "2065169465  2018-01-12  2017-12-13  2017-12-12           1          1   \n",
       "1647325451  2018-01-12  2017-12-11  2017-11-10           0          1   \n",
       "727157486   2018-01-12  2017-12-05  2017-11-28           1          0   \n",
       "1756145145  2018-01-12  2017-12-22  2017-12-18           0          1   \n",
       "\n",
       "               creator_name  blurb_length  \n",
       "idx                                        \n",
       "1396766240    B.Y. Eidelman            16  \n",
       "2065169465      Holly Weist             5  \n",
       "1647325451      Alba Roland            23  \n",
       "727157486   Charlie Wainger             9  \n",
       "1756145145   D. H. de Bruin            22  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/kickstarter_data_ds2.pkl')\n",
    "# df = pd.read_sql_query('''SELECT * FROM kickstarter_data_ds2''',engine)\n",
    "# pd.read_sql_query('''SELECT state, main_category, main_category, currency, currency, deadline, launched, usd_goal_real, usd_pledged_real FROM kickstarter_data_ds2 LIMIT 5''',engine)\n",
    "df['idx'] = df['id']\n",
    "df = df.set_index('idx')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38401, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime.datetime.strptime('2016-01-01', \"%Y-%m-%d\").date()\n",
    "\n",
    "df = df[df['launched'] >= start_date] # filter from start date to current\n",
    "df = df[['state','category_name','backers_count','usd_goal','country','currency','campaign_length',\n",
    "        'staff_pick','blurb_length']]\n",
    "df = df.dropna()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38401, 182)\n",
      "Index(['category_name_Academic', 'category_name_Accessories',\n",
      "       'category_name_Action', 'category_name_Animals',\n",
      "       'category_name_Animation', 'category_name_Anthologies',\n",
      "       'category_name_Apparel', 'category_name_Apps',\n",
      "       'category_name_Architecture', 'category_name_Art Books',\n",
      "       ...\n",
      "       'currency_USD', 'state', 'category_name', 'backers_count', 'usd_goal',\n",
      "       'country', 'currency', 'campaign_length', 'staff_pick', 'blurb_length'],\n",
      "      dtype='object', length=182)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38401 entries, 1396766240 to 1094069811\n",
      "Columns: 182 entries, category_name_Academic to blurb_length\n",
      "dtypes: float64(1), int64(5), object(3), uint8(173)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df[['category_name', 'country','currency']],drop_first=True)\n",
    "df = df_dummies.merge(df,how='inner',left_index=True, right_index=True)\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38401, 177)\n"
     ]
    }
   ],
   "source": [
    "# removing all variables that cannot be known before a campaign is launched, such as # backers and $ pledged\n",
    "df = df.dropna()\n",
    "X = df.drop(['state','state','category_name', 'backers_count', 'country', 'currency'], 1)\n",
    "y = df['state']\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26880, 177) (26880,)\n",
      "(11521, 177) (11521,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42, stratify=y)\n",
    "\n",
    "k_range = list(range(1, 101))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1: Initial Check on All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None)\n",
      "\t==============================\n",
      "\tAccuracy: 0.57859560802\n",
      "\tAUC: 0.534658591702\n",
      "\n",
      "\n",
      "[[ 428 4773]\n",
      " [  82 6238]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.08      0.15      5201\n",
      "          1       0.57      0.99      0.72      6320\n",
      "\n",
      "avg / total       0.69      0.58      0.46     11521\n",
      "\n",
      "BernoulliNB(alpha=0.5, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "\t==============================\n",
      "\tAccuracy: 0.733356479472\n",
      "\tAUC: 0.736910775435\n",
      "\n",
      "\n",
      "[[4023 1178]\n",
      " [1894 4426]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.77      0.72      5201\n",
      "          1       0.79      0.70      0.74      6320\n",
      "\n",
      "avg / total       0.74      0.73      0.73     11521\n",
      "\n",
      "MultinomialNB(alpha=0, class_prior=None, fit_prior=True)\n",
      "\t==============================\n",
      "\tAccuracy: 0.616352747157\n",
      "\tAUC: 0.58456265409\n",
      "\n",
      "\n",
      "[[1338 3863]\n",
      " [ 557 5763]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.26      0.38      5201\n",
      "          1       0.60      0.91      0.72      6320\n",
      "\n",
      "avg / total       0.65      0.62      0.57     11521\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "\t==============================\n",
      "\tAccuracy: 0.685183577814\n",
      "\tAUC: 0.680593921812\n",
      "\n",
      "\n",
      "[[3294 1907]\n",
      " [1720 4600]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.63      0.64      5201\n",
      "          1       0.71      0.73      0.72      6320\n",
      "\n",
      "avg / total       0.68      0.69      0.68     11521\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=27, p=2,\n",
      "           weights='uniform')\n",
      "\t==============================\n",
      "\tAccuracy: 0.636576686052\n",
      "\tAUC: 0.624698527425\n",
      "\n",
      "\n",
      "[[2613 2588]\n",
      " [1599 4721]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.50      0.56      5201\n",
      "          1       0.65      0.75      0.69      6320\n",
      "\n",
      "avg / total       0.63      0.64      0.63     11521\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "\t==============================\n",
      "\tAccuracy: 0.756635708706\n",
      "\tAUC: 0.755259316003\n",
      "\n",
      "\n",
      "[[3851 1350]\n",
      " [1456 4864]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.74      0.73      5201\n",
      "          1       0.78      0.77      0.78      6320\n",
      "\n",
      "avg / total       0.76      0.76      0.76     11521\n",
      "\n",
      "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=500,\n",
      "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
      "              warm_start=False)\n",
      "\t==============================\n",
      "\tAccuracy: 0.775505598472\n",
      "\tAUC: 0.776407655904\n",
      "\n",
      "\n",
      "[[4086 1115]\n",
      " [1472 4848]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.79      0.76      5201\n",
      "          1       0.81      0.77      0.79      6320\n",
      "\n",
      "avg / total       0.78      0.78      0.78     11521\n",
      "\n",
      "AdaBoostClassifier(algorithm='SAMME.R',\n",
      "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best'),\n",
      "          learning_rate=1.0, n_estimators=2, random_state=None)\n",
      "\t==============================\n",
      "\tAccuracy: 0.691953823453\n",
      "\tAUC: 0.686764807887\n",
      "\n",
      "\n",
      "[[3294 1907]\n",
      " [1642 4678]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.63      0.65      5201\n",
      "          1       0.71      0.74      0.72      6320\n",
      "\n",
      "avg / total       0.69      0.69      0.69     11521\n",
      "\n",
      "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
      "       gamma=0, learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=11, missing=-999, n_estimators=500, nthread=4,\n",
      "       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
      "       scale_pos_weight=1, seed=0, silent=1, subsample=0.8)\n",
      "\t==============================\n",
      "\tAccuracy: 0.779706622689\n",
      "\tAUC: 0.780349111296\n",
      "\n",
      "\n",
      "[[4093 1108]\n",
      " [1430 4890]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.79      0.76      5201\n",
      "          1       0.82      0.77      0.79      6320\n",
      "\n",
      "avg / total       0.78      0.78      0.78     11521\n",
      "\n",
      "LogisticRegression(C=1000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\t==============================\n",
      "\tAccuracy: 0.754292162139\n",
      "\tAUC: 0.754638147727\n",
      "\n",
      "\n",
      "[[3928 1273]\n",
      " [1567 4753]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.76      0.73      5201\n",
      "          1       0.79      0.75      0.77      6320\n",
      "\n",
      "avg / total       0.76      0.75      0.75     11521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models to test\n",
    "model_list = [['GaussianNB', GaussianNB()], \n",
    "                ['BernoulliNB', BernoulliNB(alpha=0.5)], \n",
    "                ['MultinomialNB', MultinomialNB(alpha=0)],\n",
    "                ['DecisionTree', DecisionTreeClassifier(criterion = 'gini', max_depth=2, splitter='best')], \n",
    "                ['KNN', KNeighborsClassifier(27)], # best k from KNN model below; scale data\n",
    "                ['RandomForest', RandomForestClassifier(max_features='auto',n_estimators=1000)], \n",
    "                ['GradientBoost', GradientBoostingClassifier(n_estimators=500)],\n",
    "                ['AdaBoost', AdaBoostClassifier(algorithm='SAMME.R',\n",
    "                      base_estimator=DecisionTreeClassifier(criterion = 'gini', max_depth=2, splitter='best'),\n",
    "                      n_estimators=2)],\n",
    "                ['XGBoost', XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
    "                       gamma=0, learning_rate=0.05, max_delta_step=0, max_depth=6,\n",
    "                       min_child_weight=11, missing=-999, n_estimators=500, nthread=4,\n",
    "                       objective='reg:linear', reg_alpha=0, reg_lambda=1,\n",
    "                       scale_pos_weight=1, seed=0, silent=1, subsample=0.8)],\n",
    "                ['LogisticRegression', LogisticRegression(C=1000, penalty='l1')],          \n",
    "#                 ['LogisticRegressionCV', LogisticRegressionCV()]] # scale data; F1 0.62\n",
    "                ['SVM', SVC(C=10,gamma=0.001,probability=True)]] # scale data; F1 0.57\n",
    "\n",
    "model_list_s = [['KNN', KNeighborsClassifier(27)], # best k from KNN model below; scale data\n",
    "                ['LogisticRegression', LogisticRegression(C=1000, penalty='l1')], # scale data\n",
    "#                 ['LogisticRegressionCV', LogisticRegressionCV()]] # scale data\n",
    "                ['SVM', SVC(C=10,gamma=0.001,probability=True)]] # scale data\n",
    "\n",
    "# Calculate metrics for each model\n",
    "roc = {}\n",
    "results_dict = {}\n",
    "for model in model_list:\n",
    "    if model in model_list_s:\n",
    "        X_train = X_train_s\n",
    "        X_test = X_test_s\n",
    "    \n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    \n",
    "    accuracy = []\n",
    "    precision_1 = []\n",
    "    precision_0 = []\n",
    "    recall_1 = []\n",
    "    recall_0 = []\n",
    "    f1_1 = []\n",
    "    f1_0 = []\n",
    "    auc = []\n",
    "        \n",
    "    # Perform K-Fold CV and calculate metrics for each fold\n",
    "    kf = KFold(5, random_state=42, shuffle=True) \n",
    "    for train_idx, test_idx in kf.split(X, y=y):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision_1.append(precision_score(y_test, y_pred ,pos_label=1))\n",
    "        precision_0.append(precision_score(y_test, y_pred ,pos_label=0))\n",
    "        recall_1.append(recall_score(y_test, y_pred, pos_label=1))\n",
    "        recall_0.append(recall_score(y_test, y_pred, pos_label=0))\n",
    "        f1_1.append(f1_score(y_test, y_pred, pos_label=1))\n",
    "        f1_0.append(f1_score(y_test, y_pred, pos_label=0))\n",
    "        auc.append(roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "    # Calculate mean metric across K-folds\n",
    "    mean_accuracy = np.mean(accuracy)\n",
    "    mean_precision_1 = np.mean(precision_1)\n",
    "    mean_precision_0 = np.mean(precision_0)\n",
    "    mean_recall_1 = np.mean(recall_1)\n",
    "    mean_recall_0 = np.mean(recall_0)\n",
    "    mean_f1_1 = np.mean(f1_1)\n",
    "    mean_f1_0 = np.mean(f1_0)\n",
    "    mean_auc = np.mean(auc)\n",
    "    \n",
    "    # Capture TPR and FPR from last fold for plotting\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    roc[model_name] = roc_curve(y_test, y_score), mean_auc\n",
    "    results_dict[model_name] = {\"accuracy\": mean_accuracy, \"precision_s\": mean_precision_1, \"precision_f\": mean_precision_0, \"recall_s\": mean_recall_1, \"recall_f\": mean_recall_0, \"f1_s\": mean_f1_1, \"f1_f\": mean_f1_0, \"auc\": mean_auc}\n",
    "    \n",
    "    # Print formatted results\n",
    "    print(model)\n",
    "    print('\\t==============================')\n",
    "    print('\\tAccuracy:', mean_accuracy)\n",
    "    print('\\tAUC:', mean_auc)\n",
    "    print('\\n')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rc = pd.DataFrame(roc)\n",
    "# rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc['AdaBoost'][0][1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# roc.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve from the last K-Fold split\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# colors = ['b', 'g', 'r', 'c', 'm', 'y','k','orange','darkorchid','bisque', 'darkgray']\n",
    "\n",
    "# Plot 50-50 Line\n",
    "ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "# Plot Classifier ROC Curves\n",
    "for key, value in roc.items():\n",
    "    label = '{}, AUC: {}%'.format(key, round(100*value[1],2))\n",
    "    ax.plot(roc[key][0][0], roc[key][0][1], label=label)\n",
    "    \n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('ROC Curve - All Models')\n",
    "ax.legend(loc='best')\n",
    "plt.savefig('charts/roc_ds2_p1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = pd.DataFrame(results_dict).T\n",
    "rd = rd.apply(lambda x: round(100*x,2).astype(str) + \"%\")\n",
    "# rd['f1_success'] = rd['f1']\n",
    "rd = rd.sort_values(['auc'],ascending=[False])\n",
    "rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
