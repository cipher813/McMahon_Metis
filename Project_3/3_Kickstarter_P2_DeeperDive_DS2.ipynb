{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kickstarter: Classification\n",
    "Tests Include:\n",
    "-KNN\n",
    "-Logistic Regression\n",
    "-Decision Trees\n",
    "-Random Forest\n",
    "-SVM\n",
    "-Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/sklearn/learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB,MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, RandomTreesEmbedding\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_curve, roc_auc_score\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from sklearn.cross_validation import train_test_split, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.preprocessing import label_binarize, scale, StandardScaler\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #, category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# env variable at tensorflow1.4 per https://conda.io/docs/user-guide/tasks/manage-environments.html#saving-environment-variables\n",
    "# and https://vsupalov.com/flask-sqlalchemy-postgres/\n",
    "\n",
    "def get_env_variable(name):\n",
    "    try:\n",
    "        return os.environ[name]\n",
    "    except KeyError:\n",
    "        message = \"Expected environment variable '{}' not set.\".format(name)\n",
    "        raise Exception(message)\n",
    "\n",
    "# the values of those depend on your setup\n",
    "POSTGRES_URL = get_env_variable(\"POSTGRES_URL\")\n",
    "POSTGRES_USER = get_env_variable(\"POSTGRES_USER\")\n",
    "POSTGRES_PW = get_env_variable(\"POSTGRES_PW\")\n",
    "POSTGRES_DB = get_env_variable(\"POSTGRES_DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_URL = 'postgresql+psycopg2://{user}:{pw}@{url}/{db}'.format(user=POSTGRES_USER,pw=POSTGRES_PW,url=POSTGRES_URL,db=POSTGRES_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine_var = DB_URL\n",
    "engine = create_engine(engine_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163426, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>category_main</th>\n",
       "      <th>category_name</th>\n",
       "      <th>backers_count</th>\n",
       "      <th>pct_goal_achieved</th>\n",
       "      <th>usd_pledged</th>\n",
       "      <th>goal</th>\n",
       "      <th>country</th>\n",
       "      <th>currency</th>\n",
       "      <th>campaign_length</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>created</th>\n",
       "      <th>spotlight</th>\n",
       "      <th>staff_pick</th>\n",
       "      <th>creator_name</th>\n",
       "      <th>blurb_length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1725323227</th>\n",
       "      <td>1725323227</td>\n",
       "      <td>Inspire young girls</td>\n",
       "      <td>failed</td>\n",
       "      <td>fashion</td>\n",
       "      <td>Childrenswear</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>30</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>2017-12-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Rayna</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2065169465</th>\n",
       "      <td>2065169465</td>\n",
       "      <td>Cotton-Top Pastries</td>\n",
       "      <td>successful</td>\n",
       "      <td>food</td>\n",
       "      <td>Small Batch</td>\n",
       "      <td>99</td>\n",
       "      <td>1.3</td>\n",
       "      <td>9858.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>30</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Holly Weist</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516902916</th>\n",
       "      <td>1516902916</td>\n",
       "      <td>Dreaming Creek Brewery</td>\n",
       "      <td>failed</td>\n",
       "      <td>food</td>\n",
       "      <td>Drinks</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6139.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>30</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-13</td>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Mike Bradley</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396766240</th>\n",
       "      <td>1396766240</td>\n",
       "      <td>Ripple Playing Cards - Printed by USPCC</td>\n",
       "      <td>failed</td>\n",
       "      <td>games</td>\n",
       "      <td>Playing Cards</td>\n",
       "      <td>131</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3387.0</td>\n",
       "      <td>9999.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>38</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-05</td>\n",
       "      <td>2017-10-08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>B.Y. Eidelman</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361347175</th>\n",
       "      <td>1361347175</td>\n",
       "      <td>New Boutique Funding for the San Antonio Stock...</td>\n",
       "      <td>failed</td>\n",
       "      <td>fashion</td>\n",
       "      <td>Ready-to-wear</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>US</td>\n",
       "      <td>USD</td>\n",
       "      <td>15</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Darrian Fosty</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               name  \\\n",
       "idx                                                                         \n",
       "1725323227  1725323227                                Inspire young girls   \n",
       "2065169465  2065169465                                Cotton-Top Pastries   \n",
       "1516902916  1516902916                             Dreaming Creek Brewery   \n",
       "1396766240  1396766240            Ripple Playing Cards - Printed by USPCC   \n",
       "1361347175  1361347175  New Boutique Funding for the San Antonio Stock...   \n",
       "\n",
       "                 state category_main  category_name  backers_count  \\\n",
       "idx                                                                  \n",
       "1725323227      failed       fashion  Childrenswear              1   \n",
       "2065169465  successful          food    Small Batch             99   \n",
       "1516902916      failed          food         Drinks             64   \n",
       "1396766240      failed         games  Playing Cards            131   \n",
       "1361347175      failed       fashion  Ready-to-wear              0   \n",
       "\n",
       "            pct_goal_achieved  usd_pledged     goal country currency  \\\n",
       "idx                                                                    \n",
       "1725323227                0.0         30.0   1300.0      US      USD   \n",
       "2065169465                1.3       9858.0   7500.0      US      USD   \n",
       "1516902916                0.3       6139.0  20000.0      US      USD   \n",
       "1396766240                0.3       3387.0   9999.0      US      USD   \n",
       "1361347175                0.0          0.0   5000.0      US      USD   \n",
       "\n",
       "            campaign_length    deadline    launched     created  spotlight  \\\n",
       "idx                                                                          \n",
       "1725323227               30  2018-01-12  2017-12-13  2017-12-08          0   \n",
       "2065169465               30  2018-01-12  2017-12-13  2017-12-12          1   \n",
       "1516902916               30  2018-01-12  2017-12-13  2017-08-11          0   \n",
       "1396766240               38  2018-01-12  2017-12-05  2017-10-08          0   \n",
       "1361347175               15  2018-01-12  2017-12-28  2017-12-22          0   \n",
       "\n",
       "            staff_pick   creator_name  blurb_length  \n",
       "idx                                                  \n",
       "1725323227           0          Rayna             6  \n",
       "2065169465           1    Holly Weist             5  \n",
       "1516902916           0   Mike Bradley            19  \n",
       "1396766240           0  B.Y. Eidelman            16  \n",
       "1361347175           0  Darrian Fosty            26  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('data/kickstarter_data_ds2.pkl')\n",
    "df['idx'] = df['id']\n",
    "df = df.set_index('idx')\n",
    "# df['state'] = df['state'].replace({'failed': 0, 'successful': 1})\n",
    "# df = pd.read_sql_query('''SELECT * FROM kickstarter_data_ds2''',engine)\n",
    "print(df.shape)\n",
    "# pd.read_sql_query('''SELECT state, main_category, main_category, currency, currency, deadline, launched, usd_goal_real, usd_pledged_real FROM kickstarter_data_ds2 LIMIT 5''',engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41894, 19)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = datetime.datetime.strptime('2016-01-01', \"%Y-%m-%d\").date()\n",
    "\n",
    "df = df[df['launched'] >= start_date] # filter from start date to current\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'state', 'category_main', 'category_name',\n",
       "       'backers_count', 'pct_goal_achieved', 'usd_pledged', 'goal', 'country',\n",
       "       'currency', 'campaign_length', 'deadline', 'launched', 'created',\n",
       "       'spotlight', 'staff_pick', 'creator_name', 'blurb_length'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41896, 180)\n",
      "Index(['state_successful', 'category_name_Academic',\n",
      "       'category_name_Accessories', 'category_name_Action',\n",
      "       'category_name_Animals', 'category_name_Animation',\n",
      "       'category_name_Anthologies', 'category_name_Apparel',\n",
      "       'category_name_Apps', 'category_name_Architecture',\n",
      "       ...\n",
      "       'country', 'currency', 'campaign_length', 'deadline', 'launched',\n",
      "       'created', 'spotlight', 'staff_pick', 'creator_name', 'blurb_length'],\n",
      "      dtype='object', length=180)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 41896 entries, 18520 to 2147422173\n",
      "Columns: 180 entries, state_successful to blurb_length\n",
      "dtypes: float64(3), int64(6), object(10), uint8(161)\n",
      "memory usage: 12.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df[['state','category_name', 'country']],drop_first=True)\n",
    "df = df_dummies.merge(df,how='inner',left_index=True, right_index=True)\n",
    "print(df.shape)\n",
    "print(df.columns)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41896, 163)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['category_name_Academic', 'category_name_Accessories',\n",
       "       'category_name_Action', 'category_name_Animals',\n",
       "       'category_name_Animation', 'category_name_Anthologies',\n",
       "       'category_name_Apparel', 'category_name_Apps',\n",
       "       'category_name_Architecture', 'category_name_Art Books',\n",
       "       ...\n",
       "       'country_MX', 'country_NL', 'country_NO', 'country_NZ', 'country_SE',\n",
       "       'country_SG', 'country_US', 'campaign_length', 'staff_pick',\n",
       "       'blurb_length'],\n",
       "      dtype='object', length=163)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# removing all variables that cannot be known before a campaign is launched, such as # backers and $ pledged\n",
    "X = df.drop(['state_successful','id', 'name', 'state', 'category_main','category_name', 'backers_count','pct_goal_achieved', 'usd_pledged', 'goal', 'country', 'currency',\n",
    "       'deadline', 'launched', 'created','creator_name','spotlight'], 1)\n",
    "y = df['state_successful']\n",
    "\n",
    "print(X.shape)\n",
    "X.columns\n",
    "# X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29327, 163) (29327,)\n",
      "(12569, 163) (12569,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state=42, stratify=y)\n",
    "\n",
    "k_range = list(range(1, 101))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.56155700e-17  1.01758771e-17 -9.69131157e-19  1.84134920e-17\n",
      " -4.09457914e-17  1.73232194e-17 -1.69597952e-18  9.44902878e-18\n",
      "  1.18718567e-17  6.29935252e-18 -3.31927421e-17 -1.57483813e-17\n",
      " -1.06604427e-17  2.95585003e-17 -1.12661497e-17 -3.87652463e-18\n",
      "  4.07035086e-17  8.23761483e-18 -1.16295739e-17  4.84565578e-18\n",
      " -9.20674599e-18  4.94256890e-17 -7.26848367e-18  1.16295739e-17\n",
      "  5.69364555e-18  1.93826231e-17 -1.04181599e-17 -1.04181599e-17\n",
      "  8.72218041e-18  3.05276314e-17  2.90739347e-18 -3.87652463e-17\n",
      " -1.58695227e-17 -1.67175125e-17 -2.03517543e-17  5.18485169e-17\n",
      " -5.81478694e-18  1.93826231e-18 -1.01758771e-17 -2.27745822e-17\n",
      " -9.20674599e-18  3.29504593e-17 -2.22900166e-17  1.04181599e-17\n",
      "  8.72218041e-18  4.79719923e-17 -1.67175125e-17  1.67175125e-17\n",
      " -3.48887216e-17 -2.42282789e-18  2.83470863e-17  9.69131157e-19\n",
      " -1.67175125e-17  2.01094715e-17  1.59906641e-17  1.25987050e-17\n",
      " -2.90739347e-18 -1.45369673e-18  4.28840537e-17  6.12975457e-17\n",
      "  1.93826231e-17 -4.31263365e-17  8.96446320e-18  2.27745822e-17\n",
      " -1.40524018e-17  3.14967626e-17  1.16295739e-17 -3.39195905e-18\n",
      "  1.06604427e-17  1.40524018e-17 -3.87652463e-18 -2.81048035e-17\n",
      " -8.72218041e-18  4.84565578e-17 -4.17937811e-18 -1.23564222e-17\n",
      "  6.25089596e-17 -8.72218041e-18  1.35678362e-17 -2.96796417e-18\n",
      " -3.14967626e-18 -2.37437133e-17  4.60337299e-18  2.20477338e-17\n",
      "  3.07699142e-17 -1.81712092e-17  3.36773077e-17 -3.68269840e-17\n",
      "  1.40524018e-17  2.42282789e-18 -1.88980576e-17 -2.90739347e-17\n",
      " -2.05940371e-17  5.33022136e-17  3.02853486e-17 -4.14303569e-17\n",
      " -2.61665412e-17 -1.93826231e-18  8.78275111e-18  4.84565578e-18\n",
      "  3.19813282e-17 -2.38648547e-17 -1.09027255e-17 -1.57483813e-17\n",
      " -7.75304925e-18  2.32591478e-17  2.76202380e-17 -1.11450083e-17\n",
      " -7.22002712e-17  2.25322994e-17  1.45369673e-17  3.14967626e-18\n",
      " -1.55060985e-17  2.81048035e-17 -2.56819757e-17  5.93592833e-18\n",
      " -7.51076646e-18 -2.27745822e-17 -1.64752297e-17  2.90739347e-18\n",
      " -3.82806807e-17 -1.84134920e-17  4.84565578e-18  3.75538323e-18\n",
      " -4.84565578e-18 -3.14967626e-18  4.40954676e-17 -1.30832706e-17\n",
      " -5.27570773e-17  3.99766602e-17 -9.20674599e-18  2.47128445e-17\n",
      "  6.29935252e-18 -2.30168650e-17 -2.43494203e-17  5.33022136e-18\n",
      " -1.42946846e-17 -1.69597952e-18  1.93826231e-17 -1.91403403e-17\n",
      " -9.20674599e-18 -4.36109020e-18  4.36109020e-18 -5.77844452e-17\n",
      " -1.09027255e-18 -3.39195905e-18  3.22236110e-17 -1.64752297e-17\n",
      "  5.33022136e-18 -2.14420268e-17  2.45917031e-17 -6.78391810e-18\n",
      " -6.78391810e-18  1.44158260e-17  4.65182955e-17  3.68269840e-17\n",
      " -2.61665412e-17 -6.88083121e-17 -3.67058426e-17  1.39070321e-16\n",
      " -1.91282262e-16 -1.69597952e-17 -2.10786027e-16]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# https://elitedatascience.com/python-machine-learning-tutorial-scikit-learn\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_s = scaler.transform(X_train)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "# print(X_train_s.mean(axis=0))\n",
    "# print(X_train_s.std(axis=0))\n",
    "\n",
    "# X_combined_s = np.vstack((X_train_s, X_test_s))\n",
    "# y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Deeper Dive: Logistic Regression, Naive Bayes, Random Forests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to test\n",
    "model_list = [  ['BernoulliNB', BernoulliNB(alpha=2.0, binarize=0.0, class_prior=None, fit_prior=True)], # F1 0.60\n",
    "                ['MultinomialNB', MultinomialNB(alpha=0.5, class_prior=None, fit_prior=True)], \n",
    "#                 ['DecisionTree', DecisionTreeClassifier()], \n",
    "                ['RandomForest', RandomForestClassifier(max_features='sqrt',n_estimators=1000)], # F1 0.61\n",
    "                ['GradientBoost', GradientBoostingClassifier(n_estimators=500)],\n",
    "                ['AdaBoost', AdaBoostClassifier(base_estimator=DecisionTreeClassifier())],\n",
    "#                 ['KNN', KNeighborsClassifier(38)], # best k from KNN model below; scale data\n",
    "                ['LogisticRegression', LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
    "                      intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
    "                      penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
    "                      verbose=0, warm_start=False)]]\n",
    "#                 ['LogisticRegressionCV', LogisticRegressionCV()]] # scale data; F1 0.62\n",
    "#                 ['SVM', SVC(probability=True)]] # scale data; F1 0.57\n",
    "\n",
    "model_list_s = [['LogisticRegression', LogisticRegression()]] # scale data\n",
    "#                 ['LogisticRegressionCV', LogisticRegressionCV()]] # scale data\n",
    "#                 ['SVM', SVC(probability=True)]] # scale data\n",
    "\n",
    "# Calculate metrics for each model\n",
    "roc = {}\n",
    "for model in model_list:\n",
    "    if model in model_list_s:\n",
    "        X_train = X_train_s\n",
    "        X_test = X_test_s\n",
    "    \n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "    error_rate = []\n",
    "        \n",
    "    # Perform K-Fold CV and calculate metrics for each fold\n",
    "    kf = KFold(5, random_state=42, shuffle=True) \n",
    "    for train_idx, test_idx in kf.split(X, y=y):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        auc.append(roc_auc_score(y_test, y_pred))\n",
    "        error_rate.append(np.mean(y_pred != y_test))\n",
    "        \n",
    "    # Calculate mean metric across K-folds\n",
    "    mean_accuracy = np.mean(accuracy)\n",
    "    mean_precision = np.mean(precision)\n",
    "    mean_recall = np.mean(recall)\n",
    "    mean_f1 = np.mean(f1)\n",
    "    mean_auc = np.mean(auc)\n",
    "    \n",
    "    # Capture TPR and FPR from last fold for plotting\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    roc[model_name] = roc_curve(y_test, y_score)\n",
    "    \n",
    "    # Print formatted results\n",
    "    print(model)\n",
    "    print('\\t==============================')\n",
    "    print('\\tAccuracy:', mean_accuracy)\n",
    "    print('\\tAUC:', mean_auc)\n",
    "    print('\\n')\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print(classification_report(y_test,y_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the ROC curve from the last K-Fold split\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y','k','orange','darkorchid','bisque']\n",
    "\n",
    "# Plot 50-50 Line\n",
    "ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "# Plot Classifier ROC Curves\n",
    "for key, c in zip(roc.keys(), colors):\n",
    "    ax.plot(roc[key][0], roc[key][1], color=c, label=key)\n",
    "    \n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('Classifier Comparison')\n",
    "ax.legend(loc='best')\n",
    "plt.savefig('charts/roc_ds2_p2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "param_grid = [{'penalty': ['l1','l2'],'C': [0.001,0.01,0.1,1,10,100,1000]}]\n",
    "grid = GridSearchCV(model,param_grid,refit=True,verbose=2, scoring='roc_auc', n_jobs=-1)\n",
    "grid.fit(X_train_s,y_train)\n",
    "grid_predictions = grid.predict(X_test_s)\n",
    "best_params = grid.best_params_\n",
    "best_estimator = grid.best_estimator_\n",
    "best_cm = confusion_matrix(y_test,grid_predictions)\n",
    "best_cr = classification_report(y_test,grid_predictions)\n",
    "print(best_params, best_estimator, best_cm, best_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BernoulliNB()\n",
    "param_grid = [{'alpha' : [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}]\n",
    "grid = GridSearchCV(model,param_grid,refit=True,verbose=2, scoring='roc_auc', n_jobs=-1)\n",
    "grid.fit(X_train_s,y_train)\n",
    "grid_predictions = grid.predict(X_test_s)\n",
    "best_params = grid.best_params_\n",
    "best_estimator = grid.best_estimator_\n",
    "best_cm = confusion_matrix(y_test,grid_predictions)\n",
    "best_cr = classification_report(y_test,grid_predictions)\n",
    "print(best_params, best_estimator, best_cm, best_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "param_grid = [{'alpha' : [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}]\n",
    "grid = GridSearchCV(model,param_grid,refit=True,verbose=2, scoring='roc_auc', n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "best_params = grid.best_params_\n",
    "best_estimator = grid.best_estimator_\n",
    "best_cm = confusion_matrix(y_test,grid_predictions)\n",
    "best_cr = classification_report(y_test,grid_predictions)\n",
    "print(best_params, best_estimator, best_cm, best_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "param_grid = [{'n_estimators': [10, 100, 500, 1000],'max_features': ['auto', 'sqrt', 'log2']}]\n",
    "grid = GridSearchCV(model,param_grid,refit=True,verbose=2, scoring='roc_auc', n_jobs=-1)\n",
    "grid.fit(X_train_s,y_train)\n",
    "grid_predictions = grid.predict(X_test_s)\n",
    "best_params = grid.best_params_\n",
    "best_estimator = grid.best_estimator_\n",
    "best_cm = confusion_matrix(y_test,grid_predictions)\n",
    "best_cr = classification_report(y_test,grid_predictions)\n",
    "print(best_params, best_estimator, best_cm, best_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV: Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingClassifier()\n",
    "param_grid = [{'n_estimators': [10, 100, 500, 1000]}]\n",
    "grid = GridSearchCV(model,param_grid,refit=True,verbose=2, scoring='roc_auc', n_jobs=-1)\n",
    "grid.fit(X_train_s,y_train)\n",
    "grid_predictions = grid.predict(X_test_s)\n",
    "best_params = grid.best_params_\n",
    "best_estimator = grid.best_estimator_\n",
    "best_cm = confusion_matrix(y_test,grid_predictions)\n",
    "best_cr = classification_report(y_test,grid_predictions)\n",
    "print(best_params, best_estimator, best_cm, best_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV: AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AdaBoostClassifier(base_estimator=DecisionTreeClassifier())\n",
    "param_grid = [{'n_estimators': (1, 2),\n",
    "                  'base_estimator__max_depth': (1, 2),\n",
    "                  'algorithm': ('SAMME', 'SAMME.R')}]\n",
    "grid = GridSearchCV(model,param_grid,refit=True,verbose=2, scoring='roc_auc', n_jobs=-1)\n",
    "grid.fit(X_train,y_train)\n",
    "grid_predictions = grid.predict(X_test)\n",
    "best_params = grid.best_params_\n",
    "best_estimator = grid.best_estimator_\n",
    "best_cm = confusion_matrix(y_test,grid_predictions)\n",
    "best_cr = classification_report(y_test,grid_predictions)\n",
    "print(best_params, best_estimator, best_cm, best_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## GridSearchCV: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/37678471/i-am-trying-to-implement-gridsearchcv-to-tune-the-parameters-of-k-nearest-neighb\n",
    "model = KNeighborsClassifier()\n",
    "param_grid = [{'n_neighbors': list(range(100))}]\n",
    "grid = GridSearchCV(model,param_grid,refit=True,verbose=2, scoring='roc_auc', n_jobs=-1)\n",
    "grid.fit(X_train_s,y_train)\n",
    "grid_predictions = grid.predict(X_test_s)\n",
    "best_params = grid.best_params_\n",
    "best_estimator = grid.best_estimator_\n",
    "best_cm = confusion_matrix(y_test,grid_predictions)\n",
    "best_cr = classification_report(y_test,grid_predictions)\n",
    "print(best_params, best_estimator, best_cm, best_cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
