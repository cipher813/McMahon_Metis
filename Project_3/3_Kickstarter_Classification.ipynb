{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# KNN\n",
    "# Logistic Regression\n",
    "# Decision Trees\n",
    "# Random Forest\n",
    "# SVM\n",
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brianmcmahon/anaconda3/envs/tensorflow1.4/lib/python3.5/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import warnings\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\") #, category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# env variable at tensorflow1.4 per https://conda.io/docs/user-guide/tasks/manage-environments.html#saving-environment-variables\n",
    "# and https://vsupalov.com/flask-sqlalchemy-postgres/\n",
    "\n",
    "def get_env_variable(name):\n",
    "    try:\n",
    "        return os.environ[name]\n",
    "    except KeyError:\n",
    "        message = \"Expected environment variable '{}' not set.\".format(name)\n",
    "        raise Exception(message)\n",
    "\n",
    "# the values of those depend on your setup\n",
    "POSTGRES_URL = get_env_variable(\"POSTGRES_URL\")\n",
    "POSTGRES_USER = get_env_variable(\"POSTGRES_USER\")\n",
    "POSTGRES_PW = get_env_variable(\"POSTGRES_PW\")\n",
    "POSTGRES_DB = get_env_variable(\"POSTGRES_DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DB_URL = 'postgresql+psycopg2://{user}:{pw}@{url}/{db}'.format(user=POSTGRES_USER,pw=POSTGRES_PW,url=POSTGRES_URL,db=POSTGRES_DB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "engine_var = DB_URL\n",
    "engine = create_engine(engine_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>state_code</th>\n",
       "      <th>main_category</th>\n",
       "      <th>main_category_code</th>\n",
       "      <th>currency</th>\n",
       "      <th>currency_code</th>\n",
       "      <th>deadline</th>\n",
       "      <th>launched</th>\n",
       "      <th>usd_goal_real</th>\n",
       "      <th>usd_pledged_real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>successful</td>\n",
       "      <td>1</td>\n",
       "      <td>Publishing</td>\n",
       "      <td>12</td>\n",
       "      <td>USD</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>6083.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>successful</td>\n",
       "      <td>1</td>\n",
       "      <td>Music</td>\n",
       "      <td>10</td>\n",
       "      <td>USD</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-11-30</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>11169.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>successful</td>\n",
       "      <td>1</td>\n",
       "      <td>Music</td>\n",
       "      <td>10</td>\n",
       "      <td>EUR</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-11-28</td>\n",
       "      <td>30112.5</td>\n",
       "      <td>30615.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>successful</td>\n",
       "      <td>1</td>\n",
       "      <td>Music</td>\n",
       "      <td>10</td>\n",
       "      <td>USD</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-12-09</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1743.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>failed</td>\n",
       "      <td>0</td>\n",
       "      <td>Food</td>\n",
       "      <td>7</td>\n",
       "      <td>USD</td>\n",
       "      <td>13</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>2017-11-03</td>\n",
       "      <td>200000.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        state  state_code main_category  main_category_code currency  \\\n",
       "0  successful           1    Publishing                  12      USD   \n",
       "1  successful           1         Music                  10      USD   \n",
       "2  successful           1         Music                  10      EUR   \n",
       "3  successful           1         Music                  10      USD   \n",
       "4      failed           0          Food                   7      USD   \n",
       "\n",
       "   currency_code    deadline    launched  usd_goal_real  usd_pledged_real  \n",
       "0             13  2018-01-02  2017-12-06         2000.0           6083.00  \n",
       "1             13  2018-01-02  2017-11-30        10000.0          11169.56  \n",
       "2              4  2018-01-02  2017-11-28        30112.5          30615.02  \n",
       "3             13  2018-01-02  2017-12-09         1000.0           1743.00  \n",
       "4             13  2018-01-02  2017-11-03       200000.0              1.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_pickle('data/kickstarter_data.pkl')\n",
    "# TODO determine whie ID shows up but is not called - index issue?\n",
    "df = pd.read_sql_query('''SELECT * FROM kickstarter_data''',engine)\n",
    "pd.read_sql_query('''SELECT state, main_category, main_category, currency, currency, deadline, launched, usd_goal_real, usd_pledged_real FROM kickstarter_data LIMIT 5''',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['name', 'category', 'main_category', 'currency',\n",
    "       'pledged', 'state', 'backers',\n",
    "       'country', 'usd pledged'], 1)\n",
    "\n",
    "y = df['state_successful']\n",
    "\n",
    "print(X.shape())\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7,random_state=42)\n",
    "\n",
    "k_range = list(range(1, 101))\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k_acc = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_prediction = knn.predict(X_test)\n",
    "    k_acc.append(accuracy_score(y_test, knn_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(k_range, k_acc)\n",
    "plt.xlabel('# of neighbors (k)')\n",
    "plt.ylabel('Accuracy on test set')\n",
    "plt.title('knn model - accuracy vs neighbors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(k_range, k_acc, '-', label = 'K Nearest Neighbor')\n",
    "plt.title('Comparison of accuracy between models')\n",
    "plt.xlabel('# of neighbors in knn')\n",
    "plt.ylabel('Accuracy on Test Case')\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TO DO get top 5 k values\n",
    "best_k = k_range[np.argmax(k_acc)]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.learning_curve import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[m, train_score, test_score] = learning_curve(log_reg, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cv_err = np.mean(train_score, axis=1)\n",
    "test_cv_err = np.mean(test_score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(m, train_cv_err, label='Training Error')\n",
    "plt.plot(m, test_cv_err, label = 'Test Set Error')\n",
    "plt.title('Learning Curve of Logistic Regression')\n",
    "plt.xlabel('Size of Training Observations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[m2, train_score2, test_score2] = learning_curve(KNeighborsClassifier(best_k), X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_cv_err2 = np.mean(train_score2, axis=1)\n",
    "test_cv_err2 = np.mean(test_score2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(m2, train_cv_err2, label='Training Error')\n",
    "plt.plot(m2, test_cv_err2, label = 'Test Set Error')\n",
    "plt.title('Learning Curve of Best K {}-Nearest Neighbor'.format(best_k))\n",
    "plt.xlabel('Size of Training Observations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 4\n",
    "train_sizes, train_scores, test_scores = learning_curve(KNeighborsClassifier(k), \n",
    "                                                        X, y, \n",
    "                                                        train_sizes=np.linspace(0.05, 0.95, 18),\n",
    "                                                        cv=10, \n",
    "                                                        scoring='accuracy')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Training Examples vs. Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "ax.set_title('Learning Curves (KNeighborsClassifier(k=%d))' % k)\n",
    "ax.set_xlabel('Training Examples')\n",
    "ax.set_ylabel('Accuracy')\n",
    "# ax.set_ylim([0, 1]);\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kval = np.arange(1, 101)\n",
    "accuracy = np.zeros(kval.shape)\n",
    "for idx, k in enumerate(kval):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy[idx] = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot K vs. Accuracy\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "plt.plot(kval, accuracy, lw=2)\n",
    "# plt.ylim([0, 1]);\n",
    "plt.title('K vs. Accuracy')\n",
    "plt.xlabel('K value')\n",
    "plt.ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# argmax finds first occurence of max\n",
    "best_k = kval[np.argmax(accuracy)]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# but for KNN, a larger K is generally better since it's a less complex model\n",
    "# (i.e., less likely to overfit)\n",
    "best_k = max(kval[accuracy == max(accuracy)])\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make a logistic regression object, fit it on the training set, and test it to find accuracy\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "logistic_prediction = log_reg.predict(X_test)\n",
    "log_reg_accuracy = accuracy_score(y_test, logistic_prediction)\n",
    "print(log_reg_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.state.value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(), \n",
    "                                                        X, y,\n",
    "                                                        cv=10, \n",
    "                                                        scoring='accuracy')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Training Examples vs. Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "ax.set_title('Learning Curves (LogisticRegression)')\n",
    "ax.set_xlabel('Training Examples')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "log_accuracy = cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean()\n",
    "log_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(LogisticRegression(), \n",
    "                                                        X, y,\n",
    "                                                        cv=10, \n",
    "                                                        scoring='accuracy')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Plot Training Examples vs. Accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
    "plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "\n",
    "ax.set_title('Learning Curves (LogisticRegression)')\n",
    "ax.set_xlabel('Training Examples')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = naive_bayes.GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = naive_bayes.BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "X_train = scale(X_train)\n",
    "X_test = scale(X_test)\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accuracy: %.3f\"% accuracy_score(y_test, model.predict(X_test)))\n",
    "print(classification_report(y_test, model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_list = [GaussianNB(), SVC(), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "for model in model_list:\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, \n",
    "                                                            X, y, \n",
    "                                                            train_sizes=[0.7],\n",
    "                                                            cv=10, \n",
    "                                                            scoring='accuracy')\n",
    "\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    print('%s:\\n\\tTest Score: Mean= %.3f, Std= %.3f\\n' % (model, test_scores_mean, test_scores_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_list = [GaussianNB(), SVC(), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "for model in model_list:\n",
    "    test_scores = cross_val_score(model, X, y=y, cv=10, scoring='accuracy')\n",
    "    test_scores_mean = np.mean(test_scores)\n",
    "    test_scores_std = np.std(test_scores)\n",
    "    \n",
    "    print('%s:\\n\\tTest Score: Mean= %.3f, Std= %.3f\\n' % (model, test_scores_mean, test_scores_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define models to test\n",
    "model_list = [['KNN', KNeighborsClassifier(9)], # K=9 was best performance from Challenge07\n",
    "              ['Logistic', LogisticRegression()],\n",
    "              ['GaussianNB', GaussianNB()], \n",
    "              ['SVC', SVC(probability=True)], \n",
    "              ['DecisionTree', DecisionTreeClassifier()], \n",
    "              ['RandomForest', RandomForestClassifier()]]\n",
    "\n",
    "# Calculate metrics for each model\n",
    "roc = {}\n",
    "for model in model_list:\n",
    "    \n",
    "    model_name = model[0]\n",
    "    model = model[1]\n",
    "    \n",
    "    accuracy = []\n",
    "    precision = []\n",
    "    recall = []\n",
    "    f1 = []\n",
    "    auc = []\n",
    "        \n",
    "    # Perform K-Fold CV and calculate metrics for each fold\n",
    "    kf = KFold(5, random_state=4444, shuffle=True)\n",
    "    for train_idx, test_idx in kf.split(X, y=y):\n",
    "        X_train = X.iloc[train_idx, :] \n",
    "        X_test = X.iloc[test_idx, :] \n",
    "        y_train = y.iloc[train_idx] \n",
    "        y_test = y.iloc[test_idx] \n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        f1.append(f1_score(y_test, y_pred))\n",
    "        auc.append(roc_auc_score(y_test, y_pred))\n",
    "        \n",
    "    \n",
    "    # Calculate mean metric across K-folds\n",
    "    mean_accuracy = np.mean(accuracy)\n",
    "    mean_precision = np.mean(precision)\n",
    "    mean_recall = np.mean(recall)\n",
    "    mean_f1 = np.mean(f1)\n",
    "    mean_auc = np.mean(auc)\n",
    "    \n",
    "    # Capture TPR and FPR from last fold for plotting\n",
    "    y_score = model.predict_proba(X_test)[:,1]\n",
    "    roc[model_name] = roc_curve(y_test, y_score)\n",
    "    \n",
    "    # Print formatted results\n",
    "    print(model)\n",
    "    print('\\t==============================')\n",
    "    print('\\tAccuracy:', mean_accuracy)\n",
    "    print('\\tPrecision:', mean_precision)\n",
    "    print('\\tRecall:', mean_recall)\n",
    "    print('\\tF1:', mean_f1)\n",
    "    print('\\tAUC:', mean_auc)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot the ROC curve from the last K-Fold split\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "colors = ['b', 'g', 'r', 'c', 'm', 'y']\n",
    "\n",
    "# Plot 50-50 Line\n",
    "ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "# Plot Classifier ROC Curves\n",
    "for key, c in zip(roc.keys(), colors):\n",
    "    ax.plot(roc[key][0], roc[key][1], color=c, label=key)\n",
    "    \n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('Classifier Comparison')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Find the weighted precision and recall\n",
    "print('Weighted Precision:', precision_score(y_test, y_pred, average='weighted'))\n",
    "print('Weighted Recall:', recall_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred)) #, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = OneVsRestClassifier(LogisticRegression())\n",
    "logreg.fit(X_train, y_train)\n",
    "y_score = logreg.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Micro Average Precision:', average_precision_score(y_test, y_score, average='micro'))\n",
    "print('Macro Average Precision:', average_precision_score(y_test, y_score, average='macro'))\n",
    "print('Weighted Average Precision:', average_precision_score(y_test, y_score, average='weighted'))\n",
    "print('Precision for each Class:', average_precision_score(y_test, y_score, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision, recall, _ = precision_recall_curve(y_test.ravel(), y_score.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_score = logreg.predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Plot 50-50 Line\n",
    "ax.plot([0,1],[0,1], ls='--', color='k', label='50-50')\n",
    "# Plot Logistic ROC curve\n",
    "ax.plot(fpr, tpr, color='b', label='Logistic: %.3f' % roc_auc)\n",
    "    \n",
    "ax.set_xlabel('FPR')\n",
    "ax.set_ylabel('TPR')\n",
    "ax.set_title('Logistic ROC Curve')\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
